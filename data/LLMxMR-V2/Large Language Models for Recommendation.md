# A Survey on Large Language Models for Recommendation

# 0. A Survey on Large Language Models for Recommendation

## 1. Introduction
Recommendation Systems (RS) are indispensable for personalizing content discovery and product services across myriad modern digital platforms, ranging from e-commerce to social media and information consumption [14,19,24,28]. Concurrently, Large Language Models (LLMs), characterized as Transformer-based architectures with billions of parameters trained on vast datasets through self-supervised learning, have profoundly revolutionized Natural Language Processing (NLP) with their exceptional capabilities in language understanding, generation, and intricate reasoning [9,13,21,23,28]. This transformative influence of LLMs has naturally extended to the domain of recommendation, prompting a significant paradigm shift and intensive research endeavors to integrate these powerful models into RS, capitalizing on their advanced "emergence" capabilities such as in-context learning (ICL) and Chain-of-Thought (CoT) reasoning [7,12,28].



**Comparison of Traditional RS Limitations vs. LLM Advantages**

| Feature/Aspect      | Traditional Recommendation Systems Limitations                                                                         | Large Language Models Advantages                                                                                                            |
| :------------------ | :---------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------ |
| **Data Challenges** | - Pervasive data sparsity                                                                                                 | - Enhanced semantic understanding (high-quality textual features)                                                                           |
|                     | - Notorious cold-start problem (new users/items)                                                                          | - Address data sparsity and cold-start issues (zero/few-shot learning)                                                                      |
| **Information Use** | - Saturation of ID-based embeddings, overlooking rich textual information                                                 | - Integration of extensive external and generalizable world knowledge                                                                       |
|                     | - Inability to extract useful information from long user behavior sequences                                               | - Deep and nuanced understanding of user context and behavior                                                                               |
| **Understanding**   | - Poor natural language understanding                                                                                     | - Powerful reasoning abilities to infer implied user intent (CoT reasoning)                                                               |
|                     | - Restricted generalization capacities for unseen tasks                                                                   | - Remarkable zero-shot or few-shot learning abilities                                                                                       |
| **Decision Making** | - Struggle with complex multi-step reasoning (e.g., travel planning)                                                      | - Navigate complex multi-step decision-making                                                                                               |
|                     | - Often overfitting historical interaction data without grasping dynamic user preferences or semantic depth of content      | - Dynamic profile updates and adaptable frameworks                                                                                         |
| **Transparency**    | - Difficulties in generating transparent and explainable recommendations (black-box predictions)                          | - Natural language generation capabilities improve recommendation explainability                                                            |
| **Personalization** | - Tendencies towards homogeneity and lack of diversity                                                                    | - Fine-grained personalization through customizable prompts in conversational systems                                                       |
| **Trust**           | - Struggle to understand evolving customer concerns, feedback, and tastes                                                 | - Bolster user trust and satisfaction                                                                                                       |

Traditional recommendation systems, despite their widespread adoption, are confronted with persistent and inherent limitations. These include pervasive data sparsity, the notorious cold-start problem for new users or items, difficulties in generating transparent and explainable recommendations, and the saturation of ID-based embeddings, which frequently overlook the rich textual information associated with users and items [15,19,21,24]. Furthermore, conventional methods often exhibit poor natural language understanding, restricted generalization capacities for unseen tasks, and struggle with complex multi-step reasoning required for intricate decisions (e.g., travel planning), often overfitting historical interaction data without truly grasping dynamic user preferences or the semantic depth of content [10,14,20,28]. The inability to extract useful information from long user behavior sequences, even when context length is not an issue, also presents a challenge [5].

In stark contrast, Large Language Models offer compelling advantages poised to mitigate these aforementioned shortcomings. Their capabilities encompass enhanced semantic understanding derived from the extraction of high-quality textual features from diverse sources like user queries and item descriptions, the integration of extensive external and generalizable world knowledge, and remarkable zero-shot or few-shot learning abilities [18,19,21,22,24,28]. These attributes directly address data sparsity and cold-start issues, facilitating effective recommendations for unseen items or users without requiring extensive labeled interaction data [20,21,24,28]. Moreover, LLMs provide powerful reasoning abilities to infer implied user intent and navigate complex multi-step decision-making, while their natural language generation capabilities substantially improve recommendation explainability, enable fine-grained personalization through customizable prompts in conversational systems, and consequently bolster user trust and satisfaction [7,9,10,19,20,21,24,28]. This integration fosters a deeper and more nuanced understanding of user context and behavior, establishing more transparent and robust recommendation mechanisms [8].

The growing body of literature on LLMs for recommendation systems includes several survey papers that claim specific and notable contributions. A prominent contribution shared across multiple works is the proposition of novel classification paradigms for LLM-based recommendation models. Specifically, the field is often categorized into **Discriminative LLM for Recommendation (DLLM4Rec)** and **Generative LLM for Recommendation (GLLM4Rec)** [18,21,24,26]. Several surveys emphasize that the generative paradigm, GLLM4Rec, receives particular focus and is systematically reviewed for the first time, addressing a notable gap in prior literature which predominantly concentrated on the transfer of training techniques from pre-trained language models rather than a dedicated exploration of generative methods [21,24,26]. Beyond these core classifications, surveys also provide detailed technical analyses, extending the discussion to various modeling paradigms such as LLM Embeddings + RS, LLM Tokens + RS, and LLM as Direct RS [22,24]. These contributions also include the identification of key challenges, a comprehensive analysis of existing methods' advantages and limitations, and suggestions for future research directions, sometimes accompanied by resources like GitHub repositories [4,17,18,22,24].

This survey is meticulously structured to provide a comprehensive overview of Large Language Models for Recommendation. It will commence by elucidating the foundational concepts pertaining to both recommendation systems and large language models. Subsequently, it will delve into the diverse integration paradigms between LLMs and traditional recommendation algorithms [10,30]. The survey will then progress to examine specific applications where LLMs have demonstrated their efficacy, thoroughly analyze the key challenges and limitations inherent in this rapidly evolving field, and conclude by outlining promising future research trends and directions [24,26,27].
## 2. Background and Preliminaries

![Large Language Model Fundamentals](https://modelbest-prod.oss-cn-beijing.aliyuncs.com/SurveyGo/picture/RkR6NQMGQEVLLiP2XHGNO_Large%20Language%20Model%20Fundamentals.png)

Recommendation systems (RS) have become indispensable tools in navigating the vast and increasing volume of online information, playing a pivotal role in personalizing user experiences and facilitating the discovery of relevant content, services, and products [19,28]. At their core, these systems are designed to predict user preferences and interests based on historical interactions, typically employing a multi-stage architecture that includes recall, various ranking stages (coarse, fine, re-ranking, and end-ranking), and business filtering [3,28]. Fundamental tasks within this domain include Top-K recommendation and rating prediction [23,27].



![Evolution of Recommendation Systems Paradigms (Pre-LLM Era)](https://modelbest-prod.oss-cn-beijing.aliyuncs.com/SurveyGo/picture/HdtIzej5hySl-mZQW67-d_Evolution%20of%20Recommendation%20Systems%20Paradigms%20%28Pre-LLM%20Era%29.png)

The evolution of recommendation systems has progressed through several distinct paradigms. Early approaches were largely characterized by **traditional methods** such as Collaborative Filtering (CF) and Content-Based Filtering (CBF). CF leverages user-item interaction histories to identify similar users or items, assuming that similar preferences will lead to similar future interests, and forms the basis for learning discrete ID embeddings [10,19,30]. CBF, conversely, analyzes a user's past consumption and item attributes to suggest new items aligned with their inferred interests [19,30]. Significant advancements followed with **Matrix Factorization (MF)**, which efficiently learned latent factor representations for users and items, enhancing scalability and prediction accuracy, particularly popularized by the Netflix Prize competition [19,31]. To mitigate the individual weaknesses of CF and CBF, **hybrid methods** emerged, combining their strengths to improve overall recommendation quality [19].

The advent of **deep learning architectures** marked a profound shift in the pre-LLM era, especially for modeling user behavior sequences [15,19]. Methodologies based on Recurrent Neural Networks (RNNs) and attention mechanisms became foundational for capturing temporal dynamics within user interactions. Prominent models included **CASER**, which used Convolutional Neural Networks (CNNs) to extract local sequential patterns; **SASRec**, which introduced a self-attention mechanism to capture long-range semantic dependencies; and **BERT4Rec**, which applied a bidirectional Transformer architecture with a masked item prediction objective, learning bidirectional context from user histories [29]. These deep learning sequential models primarily functioned within the ranking stage, refining predictions based on historical user interactions [31].

Despite these advancements, pre-LLM recommendation systems, encompassing both traditional and early deep learning approaches, faced **inherent challenges** that underscored the need for new paradigms. A critical limitation was their fundamental reliance on discrete ID-based data, which often disregarded or inadequately utilized rich textual and semantic information associated with users and items [7,10,19]. This resulted in several persistent issues: severe **data sparsity** and **cold-start scenarios** for new users or items [20,21,24], a pervasive **lack of explainability** in their "black-box" predictions [17,19,21], **limited semantic understanding** due to poor natural language processing capabilities [10,15], and tendencies towards **homogeneity and lack of diversity** in recommendations [17,28]. Furthermore, these models often struggled with **bias issues** perpetuated by historical data, **computational demands** for large-scale deployment, and ultimately reached a **performance bottleneck** that made further substantial improvements challenging [7,28].

In stark contrast, **Large Language Models (LLMs)** emerged as a transformative technology, fundamentally built upon the **Transformer architecture** and its innovative self-attention mechanism [8,12]. Defined by their substantial parameter counts (billions to hundreds of billions) and extensive pre-training on massive textual datasets, LLMs acquire vast world knowledge, deep semantic understanding, and common sense reasoning capabilities [8,9,28]. A key characteristic of LLMs is the emergence of advanced abilities at scale, including **In-Context Learning (ICL)**, allowing performance on novel tasks without explicit fine-tuning [19,28]; **Chain-of-Thought (CoT) Reasoning**, enabling decomposition of complex problems into intermediate steps for enhanced interpretability [9,28]; and **Zero-shot/Few-shot Learning**, facilitating recommendations with minimal or no prior interaction data [20,21].

A critical distinction arises when discussing "large models" in the context of recommendation. While traditional recommendation systems have also featured "large models," their "largeness" primarily resided in storage-intensive embedding layers for discrete user and item IDs [7,12]. LLMs, conversely, are compute-intensive, parameter-rich neural networks whose "largeness" confers universal representation capabilities and the ability to capture rich semantic information from textual data [12,19]. This fundamental difference highlights a **representational gap** between ID-centric traditional RS and text-derived semantic representations of LLMs, which bridging presents both challenges and significant opportunities [7].

The profound capabilities of LLMs provide compelling **motivations and opportunities** for their integration into recommendation systems. Their ability to capture rich semantic information from item descriptions, user reviews, and queries allows for more informative user and item representations [16,21]. LLMs leverage extensive world knowledge and powerful reasoning to understand contextual user behavior and explicit language-based preferences, leading to more personalized and contextually relevant suggestions [17,21]. Crucially, their zero-shot and few-shot learning capabilities directly address the persistent cold-start problem, adapting to new items or users even with limited historical data [1,20]. Furthermore, LLMs' natural language generation prowess allows them to provide clear, human-like textual explanations for recommendations, directly tackling the long-standing interpretability issue of traditional "black-box" models and enhancing user trust [10,17,24]. These transformative capabilities position LLMs as a new research path to overcome the limitations of prior recommendation paradigms and unlock new frontiers in personalized recommendations.
### 2.1 Evolution of Recommendation Systems
The landscape of recommendation systems has undergone a continuous evolution, driven by the increasing volume of online information and the imperative for personalized user experiences [19]. At its core, recommendation systems are designed to predict user preferences and interests based on historical interactions, forming the basis for effective content, service, and product discovery [19,28]. This process typically follows a multi-stage architecture, which has remained a consistent framework despite various optimizations, encompassing recall, multiple ranking stages (coarse, fine, re-ranking, and end-ranking), and business filtering to ultimately present items to users [3,28]. Fundamental tasks within these systems include Top-K recommendation and rating prediction [23,27].

Early approaches to recommendation systems were characterized by foundational techniques, primarily **Collaborative Filtering (CF)** and **Content-Based Filtering (CBF)**. Collaborative Filtering operates under the assumption that users exhibiting similar historical preferences will likely share future interests [19,30]. It leverages user-item interaction histories, such as ratings, to identify either similar users (User-Based CF) or similar items (Item-Based CF) for recommendation [20,29,30]. CF also laid the groundwork for learning discrete ID embeddings for users and items, crucial for modeling their interactions [7,10]. In contrast, **Content-Based Filtering**, derived from information retrieval principles, analyzes a user's past consumption patterns and item attributes to suggest new items that align with their inferred interests [19,30]. While foundational, these methods often suffered from limitations such as data sparsity, particularly in cold-start scenarios, and scalability challenges [19,20,24,26,28]. Moreover, their reliance on discrete IDs for users and items meant a lack of semantic richness, hindering the accurate calculation of user-item relevance in sparse interaction contexts [10,15]. They typically could not provide textual explanations for recommendations, struggled with homogeneity, and lacked diversity, often overfitting specific user behaviors [3,14,17,28].

Significant advancements emerged with **Matrix Factorization (MF)**, which gained prominence for its efficiency and scalability, notably during the Netflix Prize competition [19]. MF models learn latent factor representations (vector embeddings) for users and items in a shared lower-dimensional space, subsequently using these to predict missing entries in the user-item interaction matrix [20,29,31]. Further iterations included deep learning methods like Neural Collaborative Filtering (NCF) and AutoRec, which utilized neural networks to enhance feature extraction or replace traditional matrix operations [1,29]. To overcome the inherent weaknesses of individual CF and CBF approaches, **hybrid methods** were developed, combining elements from both to leverage their respective strengths and improve overall recommendation quality [19]. Despite these advancements, these ID-based models gradually reached a performance bottleneck, making further substantial improvements challenging [7].

The pre-LLM era witnessed a profound evolution in recommendation systems with the advent of **deep learning architectures**, particularly for modeling user behavior sequences [15,19]. This shift enabled more sophisticated capture of temporal dynamics within user interaction histories, with methodologies based on Recurrent Neural Networks (RNNs) and attention mechanisms becoming foundational [19]. Pioneering work, such as "Sequential Recommendation with User Memory Networks," exemplified early efforts in this domain [23]. Key models included:

*   **CASER (Convolutional Sequence Embedding Recommendation)**, introduced in 2018, employed Convolutional Neural Networks (CNNs) to extract local sequential patterns from user interaction histories. By treating item embedding sequences as "images," CASER utilized both horizontal and vertical convolutions to capture joint-level and individual-level patterns, respectively, which were then processed to predict target items. Its strength lay in effectively capturing short-term, fine-grained sequential patterns and addressing "skip behaviors" [29].
*   **SASRec (Self-Attentive Sequential Recommendation)**, also from 2018, revolutionized sequential recommendation by integrating a self-attention mechanism, inspired by the Transformer architecture. This allowed SASRec to capture long-range semantic dependencies within a user's interaction history, providing contextual predictions for the next item by focusing on relevant past actions. This approach significantly improved upon the limitations of traditional Markov Chains and RNNs in handling long-range dependencies [29]. SASRec's superior ability to model such dependencies made it a potent component in various frameworks [9,29].
*   **BERT4Rec**, drawing inspiration from BERT in Natural Language Processing (NLP), utilized a bidirectional Transformer architecture with a masked item prediction objective. This enabled it to learn bidirectional context from user interaction histories, considering both preceding and succeeding interactions relative to a masked item, thereby enhancing prediction accuracy [29]. While adopting BERT's training strategies, it is generally considered distinct from the advanced capabilities of large language models in broader LLM research contexts [21,24].

These deep learning sequential models primarily functioned within the ranking stage, refining predictions based on historical user interactions and generating relevance scores [31]. However, despite their advancements, they faced their own set of limitations. A significant drawback was their inability to fully capture the rich textual information associated with users and items, leading to suboptimal natural language understanding, especially with data and model scale constraints [10]. They often struggled with the "long-tail problem," where many items are rarely consumed, impacting both user experience and business interests [17]. Furthermore, computational demands and efficiency remained challenges, particularly in evolving areas like conversational recommendation systems requiring sophisticated dialogue management [17]. These limitations, especially in understanding complex semantics and handling data sparsity, underscored the need for more powerful and flexible models, ultimately paving the way for the integration of Large Language Models into the recommendation system paradigm [10,17].
#### 2.1.1 Traditional Recommendation Methods
Traditional recommendation systems primarily aim to predict user preferences or interests based on historical interactions, forming the bedrock of personalized recommendation [28]. These systems commonly employ a multi-stage process involving recall mechanisms, various ranking stages (coarse, fine, re-ranking, and end-ranking), and business filtering to order and present items [3,28]. Fundamental tasks include Top-K recommendation and rating prediction [23,27].

Among the foundational techniques, **Collaborative Filtering (CF)** stands out. Its core assumption posits that users with similar tastes will have similar interests, thus recommendations can be made by leveraging the preferences of like-minded individuals [19,30]. CF typically relies on user-item interaction histories, often expressed through ratings [20]. This approach is broadly categorized into User-Based CF, which identifies similar users to a target user, and Item-Based CF, which calculates item-to-item similarity [29,30]. CF also forms the basis for learning discrete ID embeddings for users and items to model their interactions [7,10].

**Content-Based Filtering (CBF)**, originating from information retrieval, operates on a different principle. It analyzes a user's past consumption behaviors and interest preferences to match candidate items based on their attributes [19,30].

Building upon CF, **Matrix Factorization (MF)** emerged as a significant advancement, gaining prominence during the Netflix Prize competition due to its efficiency and scalability [19]. MF learns latent factor models for users and items, representing them as vector embeddings in a shared lower-dimensional space. These representations are then used to predict missing entries in the user-item interaction matrix [20,29,31]. Other related advancements include deep learning methods like Neural Collaborative Filtering (NCF) and AutoRec, which use neural networks to extract item features or replace the inner product in MF [1,29]. Additionally, methods like Item-kNN and Sparse Linear Methods (SLIM) such as BPR-SLIM, along with autoencoder approaches like EASE, have contributed to the landscape of traditional recommendation systems, often competitive with more complex state-of-the-art methods in certain settings [20].

To mitigate the individual shortcomings of CF and CBF, **hybrid approaches** combine elements from both, aiming to leverage their respective strengths and improve overall performance [19].

Despite their foundational role and effectiveness in leveraging user-item interaction data for personalized recommendations [1], traditional recommendation methods face several inherent limitations. A primary challenge is **data sparsity**, particularly in cold-start scenarios where new users or items lack sufficient historical interaction data [20,24,26,28]. These systems also struggle with **scalability issues** in large-scale environments [19]. Furthermore, their reliance on discrete ID representations for users and items means they often lack sufficient semantic information, complicating user-item relevance calculation, especially in sparse interaction contexts [10,15]. Traditional CF methods, while widely used, often **lack the ability to provide textual explanations** for their suggestions, limiting transparency [14,17]. They are prone to **overfitting user behavior** in specific scenarios, leading to homogeneity issues (e.g., repeatedly recommending items a user has already purchased) and a general **diversity issue** that hinders serendipitous discoveries [3,28]. Such systems are also noted for their inability to provide a deep understanding of evolving customer concerns, feedback, and tastes, which is crucial for modern personalized experiences [14]. Optimizations for these ID-based models have progressively reached a performance bottleneck, making significant further improvements challenging [7]. Moreover, traditional graph-based systems often disregard valuable textual information associated with users and items, leading to less informative representations and challenges with noise and bias from implicit feedback [15].
#### 2.1.2 Deep Learning for Sequential Recommendation (Pre-LLM Era)
The advent of deep learning architectures marked a significant evolution in sequential recommendation, enabling more sophisticated modeling of user behavior sequences and substantial improvements in prediction accuracy [15,19]. Prior to the pervasive adoption of Large Language Models (LLMs), methodologies based on Recurrent Neural Networks (RNNs) and attention mechanisms became foundational for capturing intricate temporal dynamics within user interaction histories [19]. Early work, such as "Sequential Recommendation with User Memory Networks," exemplified this trend in modeling user behavior sequences [23].

Key deep learning models emerged to address the challenges of sequential recommendation:

*   **CASER (Convolutional Sequence Embedding Recommendation)**: Introduced in 2018, CASER leverages Convolutional Neural Networks (CNNs) to extract local sequential patterns from user interaction histories [29]. It begins by mapping users and items to embeddings, forming an embedding matrix $E$ of size $L \times d$ for a sequence of $L$ items. This matrix is then treated as an "image" for convolutional layers. Horizontal convolutions employ kernels of size $h \times d$ to capture joint-level patterns, while vertical convolutions use kernels of size $L \times 1$ to capture individual-level patterns, producing $d$-dimensional aggregated features [29]. The outputs are concatenated and processed through Multi-Layer Perceptrons (MLPs) to generate a "convolutional sequence embedding," which is then used to predict target item probabilities. CASER's strength lies in its ability to effectively capture short-term, fine-grained sequential patterns, addressing "skip behaviors" by predicting future items [29]. While effective, its explicit limitations in terms of computational demands or interpretability are not detailed in the available literature.

*   **SASRec (Self-Attentive Sequential Recommendation)**: Also introduced in 2018, SASRec revolutionized sequential recommendation by applying a self-attention mechanism, inspired by the Transformer architecture [29]. It takes user item sequence embeddings and positional embeddings as input, processing them through a self-attention block comprising self-attention layers, feed-forward networks, skip connections, and layer normalization [29]. The key innovation of SASRec is its capacity to capture long-range semantic dependencies within a user's interaction history, contextually predicting the next item by focusing on a few relevant previous actions. This approach overcomes limitations of traditional Markov Chains (MC), which struggle with long-range dependencies, and improves upon RNNs for efficient handling of dense datasets [29]. SASRec has been utilized as a component in broader frameworks, such as the LANE framework, where its embedding layer can be adapted and its prediction layer removed for specific applications [9]. The primary strength of SASRec is its superior ability to model long-range dependencies and provide contextual predictions [29].

*   **BERT4Rec**: Drawing inspiration from BERT in Natural Language Processing (NLP), BERT4Rec utilizes a bidirectional Transformer architecture [29]. Its core innovation lies in employing a masked item prediction objective, enabling the model to learn bidirectional context from a user's interaction historyâ€”considering both past and future interactions relative to a masked item. This bidirectional contextual understanding significantly enhances prediction effectiveness [29]. While BERT4Rec and similar models like RESETBERT4Rec adopted BERT's training strategies, they are generally not considered to have fully expanded the capabilities of large language models into the recommendation domain in the context of advanced LLM research [21,24]. Its main strength is improved prediction performance through bidirectional contextual understanding of user sequences [29].

In deep learning-based recommender systems, these sequential models primarily function within the ranking stage, generating relevance scores or predicting the likelihood of interaction for candidate items. While the provided digests do not explicitly detail the sequential stages from recall to re-ranking within deep learning-based recommenders, the core contribution of these models is to refine predictions based on historical user interactions, which is fundamental to accurate item ranking. Similarly, Transformer-based architectures, like NARM, were employed in session recommendations to capture short-term user interests and integrate them with long-term profiles [31].

Despite their advancements, these pre-LLM deep learning sequential recommendation models presented several inherent limitations. A significant constraint was their inability to fully capture the rich textual information of users and items, leading to suboptimal natural language understanding, especially when limited by data and model scale [10]. Furthermore, these models often struggled with the "long-tail problem," where users interact with only a few items or many items are rarely consumed, impacting both user experience and seller interests [17]. Computational demands and efficiency were also noted challenges, particularly in evolving areas like conversational recommendation systems, which require sophisticated dialogue management and anticipation capabilities [17]. These limitations, particularly in understanding complex semantics and handling data sparsity, highlighted the need for more powerful and flexible models, thus paving the way for the integration of Large Language Models into recommendation systems [10,17].
### 2.2 Inherent Challenges of Traditional Methods
Traditional recommendation systems, developed prior to the advent of large language models (LLMs), have consistently demonstrated inherent limitations that underscore the need for new paradigms. A critical drawback is their fundamental reliance on overfitting user behavior patterns within specific scenarios to generate predictions [3,28]. This "overfitting," while capable of yielding favorable results in confined contexts, is often described as a "poison" that leads to various systemic issues [3].

A core limitation stems from the pervasive dependency on ID-based data, which encodes users and items as discrete identifiers, thereby often disregarding or inadequately utilizing rich textual and semantic information associated with these entities [7,10,11,12,15,18,19,26]. This reliance on implicit signals and ID-based embeddings results in insufficient representation richness and significantly hampers the capacity to capture complex semantic aspects or achieve a deep understanding of user preferences [11,15,19]. Consequently, traditional methods often fail to exhibit a profound understanding of customer concerns, feedback, or evolving tastes [14]. They primarily model behavior patterns rather than genuinely comprehending the evolving user mindset or the semantic depth of items, thus failing to grasp "user's mental changes" [3,14,28].

These foundational issues manifest in several persistent challenges:
*   **Cold-Start Scenarios**: Traditional systems notoriously struggle with the cold-start problem, wherein they are unable to generate relevant recommendations for new users or items due to an insufficient volume of historical interaction data [1,3,18,19,20,21,22,24,26,28].
*   **Data Sparsity**: Closely related is data sparsity, which is particularly acute for long-tail users and items with limited interaction data. This scarcity leads to poorly learned ID embeddings and a significant drop in recommendation performance [7,10,11,15,17,18,19,21,24].
*   **Lack of Explainability**: Many traditional "black-box" recommendation models, particularly those based on Multi-Layer Perceptrons (MLPs) or collaborative filtering, inherently lack interpretability. They cannot articulate clear and coherent reasons behind their recommendations or the meaning of their output sequence feature vectors [7,9,15,17,19,21]. This opacity undermines user trust and satisfaction [9].
*   **Limited Semantic Understanding**: Traditional models, including graph-based recommenders, tend to overlook valuable textual information, resulting in insufficient representation richness and struggling with complex semantic aspects or deep user understanding [10,11,15,19,31]. Even when text is incorporated, such as in content-based recommenders, the derived user representations can remain "inscrutable" [20], indicating a failure to fully leverage rich textual data for user preferences [20,26].
*   **Homogeneity and Lack of Diversity**: The overfitting tendency also leads to a homogeneity problem or content singularity, wherein systems recommend items a user has already consumed or very similar content. This reduces novelty, diversity, and serendipity, failing to introduce users to diverse interests or unexpected items [3,17,28].
*   **Bias Issues**: The reliance on historical data can perpetuate and amplify inherent biases present in the data, leading to various fairness issues in recommendations. Furthermore, the utilization of implicit feedback data often introduces noise and bias, complicating effective user preference learning [3,11,15,19,24,28].

Before the widespread integration of LLMs, early deep learning sequential models and Transformer-based architectures also presented significant computational and interpretability limitations. Markov Chains (MC), while suitable for sparse datasets, struggled to capture long-range dependencies in user behavior sequences [29]. Recurrent Neural Networks (RNNs), though capable of modeling longer relationships, incurred substantial computational costs, especially for very long sequences or dense datasets [29]. Models that focused only on immediate next-item prediction often overlooked "skip behaviors" (predicting items further down the sequence) [29].

More generally, Deep Neural Networks (DNNs), including Convolutional Neural Networks (CNNs), and even some pre-trained language models like BERT, suffered from poor natural language understanding due to data and model scale limitations, hindering their ability to adequately capture user and item textual information [10]. These models exhibited limited generalization capabilities, often being task-specific and struggling to transfer knowledge to unseen recommendation tasks or those requiring complex multi-step reasoning, such as planning a travel itinerary [10]. The "black-box" nature persisted, impeding interpretability even in these advanced DNN-based methods [7,9]. Furthermore, conversational recommendation systems faced challenges with dialogue management complexity, low computational efficiency, and data sparsity in leveraging historical dialogue experiences [17]. Scalability issues were a general concern, particularly in efficiently handling large volumes of users and items [19], with the computational cost and demand for rapid response times posing practical difficulties for real-time recommendation systems [4,6,7,12,27]. These inherent drawbacks across traditional and early deep learning approaches underscore the critical necessity for innovative solutions capable of deeper semantic understanding, improved generalization, and enhanced explainability, thereby setting the stage for the exploration and integration of Large Language Models in recommendation systems.
### 2.3 Large Language Models Fundamentals
Large Language Models (LLMs) are fundamentally built upon the Transformer architecture, first introduced in 2017 [1,8]. This architecture is characterized by its compute-intensive nature and the innovative self-attention mechanism [8,12]. The self-attention mechanism is crucial for capturing long-range dependencies within input sequences and generating highly contextualized embeddings [1,3,8,21,24,26,28]. LLMs can be categorized based on their Transformer structure into encoder-only (e.g., BERT), decoder-only (e.g., GPT family), and encoder-decoder (e.g., T5) architectures, each designed for distinct natural language processing tasks such as contextual understanding, generation, or sequence-to-sequence transformations, respectively [8,19].

These models are defined by their substantial parameter counts, typically ranging from 10 billion to over 100 billion, and undergo an extensive pre-training process [3,28]. This process involves self-supervised or semi-supervised learning on massive textual datasets, endowing LLMs with vast world knowledge, deep semantic understanding, factual information, domain expertise, and common sense reasoning capabilities [8,9,12,18,21,24,26,28]. Through this pre-training, LLMs learn to model the probability of token sequences, where semantically similar words acquire analogous embeddings, and these embeddings adapt dynamically based on their surrounding context [8].

The pre-trained capabilities allow LLMs to perform a wide array of complex natural language tasks, including text generation, comprehension, classification, intent and sentiment extraction, summarization, relation mapping, question answering, and code generation [1,18,20,23,33]. A hallmark of LLMs is the emergence of advanced abilities, which manifest when models reach a critical scale in parameter size [3,18,21,28]. Key emergent abilities include:

*   **In-Context Learning (ICL)**: This refers to the model's capacity to achieve strong performance on novel tasks without explicit fine-tuning. Instead, it leverages a small number of example input-label pairs provided directly within the prompt to guide its predictions on new, unseen data, without requiring any gradient updates [1,3,19,20,26,27,28].
*   **Chain-of-Thought (CoT) Reasoning**: An ability that enables LLMs to decompose complex problems into a series of intermediate steps, thereby providing a transparent, step-by-step thought process. This enhances their capacity to solve intricate problems and generate more interpretable explanations [3,9,27,28].
*   **Zero-shot/Few-shot Learning**: Due to their extensive pre-training and ICL capabilities, LLMs can generate reasonable responses and recommendations even for items or users they have not explicitly encountered during their training phase [1,5,19,20,21,26]. While exhibiting powerful reasoning capabilities, LLMs can sometimes display "hallucination," generating plausible but factually incorrect information [10].

These fundamental characteristics of LLMs, encompassing their architectural design, extensive pre-training, and sophisticated emergent abilities like complex reasoning and adaptive learning, collectively establish a robust foundation for their innovative application within recommendation systems [1,3,23,26,28].
#### 2.3.1 Differentiating 'Large Models' in Recommendation
The term "large model" holds distinct meanings within the realms of traditional recommendation systems (RS) and Large Language Models (LLMs), a differentiation crucial for comprehending the unique challenges and opportunities of integrating LLMs into recommendation [12].

In traditional recommendation systems, "large models" primarily refer to architectures characterized by a high parameter count predominantly concentrated in the embedding layers, which are used to represent users and items through unique identifiers (IDs) [7,12]. These models are inherently storage-intensive, as they rely on vast ID embeddings to capture user and item interactions and collaborative filtering signals [7]. Consequently, their "largeness" is predominantly storage-centric, with their capabilities often limited by the implicit signals derived from interaction data and a neglect of valuable textual information associated with users and items [11,12,18]. Traditional ID-based models struggle to leverage rich external knowledge and context beyond explicit interaction patterns [18,19].

In stark contrast, Large Language Models (LLMs) are defined by their compute-intensive, parameter-rich neural networks, typically built upon Transformer structures and attention mechanisms, and trained on extensive text corpora [7,12]. The "largeness" of LLMs stems from their massive parameter counts, enabling universal representation capabilities and the ability to understand context, generate human-like text, and capture rich semantic information from textual data [18,19]. This allows LLMs to derive superior representations for users and items by leveraging descriptions, reviews, and other textual data, thereby enhancing recommendation performance, especially in scenarios like cold-start where traditional ID-based systems falter [19]. Furthermore, LLMs exhibit emergent capabilities, such as learning complex relations and unifying diverse search and recommendation tasks under a single framework, distinguishing them fundamentally from traditional "large" models with extensive ID embedding tables [23]. While some literature emphasizes the general benefits of LLMs for recommendation, focusing on their language processing and reasoning abilities, the underlying distinction in their "largeness" remains pertinent [10].

This differentiation is crucial for understanding the unique challenges and opportunities in integrating LLMs into recommendation systems. A primary challenge lies in the representational gap between the discrete, ID-centric nature of traditional RS and the continuous, text-derived semantic representations of LLMs [7]. Bridging this gap requires innovative methods to align or merge these two modalities effectively [7]. Moreover, the compute-intensive nature of LLMs introduces significant challenges related to computational resources and model complexity, demanding substantial infrastructure and efficient inference strategies [12]. Despite these challenges, the integration of LLMs offers substantial opportunities, such as leveraging their ability to model textual data effectively, as seen in systems like CLLM4Rec, which extends pre-trained LLM vocabulary with user/item ID tokens to integrate collaborative and content semantics [11]. This paradigm shift moves beyond solely ID-based approaches, enabling a richer, more context-aware, and personalized recommendation experience.
### 2.4 Why LLMs for Recommendation? (Motivations & Opportunities)
The integration of Large Language Models (LLMs) into recommendation systems represents a significant paradigm shift, driven by their distinct advantages that address many limitations inherent in traditional recommendation approaches [12,21]. LLMs offer a "new research path" by enabling advanced comprehension, generation, and reasoning capabilities that were previously unseen in conventional models [9,23].

A primary motivation stems from LLMs' remarkable capacity for capturing rich semantic information from textual data. Unlike traditional ID-based systems that struggle with non-structured inputs, LLMs can deeply understand and process complex textual information such as item descriptions, user reviews, and queries [16,21]. This capability allows for the extraction of high-quality textual features and the generation of more informative user and item representations [14,18]. For instance, LLMs can generate contextual embeddings that reveal nuanced semantic relationships between items and users, which is crucial for effective recommendations [8,11]. They can even fuse cross-modal information, combining text, images, and audio into unified representations for more comprehensive user profiles [14,31].

Furthermore, LLMs leverage their extensive world knowledge and powerful reasoning capabilities to understand contextual user behavior in depth [17,21]. Trained on vast datasets, LLMs encode factual information, domain expertise, and common sense reasoning, enabling them to make reasonable recommendations even without extensive historical interaction data [7,18]. Their ability to perform complex multi-step reasoning, often facilitated by techniques like Chain-of-Thought prompting, allows them to handle intricate recommendation scenarios and interpret implied user intent, leading to more personalized and contextually relevant suggestions [9,19].

Crucially, LLMs excel at handling **natural language user profiles** and **explicit language-based preferences**. This capacity allows for the direct processing of descriptive natural language inputs, yielding more explainable and scrutable preference representations compared to opaque item-based or vector-based approaches [20]. Such transparency empowers users with greater control over their personalization experience. Moreover, these linguistic capabilities are instrumental in addressing **cold-start challenges**, where limited historical data hinders traditional methods. LLMs' remarkable **zero-shot and few-shot learning abilities** allow them to make recommendations with minimal or no prior interaction data, adapting to new items or users by drawing on their vast pre-training [5,21]. For instance, studies have shown that LLMs can deliver competitive recommendation performance for pure language-based preferences in near cold-start scenarios, even without supervised training, suggesting their efficacy in alleviating data sparsity [1,20].

Finally, LLMs' reasoning and text generation capabilities lead to more personalized, contextually relevant, and explainable recommendations [20,22]. By leveraging their natural language generation prowess, LLMs can provide clear, comprehensive, and human-like textual explanations for their suggestions, such as "recommending *The Three-Body Problem* because the user enjoys science fiction" [10,24]. This directly addresses the long-standing interpretability issue of traditional "black-box" models, enhancing user trust and understanding [13,17]. Moreover, LLMs facilitate dynamic profile updates and adaptable frameworks, allowing for customization to individual user preferences and multi-task optimization [17,31]. The emerging availability of high-performance open-source LLMs and decreasing API costs further reduce computational barriers, making these advanced capabilities more accessible for research and development [27].
## 3. LLM Integration Taxonomies and Core Paradigms in Recommendation Systems

![Prompting Strategies for LLMs in Recommendation](https://modelbest-prod.oss-cn-beijing.aliyuncs.com/SurveyGo/picture/PJ8RIXgJeF04HJo0un-ss_Prompting%20Strategies%20for%20LLMs%20in%20Recommendation.png)


**Comparison of Fine-tuning Strategies for LLMs in Recommendation**

| Feature/Aspect         | Full-Model Fine-tuning                                                                   | Parameter-Efficient Fine-tuning (PEFT)                                                                                                                                                                                                                                                                                                                                       |
| :--------------------- | :--------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Parameters Tuned**   | All parameters of the pre-trained LLM                                                    | Only a small subset of parameters or new, trainable components are introduced; majority of LLM parameters remain frozen                                                                                                                                                                                                                                                     |
| **Goal**               | Deeply specialize the model for the target recommendation task                           | Adapt LLM to specific tasks with significantly fewer trainable parameters, reducing computational burden                                                                                                                                                                                                                                                             |
| **Computational Cost** | High (updating billions of parameters)                                                   | Significantly lower (reduces GPU memory and training time)                                                                                                                                                                                                                                                                                                           |
| **Resource Demands**   | Demanding, resource-intensive, scalability challenges                                    | More accessible and practical, especially for limited resources or very large base models                                                                                                                                                                                                                                                                            |
| **Potential Performance**| Potentially superior due to full leverage of LLM capacity                              | Achieves comparable performance to full fine-tuning with minor trade-offs                                                                                                                                                                                                                                                                                            |
| **Examples**           | RecLLM, GIRL, P5 (multi-task instruction fine-tuning), Kang et al. (rating prediction)   | **LoRA:** iLoRA (instance-wise for sequential RS), TALLRec (instruction-based on LLaMA-7B), GANPrompt<br>**Adapters & Prompt Tuning:** Learning "soft prompts," "Option Tuning" (enhanced prompt tuning)<br>**Instruction Tuning:** P5 (five instruction types), GBERT, InstructRec, ReiT (Retrieval-enhanced Instruction Tuning in ReLLa)                                 |
| **Trade-offs**         | High performance vs. substantial cost & scalability issues                                | Efficiency & accessibility vs. minor performance trade-offs, potential `LossOfInterpretability` (soft prompts), `DiscreteOptimization` (hard prompts), `PromptDesignComplexity` (all prompting methods), `ComputationalCost` of retrieval (ReiT)                                                                                                                            |
| **Application Areas**  | Conversational RS, unified RS, rating prediction, news recommendation, sequential RS     | Sequential RS, rating prediction, item generation, diverse recommendation tasks, cold-start problems, especially in resource-constrained environments                                                                                                                                                                                                                     |


**Overarching LLM Recommendation Classifications**

| Feature/Aspect        | Discriminative LLMs for Recommendation (DLLM4Rec)                                                 | Generative LLMs for Recommendation (GLLM4Rec)                                                     |
| :-------------------- | :------------------------------------------------------------------------------------------------ | :------------------------------------------------------------------------------------------------ |
| **Primary Goal**      | Deep semantic understanding, feature extraction, encoding information                             | Produce novel textual outputs, natural language generation                                        |
| **LLM Role**          | "Embedding backbones," "embedding extractors," feature encoders                                   | Direct output generation, transforming tasks into NLG problems                                    |
| **Typical Architecture** | Encoder-only (e.g., BERT, RoBERTa)                                                                | Decoder-only (e.g., GPT family, Llama)                                                            |
| **Directionality**    | Bidirectional                                                                                       | Unidirectional (causal)                                                                           |
| **Core Task Focus**   | Natural Language Understanding (NLU), representation learning                                     | Natural Language Generation (NLG), text-to-text generation                                        |
| **Integration Paradigm**| Aligns with "LLM Embeddings + RS"                                                                 | Aligns with "LLM Tokens + RS" and "LLM as RS"                                                     |
| **Adaptation Strategy**| Fine-tuning, prompt tuning for specific domain data                                               | In-context learning, prompt tuning, instruction tuning for direct generation                      |
| **Examples**          | U-BERT, UserBERT, UNBERT (for representations), BERT4Rec (masked behaviors)                       | GenRec, PGNR, NIR, GPTRec (for recommendations), XRec (explanation generation), D3 (item generation) |
| **Challenges**        | Computational cost of fine-tuning, data bias from training data, complexity of aligning features  | Hallucination risk, computational cost, consistency issues                                        |

The advent of Large Language Models (LLMs) has profoundly influenced the landscape of recommender systems (RS), leading to the emergence of innovative integration strategies. This section systematically categorizes and explains the primary modeling paradigms for incorporating LLMs into recommendation systems, establishing a comprehensive framework for understanding this evolving field [1,3,4,21,22,24,28].

We formally define **LLM-Enhanced Recommender Systems (LLMERS)** as conventional recommender systems that are "enhanced by large language models via assistance in training or supplementary for data, while no need for LLM inference during the service" [4]. This definition highlights a crucial distinction: LLMERS typically leverage LLMs for offline processes, such as enriching knowledge, enhancing interaction data, or improving model components, rather than relying on real-time LLM inference during the online recommendation service. This focus on offline enhancement addresses significant challenges related to computational cost and latency, making LLM integration more practical for many industrial applications.

The integration of LLMs into recommendation systems is fundamentally bifurcated into two overarching classifications: **Discriminative LLMs for Recommendation (DLLM4Rec)** and **Generative LLMs for Recommendation (GLLM4Rec)** [18,21,24,26]. This distinction is pivotal, reflecting whether LLMs are primarily utilized for understanding and encoding information (discriminative) or for producing novel textual outputs (generative).



![Core LLM Integration Paradigms in Recommendation Systems](https://modelbest-prod.oss-cn-beijing.aliyuncs.com/SurveyGo/picture/HR5zlta0eAbeXUJ1B3ufg_Core%20LLM%20Integration%20Paradigms%20in%20Recommendation%20Systems.png)

Building upon this foundational classification, existing LLM integration works can be broadly categorized into three core modeling paradigms [3,18,21,22,24,26,28]:

1.  **LLM as Feature Enhancer (LLM Embeddings + RS)**: In this paradigm, LLMs primarily function as powerful feature encoders, generating dense, semantically rich embeddings for users and items [21,22,24]. These embeddings, extracted from various textual data associated with users and items (e.g., descriptions, reviews, queries), are then integrated into conventional recommendation models to augment their understanding of preferences and characteristics [1,15,21]. This approach predominantly aligns with **DLLM4Rec**, as it leverages LLMs' capabilities for deep semantic understanding and representation learning [21,24]. It aims to empower existing recommenders through LLM-driven representation learning rather than replacing them entirely, addressing issues like data sparsity and less informative representations [15].

2.  **LLM for Semantic Interpretation and Token Generation (LLM Tokens + RS)**: This paradigm leverages LLMs to generate meaningful semantic "tokens" or descriptive summaries that encapsulate potential user preferences or item characteristics through advanced semantic mining [21,22,24,26]. These generated tokens serve as enriched input features, integrated into the decision-making process, or utilized for similarity matching within the recommendation system. This approach primarily aligns with **GLLM4Rec**, as it capitalizes on the LLM's generative and summarization powers to provide richer contextual information for recommendation logic [21,24]. Examples include generating explanations, summarizing reviews, or producing descriptive textual content for items.

3.  **LLM as Direct Recommender (LLM as RS)**: This represents the most direct integration, where LLMs process input sequences (including user behaviors, preferences, and task instructions) to directly generate recommendation results, often in natural language format [1,21,22,24]. This paradigm fully harnesses the generative and comprehension capabilities of LLMs for end-to-end recommendation tasks. It explicitly aligns with **GLLM4Rec**, as the LLM directly produces the final recommendation output [21,24]. The LLM takes on roles such as a direct recommender through fine-tuning and specialized decoding strategies [7,17].

To effectively deploy LLMs across these paradigms, specialized **adaptation and tuning strategies** are indispensable [10,19]. These strategies, including pre-training, fine-tuning (both full-model and parameter-efficient methods), and various prompting techniques, aim to bridge the gap between LLMs' generic language understanding and the domain-specific nuances of recommendation tasks. These methodologies ensure that LLMs can learn user and item representations effectively and are adapted for diverse recommendation scenarios [1,10].

While offering significant advancements in personalization, explainability, and cold-start resolution, the integration of LLMs into recommendation systems also introduces several challenges. These include substantial `ComputationalCost`, the inherent `HallucinationRisk` of generative models, potential `DataBias` from training data, `ScalabilityIssue` with large models and long sequences, and the `PromptDesignComplexity` required for effective interaction [15,17]. Ongoing research continues to explore methods to mitigate these limitations, striving to maximize the potential of LLMs in delivering next-generation recommendation experiences. The subsequent subsections will delve into each of these paradigms and adaptation strategies in greater detail, providing specific examples and insights into their mechanisms, applications, and associated challenges.
### 3.1 Overarching Classification: Discriminative vs. Generative LLM Recommendation (DLLM4Rec vs. GLLM4Rec)
The integration of Large Language Models (LLMs) into recommendation systems (RS) can be broadly categorized into two primary paradigms: Discriminative LLMs for Recommendation (DLLM4Rec) and Generative LLMs for Recommendation (GLLM4Rec) [21,22,24,26]. This fundamental distinction is critical for understanding the diverse ways LLMs are leveraged within the recommendation domain, reflecting their inherent capabilities for either understanding and encoding information or for producing novel textual outputs [22,26].

**Discriminative LLMs for Recommendation (DLLM4Rec)** primarily utilize LLMs for deep semantic understanding and feature extraction [21,24,26]. In this paradigm, LLMs serve predominantly as "embedding backbones" or "embedding extractors," tasked with encoding rich textual information into meaningful numerical representations for users and items [18,19,21,22,24]. These models are typically based on encoder-only architectures, such as the BERT series (e.g., BERT, RoBERTa), which excel in Natural Language Understanding (NLU) tasks by learning bidirectional representations of input text [18,19,21,22,24]. The objective of DLLM4Rec is to align the LLMs' pre-trained knowledge with domain-specific recommendation data through adaptation strategies like fine-tuning or prompt tuning [18,21,22,24,26,27]. Examples include models like U-BERT and UserBERT for enhancing user representations by encoding reviews, UNBERT for news recommendation through browsed news text, and BERT4Rec for modeling masked user behaviors in sequential recommendation [19]. This approach aligns with the "LLM Embeddings + RS" paradigm [18,22].

Conversely, **Generative LLMs for Recommendation (GLLM4Rec)** leverage the powerful generative capabilities of LLMs to produce natural language outputs directly relevant to recommendation tasks [21,24,26]. This paradigm typically employs decoder-only LLMs, such as the GPT family (e.g., GPT-2, GPT-3, ChatGPT) and Llama, which are unidirectional (causal) transformers designed to autoregressively predict subsequent tokens [19,21,22,23,24,26]. GLLM4Rec models transform recommendation tasks into natural language generation problems, enabling them to move beyond mere item prediction to generate comprehensive explanations, personalized recommendations, and facilitate conversational interactions, thereby enhancing user trust and engagement [17,19,21,22,24,26]. Adaptation strategies often involve in-context learning, prompt tuning, and instruction tuning to enable direct generation of recommendation results or associated natural language text [18,19,21,22,24,26,27]. Notable examples include "GenRec: Large Language Model for Generative Recommendation" and "Prompt-based Generative News Recommendation (PGNR)" [23], NIR for generating movie recommendations, and GPTRec for sequential recommendation [19]. Generative models can also be employed for tasks like explanation generation (e.g., XRec, Li et al.) [17,19], item generation (e.g., D3), or optimizing personalized ranking by distinguishing preferred items (e.g., S-DPO) [17]. KERAG_R also suggests a generative approach for estimating user preferences [6]. This paradigm aligns with the "LLM Tokens + RS" and "LLM as RS" frameworks [18,22]. However, GLLM4Rec approaches may face challenges such as `HallucinationRisk` and `ComputationalCost` [22].

Beyond these two distinct categories, certain models exhibit a **Hybrid Role**, utilizing encoder-decoder LLM architectures (e.g., BART, T5) [19]. These models are capable of combining both feature encoding and structured output generation, optimized for tasks that require explicit input encoding prior to generation. Examples include UniTRec, which uses an encoder for user history representations and a decoder for perplexity-based matching scores, and P5, a multi-task framework for sequential recommendation, rating prediction, and review explanation/summarization [19]. This tripartite view provides a comprehensive classification framework for LLM-based recommendation systems.
### 3.2 LLM as Feature Enhancer (LLM Embeddings + RS)
The paradigm where Large Language Models (LLMs) primarily function as powerful feature encoders for recommendation systems is a significant area of research, often aligned with the **DLLM4Rec** framework [1,3,4,15,18,21,22,24,26,28]. In this approach, LLMs are leveraged to generate dense, semantically rich embeddings for both users and items, which are then integrated into conventional recommendation models.

LLMs achieve this by processing various forms of textual data associated with users and items. For instance, item descriptions, titles, product reviews, user queries, and historical interaction sequences serve as inputs [1,3,4,10,12,14,15,21,24,26]. These models, particularly discriminative language models like the BERT series, utilize their advanced contextual understanding capabilities to extract high-order semantic features, generating robust and context-aware embeddings [10,18,19,21,22,24]. For example, `NoteLLM` employs LLaMA 2 to produce embeddings for notes by constructing specific prompt templates, deriving these embeddings from the last hidden layer and processing them through an MLP layer [12]. Similarly, `LLM-ESR` generates semantic embeddings to enhance Sequential Recommendation Systems (SRS) [17]. Other methods like `RLMRec` utilize LLMs for user and item profiling, incorporating auxiliary text signals to generate high-quality semantic representations [11,15]. The conceptual representation for a user's profile vector, $\mathbf{u}$, can be formally expressed as:
$$ \mathbf{u} = \text{LLM}(\text{Item}_1, \text{Item}_2, \dots, \text{Item}_n) $$
where $\text{Item}_1, \dots, \text{Item}_n$ represent the sequence of items (or their textual descriptions) with which the user has interacted, allowing LLMs to extract high-order semantic features from these sequences to construct a vectorial representation of user interests [31]. The LANE framework, for instance, uses Sentence-BERT to encode item titles and user multi-preferences, initializing the embedding layer of sequential recommendation models with these semantic embeddings [9]. The GANPrompt framework further demonstrates this by using LLM encoders as generators within a generative adversarial training setup to produce diverse item descriptions, injecting LLM-embedded knowledge with attribute features for richer text representations [9]. Furthermore, `ReLLa`'s Semantic User Behavior Retrieval (SUBR) component enriches user behavior sequences by retrieving semantically similar items based on their textual descriptions, providing a more concentrated feature set for the LLM [5].

These LLM-generated embeddings are subsequently fed into established recommendation algorithms, such as collaborative filtering or deep learning models, to augment their understanding of user preferences and item characteristics [1,15,21,22,24,26,28]. This integration significantly improves recommendation accuracy and effectively addresses cold-start scenarios, particularly for new items or users who lack extensive interaction histories [18,22,24]. To ensure optimal performance, methods often involve joint training or fine-tuning strategies to align the LLM's semantic representations with the collaborative signals from traditional recommendation models. For instance, `RLMRec` introduces a cross-view alignment mechanism, theoretically grounded in mutual information maximization, to reconcile the semantic space derived from LLMs with collaborative relational signals [11,15]. `LLM-ESR` employs a dual-view modeling approach combined with retrieval-enhanced self-distillation to refine user preference representations without additional computational overhead [17]. Additionally, "The Elephant in the Room" proposes initializing item ID representations in ID-based sequential models with LLM-derived embeddings, leveraging LLM text understanding to provide richer, generalized initial representations and maximize LLM capabilities while maintaining the efficiency of ID-based models [7]. Other works such as `U-BERT`, `UserBERT`, and `BERT4Rec` exemplify how BERT-series models are utilized to enhance user or item representations and sequential modeling, by encoding review text, user behavior sequences, or by masked language modeling objectives [18,19,22].

This approach effectively leverages the LLM's sophisticated semantic capabilities to provide richer feature representations, thereby enhancing the performance of existing recommendation algorithms. It enables a deeper understanding of explicit and implicit user feedback from unstructured data, moving beyond traditional discrete ID-based systems [10,14]. While benefiting from improved contextual understanding and enhanced cold-start resolution, this paradigm faces challenges such as the significant computational cost associated with running and fine-tuning large LLMs [10,18,19,22,28], potential data bias inherited from the textual training data [19,22], and the complexity of aligning features across different views [15]. Despite these limitations, the integration of LLM-generated embeddings into traditional recommendation systems represents a powerful avenue for advancing personalization and recommendation quality.
### 3.3 LLM for Semantic Interpretation and Token Generation (LLM Tokens + RS)
This paradigm leverages Large Language Models (LLMs) to generate meaningful semantic "tokens" or descriptive summaries, which encapsulate potential user preferences or item characteristics through advanced semantic mining [3,18,21,22,24,26,28]. This approach is a prominent facet of Generative LLM for Recommendation (GLLM4Rec) and highlights the LLMs' inherent capabilities in generation and summarization to provide richer contextual information for recommendation logic. The generated tokens, derived from user interactions, item features, or other input features, serve as enriched input features, are integrated directly into the decision-making process, or are utilized for similarity matching within the recommendation system [3,18,21,22,24,26].

The core mechanism involves LLMs processing raw or structured input to produce concise, semantically rich outputs. For instance, the LANE framework employs zero-shot prompting templates with powerful LLMs like GPT to extract multiple preferences from a user's historical interaction sequence [9]. These extracted preferences, being natural language descriptions, are subsequently semantically embedded to capture complex user interests, represented as $e_{pref} = E(\text{GPT}(\text{Prompt with Historical Interaction Sequence}))$ [9]. This demonstrates how LLMs can interpret and summarize user behavior into meaningful semantic tokens. Similarly, ReLLa utilizes Semantic User Behavior Retrieval (SUBR) to identify items semantically akin to those in a user's history, where the titles or genres of these retrieved items function as "tokens" to guide the LLM's interpretation of user behavior, providing a focused and semantically rich context for preference identification [5]. Some research also proposes using LLMs to generate textual descriptions for users as "auxiliary information" to be incorporated into existing recommendation models [1].

In terms of item feature enrichment, LLMs can generate descriptive textual content or "tokens" that summarize product attributes or user preferences, thereby enhancing item representation [14]. For example, NoteLLM employs LLaMA 2 to generate explicit categories and tags for notes, which serve as semantic tokens to enrich item content representation, though the overall improvement in recommendation performance from this specific task might not be substantial [12]. Ant Group's work illustrates an advanced approach where LLMs generate additional textual knowledge for a given item, which is then encoded and fused with the item's original ID embedding. A notable innovation here is modeling a distribution to sample only recommendation-effective information from the LLM-generated text, mitigating the risks of irrelevant or noisy outputs, such as `HallucinationRisk` and `DomainKnowledgeGap` [7].

Beyond direct user or item representations, LLMs are also instrumental in generating semantic content for tasks such as explanation generation and review summarization, demonstrating their robust capabilities in semantic interpretation [13]. XRec, for example, integrates collaborative signals from traditional recommendation systems with LLMs via lightweight adapters to generate comprehensive textual explanations for recommendations, surpassing the capabilities of conventional explainable recommendation systems [17].

Furthermore, this paradigm facilitates the integration of external knowledge. The KERAG_R model enhances LLM instructions by incorporating information from knowledge graphs through a Graph Retrieval-Augmented Generation (GraphRAG) component. A pre-trained Graph Attention Network (GAT) within GraphRAG selects the most relevant triples, refining the semantic input for the LLM and enabling it to better understand user preferences by combining text-based interactions with structured knowledge [6]. This approach also extends to augmenting user-item interactions, where LLMs generate text-based or score-based data to enrich interaction signals, exemplified by models like `LLMRec`, `LlamaRec` (text-based), and `LLM-InS` (score-based) [4].

The effectiveness of this paradigm also lies in its ability to bridge semantic gaps. CLLM4Rec addresses the disparity between natural language and recommendation tasks by extending the LLM's vocabulary with user/item ID tokens and employing a soft+hard prompting strategy. This enables stable and efficient language modeling on recommendation-specific corpora, allowing LLMs to generate recommendations without spurious information [11]. Similarly, the "Recommendation as Language Processing (RLP)" framework, such as P5, unifies diverse recommendation tasks into a language processing paradigm, fundamentally relying on semantic interpretation by LLMs [23].

While this paradigm offers significant advantages in leveraging LLMs' generative and summarization powers, it faces challenges such as the `ComputationalCost` associated with running LLMs and potential `DataBias` in their training data [28]. Moreover, `HallucinationRisk` and `ConsistencyIssue` remain concerns, particularly when LLMs are tasked with generating explanations or knowledge, requiring careful mitigation strategies [7,17]. In contrast to approaches where LLMs primarily serve as feature encoders or direct recommenders, this paradigm emphasizes the generation of distinct, semantically rich tokens that act as intermediate representations, providing a nuanced understanding of user and item characteristics before final recommendation decisions [15,19,31].
### 3.4 LLM as Direct Recommender (LLM as RS)
The paradigm of Large Language Models (LLMs) acting as direct recommenders, often referred to as LLM as RS, represents the most straightforward integration of LLMs into recommendation systems and primarily aligns with Generative LLM for Recommendation (GLLM4Rec) [1,3,18,21,22,24,26,28]. In this approach, LLMs process input sequences that include summary descriptions, user behavior prompts, and explicit task instructions to directly generate recommendation results, frequently in natural language format [1,3,18,19,21,22,24,26,28]. This direct application harnesses the generative and comprehension capabilities of LLMs for end-to-end recommendation tasks.

A core mechanism for LLMs operating as direct recommenders involves scoring candidate items by computing the log likelihood of an item name (suffix) given a preference-based natural language prefix [20]. This allows the LLM to implicitly rank items based on its understanding of the provided textual context. Frameworks like ReLLa adapt pure LLMs to perform zero-shot and few-shot recommendations by formatting user behavior sequences and retrieval-enhanced information into natural language prompts, enabling the LLM to directly score and recommend items based on these textual inputs [5]. Similarly, P5 (Recommendation as Language Processing) and M6-Rec unify various recommendation tasks into a token generation paradigm, converting all user and item features into text for an LLM to generate recommendations [8,12,23]. Another notable approach involves fine-tuning LLMs with item IDs integrated as unique tokens into the vocabulary, allowing the model to directly generate these IDs as recommendations, as explored by WeChat's method which bypasses traditional candidate generation and ranking stages [7].

Experimental setups to test this direct application often involve various item ranking methods. These include point-wise ranking, where the LLM scores each item individually; pair-wise ranking, where the LLM compares two items to determine preference; and list-wise ranking, where the LLM is directly tasked with sorting a given list of items [1]. Studies have utilized LLMs such as ChatGPT, text-davinci-002, and text-davinci-003, evaluating their performance with metrics like NDCG and MRR on datasets including MovieLens and Amazon [1]. Few-shot prompting generally demonstrates superior performance compared to zero-shot, though both approaches often outperform random or popularity-based baselines [1]. List-wise ranking has been shown to offer the highest improvements per unit cost, making it the most economical ranking method, despite ChatGPT's general superiority in this paradigm [1].

The implications of this direct application include the potential for generating highly personalized and explainable recommendations [1,19,22]. LLMs can leverage their broad world knowledge and natural language capabilities to offer explicit textual explanations for their choices, enhancing user trust and transparency [1]. Furthermore, this paradigm excels in cold-start scenarios, where LLMs can make competitive recommendations even with limited user-item interaction data by leveraging language-based preferences and their extensive pre-trained knowledge in zero-shot or few-shot settings [1,19,20]. For instance, a 62-billion parameter PaLM variant demonstrated competitive NDCG@10 scores in near cold-start movie recommendations using language-based preferences, rivaling traditional item-based collaborative filtering methods [20].

Despite these advantages, the LLM as RS paradigm faces significant challenges, particularly concerning precision and factual accuracy. The requirement for high precision is paramount, as LLMs directly generate the final recommendation output [3,28]. A critical concern is the `HallucinationRisk`, where LLMs may generate plausible but incorrect, non-existent, or irrelevant items [1,8,10,19,22]. For example, while ChatGPT can generate multi-step travel recommendations, it has also produced incorrect book titles and authors in zero-shot book recommendation tasks [10]. Other limitations include significant `ComputationalCost` due to the size of LLMs and the number of calls required for ranking methods like point-wise and pair-wise, and `ScalabilityIssue` when attempting to scale to very long item lists [1,8,19,22]. `PromptDesignComplexity` is another challenge, as the effectiveness of recommendations is highly sensitive to prompt formulation, and adding too much information can introduce noise and degrade performance [1,19,22]. Additionally, recommendations based primarily on similarity to previously purchased items can lead to `HomogeneityIssue` and `DataBias`, limiting diversity [8].

Researchers are actively developing methods to mitigate these challenges. For instance, KERAG_R integrates knowledge graph information into LLM instructions via a GraphRAG component to reduce inaccuracies and hallucinations caused by a lack of domain-specific knowledge [6]. To address `amplification bias` and `homogeneity issues` in LLM-based item generation, D3 proposes a novel decoding method that disables 'ghost tokens' and introduces a text-free auxiliary model to encourage the generation of less frequent tokens [17]. For personalized ranking, S-DPO directly optimizes LLM behavior by integrating `Direct Preference Optimization (DPO) loss` with multiple negative samples and a softmax sampling strategy, enabling LLMs to better distinguish between preferred and non-preferred items [17].

Evaluating the current state of LLMs as standalone recommenders, studies indicate they possess "moderate skill" in accuracy-based tasks such as Rating Prediction, Sequential Recommendation, and Direct Recommendation when benchmarked by systems like LLMRec [13]. While they consistently outperform simple baselines like Random and Popularity, particularly excelling in near cold-start scenarios by leveraging language-based preferences [1,20], their general performance against highly optimized traditional recommendation models remains an area of active research and improvement. The "Actions Speak Louder than Words" work by Meta, which achieved state-of-the-art results in a large-scale industrial setting by modeling heterogeneous sequences and optimizing attention, suggests a promising future direction for direct LLM recommendations, despite requiring substantial computational resources and engineering expertise [12]. This highlights that while LLMs offer unique advantages in personalization, explainability, and cold-start resolution, the `PrecisionRequirement`, `ComputationalCost`, and `HallucinationRisk` necessitate continued research and specialized solutions to realize their full potential as standalone recommenders.
### 3.5 LLM Adaptation and Tuning Strategies
The effective deployment of Large Language Models (LLMs) in recommendation systems necessitates specialized adaptation and tuning strategies to bridge the gap between their generic language understanding capabilities and the domain-specific nuances of user preferences, item attributes, and interaction patterns [19,28]. This section systematically categorizes and explains the prevalent adaptation techniques, detailing their core mechanisms, typical applications in recommendation, and reported benefits or limitations [3,10,12,17,18,26]. These strategies are broadly classified into three main paradigms: pre-training, fine-tuning, and prompting [1,10,17,18,21,22,24,26,27,28].

**Pre-training LLMs for Recommendation** involves either initializing LLMs from scratch on recommendation-specific datasets or further pre-training existing generic LLMs to imbue them with domain knowledge. This process is crucial for developing Dually Large Language Models for Recommendation (DLLM4Rec) by learning inherent item similarities, user preferences, and interaction patterns, thereby enhancing their understanding of the recommendation context [3,10,18].

**Fine-tuning LLMs for Recommendation** adapts pre-trained LLMs to specific recommendation tasks by optimizing their parameters on targeted datasets. This strategy is essential for integrating the LLM's vast external knowledge with personalized user preferences, addressing challenges such as cold-start scenarios [18,21,22,24]. Fine-tuning methods are broadly divided into full-model fine-tuning, which adjusts all LLM parameters, and Parameter-Efficient Fine-tuning (PEFT), which selectively modifies a smaller subset of parameters or introduces new trainable components, balancing performance gains with computational cost and resource demands [7,10,19].

**Prompting LLMs for Recommendation** encompasses methods that guide the LLM's behavior through carefully constructed textual inputs without extensive parameter updates. This paradigm is instrumental in leveraging the LLM's pre-trained knowledge for diverse recommendation scenarios, particularly supporting Generative LLM-based Recommender Systems (GLLM4Rec) and, to a lesser extent, DLLM4Rec for prompt-based feature extraction [12,21]. The evolution of prompting techniques ranges from simple template-based prompts to more sophisticated In-Context Learning (ICL) and instruction tuning [3,10,18]. This evolution enables LLMs to adapt to diverse tasks, provide strong zero-shot and few-shot capabilities, and generate explainable recommendations, albeit with challenges related to prompt design complexity, hallucination risk, and scalability [5,10,19].

Across all these adaptation strategies, a central theme is the continuous effort to enhance the LLMs' domain understanding, personalize recommendations, and overcome limitations inherent in generic models. The choice among pre-training, fine-tuning, and prompting often involves weighing performance requirements against computational resources and the specific characteristics of the recommendation task at hand [7,14]. While pre-training and full fine-tuning often contribute to building robust underlying models for both DLLM4Rec and GLLM4Rec, parameter-efficient fine-tuning and various prompting techniques are crucial for making these powerful models practical, adaptable, and efficient, especially for generative applications and addressing cold-start problems [22,26]. The interplay between these strategies drives ongoing research and development in leveraging LLMs for next-generation recommendation systems.
#### 3.5.1 Pre-training LLMs for Recommendation
The adaptation of Large Language Models (LLMs) for recommendation systems frequently involves either initiating their pre-training from scratch on recommendation-specific data or further pre-training existing generic LLMs to imbue them with domain-specific understanding [3,10,18]. This process is pivotal for developing effective Dually Large Language Models for Recommendation (DLLM4Rec) approaches, allowing LLMs to learn item similarities, user preferences, and interaction patterns inherently present in recommendation datasets [8].

The objectives of such pre-training often draw parallels with established NLP tasks, leveraging the architectural strengths of Transformer-based models. Common objectives include masking items within user behavior sequences and subsequently predicting the masked elements, analogous to the Masked Language Modeling (MLM) task in BERT [10,19]. Another prevalent objective is forecasting the next item(s) in a sequence based on preceding behaviors, which mirrors the causal language modeling objectives seen in GPT-like architectures [10,19].

A prominent framework that exemplifies these pre-training methods is **PTUM**, which proposes two analogous approaches: masking a user behavior within a sequence for prediction based on context, and predicting the next 'k' behaviors from historical interactions [10]. This directly adapts NLP masking and next-token prediction strategies to user behavior sequences, aiming to enhance user and item representations. Similarly, **BERT4Rec** trains BERT with an objective akin to MLM, specifically masking user behaviors in interaction sequences to allow items to integrate information from both sides of the sequence, with the last behavior masked during testing for next-item prediction [1,19]. **GPTRec** also employs standard language modeling objectives, optimized with cross-entropy loss, following the GPT-2 paradigm [19].

Beyond these foundational adaptations, more sophisticated pre-training methodologies have emerged to address specific challenges in recommendation. The **P5 (Recommendation as Language Processing - RLP)** framework stands out by framing diverse recommendation tasks, including sequential recommendation, rating prediction, explainable recommendation, and review summarization, as unified language processing tasks [3,28]. P5 utilizes a pre-trained T5 model as its backbone and is further pre-trained on scene-specific data, employing a single model structure during this phase. It then uses different prompt templates for personalized inference across various tasks, achieving a high degree of unification and demonstrating strong performance across datasets [3,8,28]. This approach aligns with the concept of adapting pre-trained LLMs through specialized pre-training and prompting strategies [23].

For aligning heterogeneous modalities, **FLIP** proposes a two-stage pre-training alignment process to bridge ID-based models and pre-trained language models for CTR prediction [4,7]. The first stage involves an MLM-like task where parts of both text and ID representations of features are masked, and the model attempts to reconstruct them using contextual information from both modalities. The second stage employs contrastive learning, treating ID and text representations of each sample as positive pairs to pull them closer in the embedding space. This aims for fine-grained alignment but incurs significant computational costs and complexity in balancing the objectives [7].

Other notable approaches focus on enhancing user and item representations:
*   **CLLM4Rec** extends the vocabulary of a pre-trained LLM with user/item ID tokens to accurately model collaborative and content semantics. It then performs language modeling on an RS-specific corpus, structured with prompts and item/vocab tokens, to learn effective user/item token embeddings [11].
*   **RLMRec** integrates representation learning and LLMs through a cross-view alignment mechanism. This technique aligns the LLM's semantic space with collaborative relational signals from traditional recommendation systems, theoretically maximizing mutual information to improve the quality of learned representations [11,15].
*   **CTRL** employs a two-stage training approach to inject LLM knowledge into a ranking model. The initial stage aligns the embedding representations of traditional models and LLMs, converting traditional model samples into LLM-compatible prompts, followed by traditional supervised learning [12].
*   **UserBERT** utilizes self-supervised tasks like medium-difficulty contrastive learning, masked behavior prediction, and behavior sequence matching to train accurate user representations by capturing intrinsic user interests and relevance. This method can be applied to various models like BERT4Rec, NRMS, or GRU4Rec through joint pre-training with a combined loss [19,21].
*   **UniSRec** develops a BERT fine-tuning framework that associates item description text to learn transferable representations across different recommendation scenarios [21,24].

The design choices for pre-training, such as different masking strategies or prediction targets, critically influence the model's understanding of user preferences and item characteristics. For instance, masking specific items in a user's historical sequence helps the model infer preferences based on context, while predicting future behaviors directly models sequential patterns. The unification of tasks in P5 demonstrates how a single pre-training paradigm can capture diverse recommendation facets. Approaches like FLIP emphasize the importance of aligning textual and ID-based representations to leverage both semantic richness and collaborative signals effectively.

It is important to distinguish these pre-training efforts from methods that merely leverage pre-trained LLMs as fixed feature extractors. For example, the LANE framework uses Sentence-BERT as a text encoder for item titles and user preferences, but this involves leveraging the pre-trained capabilities of these models for semantic embedding rather than pre-training LLMs specifically for recommendation tasks from scratch or through specialized adaptation [9,22]. The core distinction lies in the specialized pre-training tasks and methodologies designed to adapt LLMs *for* the recommendation domain, moving beyond their generic language understanding capabilities. However, these specialized pre-training processes often incur significant computational costs [7,10,19].
#### 3.5.2 Fine-tuning LLMs for Recommendation
Fine-tuning serves as a pivotal strategy for adapting pre-trained Large Language Models (LLMs) to the specialized requirements of recommendation systems [21,22,26]. This process involves initializing an LLM with its extensive learned parameters and subsequently training it on recommendation-specific datasets, such as user-item interactions, item textual descriptions, and user profiles [18,19,21,22,24,26]. The primary objective of fine-tuning is to integrate the LLM's vast external knowledge with personalized user preferences, thereby enhancing recommendation accuracy and addressing challenges like cold-start scenarios for new items or users [18,21,22,24].

Broadly, fine-tuning approaches for LLMs in recommendation can be categorized into full-model fine-tuning and parameter-efficient fine-tuning (PEFT), each presenting distinct trade-offs between performance, computational cost, and practicality [10,19].

**Full-Model Fine-tuning**

Full-model fine-tuning involves adjusting all parameters of a pre-trained LLM on recommendation-specific data [10,19,22]. This comprehensive approach allows the model to deeply specialize in the target task, potentially leading to superior performance by fully leveraging its vast capacity [10,22]. For instance, models like RecLLM and GIRL utilize full-model supervised fine-tuning for conversational YouTube video recommendations and job-finding applications, respectively [10]. P5, for example, employs multi-task instruction fine-tuning based on T5 checkpoints to create a unified recommendation system capable of handling tasks such as sequential recommendation and rating prediction, demonstrating zero-shot generalization capabilities [19]. Kang et al. similarly applied full fine-tuning to FLAN-T5 models for rating prediction, achieving performance comparable to traditional recommender systems [19]. Other examples include UNBERT for news recommendation and frameworks by Penha and Hauff or UnitRec/UniMIND for conversational recommendation, all relying on fine-tuning BERT or BART to infuse knowledge or predict relevance [19].

Despite its potential for high performance, full-model fine-tuning is characterized by significant computational costs and demanding resource requirements, particularly for very large models [7,10,18,19,22]. The process of updating billions of parameters makes it resource-intensive and presents scalability challenges, limiting its practical application in many real-world recommendation scenarios [10,19]. For instance, a practical experiment involved fine-tuning an open-source T5-large model for recommendation, underscoring the computational effort involved [8].

**Parameter-Efficient Fine-tuning (PEFT)**

Parameter-Efficient Fine-tuning (PEFT) addresses the computational and scalability limitations of full-model fine-tuning by modifying only a small subset of model weights or by introducing new, trainable components while keeping the majority of the pre-trained LLM parameters frozen [10,19]. This approach allows LLMs to achieve comparable performance with significantly fewer trainable parameters, making them more accessible and practical for various recommendation tasks [10,17,19].

Several techniques fall under the PEFT paradigm:
*   **Low-Rank Adaptation (LoRA)**: A prominent reparameterization method, LoRA approximates the weight update matrix $\Delta W$ with a product of two low-rank matrices, $A \in \mathbb{R}^{d \times r}$ and $B \in \mathbb{R}^{r \times k}$, where $r \ll \min(d, k)$. The update formula is given by $h = (W + \Delta W)x = (W + AB)x$ [19]. This significantly reduces the number of trainable parameters. Examples include iLoRA, which employs instance-wise LoRA combined with a Mixture-of-Experts (MoE) framework to customize LLMs for sequential recommendation and mitigate negative transfer by dynamically adapting to diverse behavioral patterns [17]. TALLRec utilizes instruction-based LoRA on models like LLaMA-7B, allowing operation on single high-performance GPUs like an RTX 3090, a notable efficiency improvement over full-model approaches [12,19]. The GANPrompt framework also explicitly uses LoRA for efficient adaptation to recommendation tasks [9].
*   **Adapters and Prompt Tuning**: Additive methods like prompt tuning introduce new trainable components. Prompt tuning involves learning "soft prompts"â€”learnable embedding vectors prepended to input embeddingsâ€”which are optimized while the LLM's core parameters remain frozen [19,21]. Li et al. employed a two-stage sequential tuning strategy beginning with prompt tuning to bridge the gap between randomly initialized prompts and pre-trained LLM parameters [19]. Cui et al.'s "Option Tuning," an enhanced prompt tuning method, achieved better performance than full fine-tuning while reducing trainable parameters to approximately 1% [19].
*   **Instruction Tuning**: This variant involves fine-tuning LLMs on multiple tasks under various instructions to improve generalization and performance [21]. TALLRec, for example, focuses on instruction fine-tuning using LoRA to adapt open-source LLMs for recommendation [12]. S-DPO fine-tunes LLMs by converting historical interactions into text instructions and targeting positive item samples [17]. BEQUE utilizes multi-instruction supervised fine-tuning to construct rewriting datasets and fine-tune LLMs for candidate generation [11]. ReLLa employs retrieval-enhanced guided tuning (ReiT), which augments training samples with retrieved semantic user behaviors to enhance few-shot recommendation performance, sometimes outperforming traditional CTR models with significantly less data [5,11].

**Trade-offs and Practical Considerations**

The choice between full-model fine-tuning and PEFT involves weighing performance gains against computational resources. Full-model fine-tuning can potentially achieve higher performance due to its complete parameter adjustment, but at a substantial cost in terms of GPU memory and training time [10,19]. Conversely, PEFT significantly reduces computational overhead and memory footprint, making it a more practical solution for deploying LLMs in recommendation systems, especially with limited resources or very large base models [10,19]. While PEFT may entail minor performance trade-offs compared to its full-model counterpart, its efficiency often makes it the preferred approach for enabling LLMs in resource-constrained environments [10]. The complexity of prompt design and the potential computational cost of retrieval mechanisms, such as those in ReLLa, represent new challenges introduced by some PEFT methods [5,17].

**Fine-tuning BERT-like Models for Specific Recommendation Tasks**

Beyond the general distinction between full and parameter-efficient fine-tuning, specific approaches have been developed to adapt BERT-like models for various recommendation tasks, primarily focusing on learning representations, improving re-ranking, and addressing lexical mismatch.

*   **User Representation**: U-BERT learns user representations by augmenting user features with content-rich domain data and utilizes a review co-matching layer to capture implicit semantic interactions between user and item reviews [18,21,22,24,26]. Similarly, UserBERT enhances user modeling through self-supervised tasks like masked behavior prediction and behavior sequence matching, aiming to capture intrinsic user interests and relationships [18,21,22,24].
*   **Re-ranking and Lexical Mismatch**: BECR proposes a lightweight composite re-ranking scheme that integrates deep contextual token interactions with traditional lexical matching features. It uses pre-computable token embeddings to efficiently approximate query representations, balancing relevance and efficiency [18,21,22,24,26]. For product ranking, Wu et al. developed an end-to-end multi-task learning framework that fine-tuned domain-specific BERT to resolve lexical mismatches between queries and products, employing expert mixture layers and probabilistic transitions [21,24].
*   **Sequential and Content-based Recommendation**: Fine-tuning is also crucial in models like BERT4Rec and RESETBERT4Rec for sequential recommendation, though these mainly leverage specific training strategies [18,21,22]. For content-based recommendation, particularly in news, models such as NRMS, Tiny-NewsRec, and PREC utilize fine-tuned LLMs to address domain transfer issues and reduce transfer costs [18,21].

In summary, fine-tuning is an essential technique for adapting LLMs to recommendation tasks, allowing the integration of their broad language understanding with specific domain knowledge and user preferences. The continuous development of PEFT methods promises to make these powerful models more accessible and efficient for a wider range of recommendation applications, balancing high performance with reduced computational demands.
#### 3.5.3 Prompting LLMs for Recommendation
Prompting techniques serve as a cornerstone for adapting Large Language Models (LLMs) to recommendation tasks, primarily by guiding their behavior through carefully constructed text inputs without extensive parameter updates [12,21]. These methods are instrumental in leveraging the LLM's pre-trained knowledge for diverse recommendation scenarios, predominantly supporting **Generative LLM-based Recommender Systems (GLLM4Rec)** and, to a lesser extent, **Discriminative LLM-based Recommender Systems (DLLM4Rec)** for prompt-based feature extraction.

**Conventional Prompting** involves the deliberate design of specific text-based instructions or templates, often referred to as prompt engineering, to elicit desired outputs from LLMs [19]. This approach transforms various recommendation tasks, such as review summarization, into text generation problems, where the LLM is instructed to "Write a short sentence summarizing..." [10,21]. Studies have explored prompt engineering for evaluating LLM capabilities in recommendation, as demonstrated by early work assessing ChatGPT's performance across five distinct recommendation scenarios solely through prompt design [28] and analyzing its information retrieval (IR) capabilities for point-wise, pair-wise, and list-wise ranking tasks [28]. Such prompts often incorporate user preferences, item attributes, and specific role indicators, for instance, "You are now a news recommendation system," to enhance domain adaptation [21,22]. To manage the limited input token count for long user histories or candidate lists, strategies like sliding window prompting have been introduced [18,21]. Furthermore, prompts are utilized for feature generation, where LLMs generate user preference keywords, item content features, or representative items to enrich recommendation inputs [18,21]. LLMs can also act as system controllers, orchestrating interactive recommendation frameworks like ChatREC or making decisions on whether to recommend existing items or generate new ones via AIGC models [18,21]. An example of a structured prompt for extracting user preferences is found in LANE, which comprises Task, Role, Requirements, Standard Template, and Historical Interaction Sequence components to guide GPT in generating explainable recommendations [9]. Similarly, P5 transforms diverse recommendation tasks into unified natural language sequences [8,12].

**In-Context Learning (ICL)** capitalizes on an LLM's ability to learn from contextual examples provided within the prompt itself, without requiring any parameter updates [3,26]. This paradigm includes:
*   **Zero-shot ICL**, where no examples are provided, and the LLM relies entirely on its pre-trained knowledge to fulfill instructions [10,19]. While some studies on zero-shot rating prediction with LLMs like ChatGPT have shown underperformance compared to traditional recommenders [19], others have demonstrated its competitiveness for movie recommendations in scenarios with very low user counts [19].
*   **Few-shot ICL**, which involves including a small number of input-output examples within the prompt to guide the LLM's behavior [1,20]. This approach typically outperforms zero-shot and completion prompting, as observed in studies where few-shot (e.g., 3 examples) yielded superior NDCG@10 scores compared to zero-shot and completion [20]. Few-shot ICL has shown performance comparable to heuristic-based methods for rating prediction and is effective in competitive near cold-start recommendations [19]. ICL's performance generally surpasses Zero-Shot Learning and enables new avenues for few-shot learning [3].
A significant advancement within ICL is **Chain-of-Thought (CoT) prompting**, which enhances LLM performance on complex, multi-step tasks by explicitly incorporating intermediate reasoning steps into the prompt [10]. This can be applied in a zero-shot manner (e.g., "Let's think step by step") or a few-shot manner (manually designing reasoning steps for examples), empowering LLMs to decompose complex decisions [10]. LANE employs a Chain-of-Thought prompting template to guide GPT in generating accurate and explainable recommendation narratives [9].
Despite its strengths, ICL faces limitations such as a heightened `HallucinationRisk` if prompts are imprecise, potentially leading to irrelevant or factually incorrect outputs [5,19]. The `PromptDesignComplexity` is considerable, and the optimal selection and quantity of demonstration instances remain open research questions, as increasing examples or historical items does not invariably lead to better results and can even introduce noise [1,26].

**Prompt Tuning** presents an alternative to full fine-tuning, where recommendation tasks are reframed to align with the LLM's pre-training objectives through specially designed prompts. This involves optimizing either **hard prompts** (discrete text templates) or **soft prompts** (learnable embedding vectors prepended to input embeddings), while keeping the core LLM parameters frozen [10,21]. These prompts often utilize verbalizers to map the LLM's predicted vocabulary to specific labels or actions, ensuring coordination between the language model and the recommendation task [21,26]. Prompt tuning can leverage the LLM's pre-training heads, such as Masked Language Modeling (MLM) or Next Sentence Prediction (NSP), to infer item types or assess item relatedness. For instance, Penha and Hauff (2020) used BERT's MLM and NSP heads with cloze-style prompts to reveal its understanding of item characteristics and relevance without fine-tuning [19,24]. Prompt4NR transformed news recommendation into a fill-in-the-blank mask prediction problem, achieving significant performance improvements by carefully designing personalized prompt templates and answer spaces [12,28]. GANPrompt employs a GAN-based framework to generate "diversity prompts" by summarizing multi-dimensional attribute information using masked language model prediction tasks: $P(Attr | X) = \sum_{mask \in M} P(mask | X)$ [9]. Models like TALLRec, GenRec, PBNR, UniCRS, and M6-Rec (through "option tuning") implement prompt tuning for various recommendation tasks, including rating prediction and item generation [12,18]. While soft prompt tuning is more amenable to continuous optimization, it often suffers from `LossOfInterpretability`, whereas hard prompt tuning faces challenges in `DiscreteOptimization` and `PromptDesignComplexity` [10]. ClickPrompt utilizes intermediate embeddings from traditional CTR models as prompts for LLMs, effectively transferring knowledge and aligning ID-based models with LLMs, but this also introduces `ComputationalCost` and `PromptDesignComplexity` [7].

**Instruction Tuning** involves fine-tuning LLMs on a diverse set of tasks, each presented with various instructions. This process aims to enhance the LLM's zero-shot generalization capabilities and improve its alignment with human intent [5,26]. The methodology typically includes an instruction (prompt) generation stage, where task-oriented inputs and desired outputs are formatted into natural language instructions, followed by a model tuning stage where the LLM is fine-tuned using these instruction-output pairs [10]. Notable examples include P5 fine-tuning T5 models on five instruction types for recommendation tasks, and GBERT fine-tuning FLAN-T5-XL with 39 instruction templates, which yielded competitive zero-shot results against models like GPT3.5 [18,22]. InstructRec, leveraging a 3B Flan-T5-XL backbone, allows users to express preferences in natural language instructions that LLMs can understand and execute [28]. ReiT (Retrieval-enhanced Instruction Tuning) within the ReLLa framework further refines this by constructing prompts with augmented training examples, improving their effectiveness by making the input context more comprehensible through semantic retrieval [5].

A **well-constructed prompt** for recommendation typically comprises a clear task description, demonstration examples for few-shot learning, and a new input query [1]. Liu et al. (2023a) proposed a general prompt construction framework featuring a task description (adapting RS to NLP tasks), behavior injection (incorporating user-item interactions), and a format indicator (constraining output format) [18,21]. The impact of these components is significant; while few-shot prompting generally outperforms zero-shot, experimental analysis reveals that simply increasing the "number of prompt shots" or "number of history items" does not guarantee better results, as it can introduce additional noise that negatively impacts performance [1].

The **effectiveness** of prompt-based methods lies in their ability to avoid or minimize model parameter updates, significantly reducing `ComputationalCost` compared to full fine-tuning [19,22]. They offer remarkable flexibility, adapting LLMs to diverse tasks and enabling strong zero-shot and few-shot capabilities, which are particularly valuable for `ColdStartResolution` [20,26]. Prompting has demonstrated potential in various ranking methods, with `list-wise ranking` being noted for its cost-effectiveness [28]. The use of Chain-of-Thought prompting empowers LLMs to engage in step-by-step reasoning for complex decisions [10], and prompt-based methods can also generate detailed explanations for recommendations [9]. Furthermore, prompting can be enhanced with contextual information, such as entity-centric user knowledge stores, for personalized query suggestions [11], and specialized prompts leveraging knowledge graphs can enrich LLM context with domain-specific knowledge to estimate user preferences [6].

However, these methods also come with notable **limitations**. The `PromptDesignComplexity` is a major challenge, as the quality and effectiveness are highly sensitive to prompt design, often requiring tedious trial-and-error [19,20]. The `HallucinationRisk` is prevalent, where LLMs may produce incorrect rankings, irrelevant outputs, or even refuse to answer despite clear instructions [5,19]. `ScalabilityIssue` arises from the context window limits, restricting the length of user histories or candidate lists that can be included in a single prompt [19]. Moreover, conventional few-shot prompting can suffer from `LimitedEffectiveness` due to the inherent gap between general language generation and specific recommendation tasks [10]. For prompt tuning, hard prompts face `DiscreteOptimization` challenges, while soft prompts often lead to `LossOfInterpretability` [10]. In specific cases, zero-shot ICL for rating prediction has been observed to underperform traditional recommendation systems [19]. These limitations highlight that while prompting techniques unlock significant potential for LLMs in recommendation, especially for specialized tasks where traditional prompts might be insufficient, their practical application demands meticulous engineering and a thorough understanding of their trade-offs.
## 4. Applications and Advanced Topics of LLMs in Recommendation
This section provides a comprehensive exploration of cutting-edge research and specialized applications of Large Language Models (LLMs) within the recommendation domain. It synthesizes findings from recent conference papers and highlights prominent open problems and potential application areas for future exploration, often outlined in research agendas or workshop calls [14,17].

The discussion is structured into two primary categories, each detailing distinct yet complementary avenues where LLMs are making significant advancements. The first category, **LLMs for Enhanced Recommendation Tasks**, delves into how these models are fundamentally transforming core recommendation functionalities. It examines their application in improving areas such as explainable recommendation, sequential recommendation, cold-start and long-tail scenarios, and conversational recommendation systems [13,17]. This part highlights how LLMs' advanced natural language understanding (NLU), natural language generation (NLG), and extensive world knowledge provide novel solutions for challenges like transparency, dynamic user interaction, and robust performance in data-sparse environments.

The second category, **LLMs for Specific Recommendation Scenarios**, focuses on the role of LLMs in addressing more intricate and specialized challenges within recommendation systems. This includes their application in enhancing user profile management through richer semantic understanding and dynamic updates, enabling multi-modal and graph-enhanced recommendations by integrating diverse data types and knowledge graphs, optimizing preference alignment for more personalized ranking, and their practical deployment in domain-specific contexts such as e-commerce [4,14].

For each sub-section within these categories, a systematic analysis will be provided, detailing the specific problem it addresses, the proposed LLM-based solution, and an evaluation of its technical innovations and contributions [17]. Methodologies and results will be critically compared to highlight the spectrum of approaches and their impact on system performance or their efficacy in addressing particular challenges. Furthermore, this section will synthesize prevalent open problems and identify promising application areas for future exploration, often drawing insights from research agendas and workshop calls [5,14]. Recurring challenges such as `ComputationalCost`, `Latency`, `HallucinationRisk`, `ConsistencyIssue`, `LongSequenceHandling`, `DataBias`, and `DomainKnowledgeGap` will be discussed as overarching themes that require continuous research and mitigation strategies to fully realize the transformative potential of LLMs in recommendation systems.
### 4.1 LLMs for Enhanced Recommendation Tasks
Large Language Models (LLMs) are profoundly reshaping the landscape of recommendation systems by augmenting their capabilities across various core tasks and addressing long-standing challenges inherent in traditional approaches [7,8,13]. Their advanced natural language understanding (NLU), generation (NLG), and extensive world knowledge enable novel solutions for enhanced transparency, dynamic user interaction, and robust performance in data-sparse environments [19,28]. This section provides a comprehensive overview of how LLMs are integrated to improve critical recommendation tasks, exploring the specific problems they address, the innovative solutions they offer, and their technical contributions and methodologies [11,13,17].

One significant application lies in **Explainable Recommendation**, where LLMs address the "black-box" problem by generating human-readable justifications for recommendations [9,19]. This capability significantly boosts user trust and system transparency, leveraging LLMs' generative power to articulate clear and reasonable explanations that often surpass traditional methods in quality and comprehensiveness [13,20]. Frameworks such as XRec and LANE illustrate distinct strategies: XRec integrates collaborative signals with LLM language capabilities, while LANE aligns non-fine-tuned LLMs with existing systems via semantic embeddings and advanced prompting for logical reason generation [9,17].



**Key LLM Models for Sequential Recommendation**

| Model/Approach        | Core Mechanism                                                                                                                                                                  | Key Strengths/Contributions                                                                                                                               | Challenges/Considerations                                                                                                                                  |
| :-------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **P5 (RLP)**          | Unifies diverse RS tasks (incl. sequential) into a text-to-text generation paradigm using T5. Processes user purchase sequences as natural language input.                     | Broad applicability, unifies multiple tasks, strong generalization with larger models. Transforms CF behaviors to language modeling.                         | Performance varies by dataset.                                                                                                                             |
| **LLM-ESR**           | Enhances Sequential Recommendation Systems (SRS) for long-tail items/users using LLM semantic embeddings. Dual-view modeling (text + collaborative). Retrieval-enhanced self-distillation. | Improves long-tail recommendations, refines user preference representations without added computational overhead. Leverages LLM semantics effectively.        | Effectiveness depends on LLM embedding quality and collaborative signals.                                                                                    |
| **iLoRA**             | Customizes LLM fine-tuning for individual user sequences using instance-wise LoRA with a Mixture-of-Experts (MoE) framework. Uses sequence representation-guided gating.         | Adapts to diverse behavioral patterns, mitigates negative transfer, enhances individualization. Effective for specific user sequences.                     | Higher computational costs due to MoE. Demands careful handling of long sequences.                                                                         |
| **ReLLa**             | Retrieval-enhanced LLM for zero-shot/few-shot sequential recommendation. Semantic User Behavior Retrieval (SUBR) for data augmentation. Retrieval-enhanced Guided Tuning (ReiT). | Addresses lifelong sequential behavior comprehension, strong performance with minimal training data (few-shot outperforms full-data CTR models).              | Computational overhead for retrieval. Quality is dependent on the retrieval module.                                                                          |
| **SINGLE**            | Models user viewing flow for article recommendation using LLMs to capture static and instant user preferences.                                                                  | Captures both long-term and short-term preferences. Significant improvements in online A/B tests (2.4%).                                                   | Specific to article recommendation domain.                                                                                                                 |
| **BERT4Rec**          | Bidirectional Transformer with masked item prediction objective.                                                                                                                | Learns bidirectional context from user histories, enhancing prediction accuracy.                                                                          | Generally considered distinct from advanced LLMs in broader research context.                                                                               |
| **UniTRec**           | BART-based, encoder for user history representations, decoder for perplexity-based matching scores.                                                                             | Combines encoder-decoder strengths for sequence processing and matching.                                                                                  |                                                                                                                                                            |
| **General Challenges**| **`LongSequenceHandling`**: Context window limits. **`ComputationalCost`**: Processing/fine-tuning large models.                                                               | Improves sequence understanding, especially with textual data. Addresses zero-shot/few-shot.                                                              | Many models still show "moderate skill" in accuracy tasks compared to highly optimized traditional models. Need to balance innovation with practical deployment. |

For **Sequential Recommendation**, LLMs excel at capturing complex patterns and semantic meanings from textual data to predict future user preferences based on interaction histories [8,11]. Unified frameworks like P5 and M6-Rec transform diverse recommendation tasks, including sequential ones, into a text-to-text generation paradigm [8]. Furthermore, specialized models like LLM-ESR and iLoRA enhance recommendations for long-tail users and adapt to individual user sequences by integrating LLM semantic embeddings and advanced fine-tuning techniques [17]. Retrieval-augmented approaches, such as Huawei's ReLLa, tackle the challenge of lifelong sequential behavior comprehension and long user behavior sequences, demonstrating strong performance even with minimal training data [5,11].



In addressing the pervasive **Cold-Start and Long-tail Recommendation** problems, LLMs leverage their vast pre-trained knowledge, common sense, and zero-shot/few-shot learning abilities to infer preferences and generate representations for new users, items, or infrequently interacted entities, thereby overcoming severe data sparsity [19,20]. LLM-ESR, ReLLa, and BEQUE are examples of systems that employ dual-view modeling, retrieval augmentation, or query rewriting to effectively handle sparse data, utilizing natural language descriptions to facilitate preference elicitation without extensive interaction history [7,11,17].



![LLMs in Conversational Recommendation Systems](https://modelbest-prod.oss-cn-beijing.aliyuncs.com/SurveyGo/picture/y5hDlr371CMYgpYKJJJP3_LLMs%20in%20Conversational%20Recommendation%20Systems.png)

Finally, LLMs are instrumental in advancing **Conversational Recommendation Systems**, where they enable more intuitive, dynamic, and responsive user experiences through sophisticated dialogue management and accurate prediction of user interactions [17,28]. Frameworks like EPL optimize dialogue management by learning from historical experiences, while interactive systems such as Chat-REC leverage in-context learning and multi-turn dialogues to iteratively refine candidate recommendations based on user feedback and profiles [17,28]. Other models like RecLLM and InstructRec further exemplify the use of LLMs for comprehensive system optimization and fulfilling user-articulated preferences through natural language instructions [19].

Despite these significant advancements, the integration of LLMs into recommendation tasks presents common challenges. These include the substantial `ComputationalCost` and potential `Latency` associated with deploying and inferring large models, especially in real-time scenarios [13,19]. Furthermore, the `HallucinationRisk` and `ConsistencyIssue` in generative explanations and responses, the complexities of `LongSequenceHandling` in sequential models, and potential `DataBias` or `DomainKnowledgeGap` stemming from LLMs' pre-training data require continuous research and mitigation strategies [19,20]. Addressing these limitations while further exploring LLMs' capacity for nuanced understanding, multimodal integration, and ethical considerations remains paramount for realizing their full transformative potential in recommendation systems.
#### 4.1.1 Explainable Recommendation
Traditional recommendation systems often suffer from a "black-box" problem, where their underlying decision-making processes are opaque, leading to a lack of transparency and hindering user trust [7,19]. Large Language Models (LLMs) offer a transformative solution by enhancing the explainability of recommendation systems through their capacity to generate human-readable justifications for recommended items [13,21]. This ability to articulate reasons directly addresses the interpretability challenge, enabling users to understand why specific recommendations are made [23].

LLMs demonstrate significant strengths in interpretability-based tasks, including explanation generation and review summarization. Studies consistently report that LLMs exhibit performance "comparable to state-of-the-art methods" and generate "clearer, more reasonable results" for explanations [13,20]. Their generative capacity is leveraged to produce "good explanatory descriptions" that are user-understandable [21,22]. For instance, the P5 model explicitly incorporates "Explanation generation" as one of its unified tasks, showcasing the direct application of LLMs in this domain [8,28]. Moreover, the rich knowledge base embedded within LLMs allows them to provide insights and justifications, making language-based preference representations inherently more explainable and scrutable than traditional item-based or vector-based methods [3,28]. Some research even suggests that the zero-shot explanation quality generated by LLMs like ChatGPT can surpass the annotated results of certain supervised methods, with expectations for even stronger performance from future fine-tuned models [18].

Several frameworks have been developed to leverage LLMs for explainable recommendations. XRec is one such framework that generates comprehensive and meaningful textual explanations by integrating collaborative signals with LLMs' language capabilities [17]. It employs lightweight collaborative adapters to enable LLMs to grasp complex user-item interaction patterns and user preferences. Experimental evaluations indicate that XRec surpasses traditional explainable recommendation systems in both the quality and comprehensiveness of the generated explanations, achieving results comparable to state-of-the-art methods [17].

Another prominent framework, LANE (Logic Alignment of Non-tuning Large Language Models and Online Recommendation Systems for Explainable Reason Generation), specifically focuses on generating "explainable reason generation" with clear and reasonable recommendation logic [9]. LANE aims to provide highly user-acceptable personalized explanations based on user multi-preferences. Its methodology involves logically aligning non-fine-tuned LLMs with online recommendation systems using semantic embeddings, a multi-head attention-based semantic alignment module, and Chain-of-Thought prompting [9]. User interaction sequences, target items, user multi-preferences, and attention weights are fed into a GPT model to generate explanations. Qualitative assessments of LANE's explanations, based on expert scoring across seven metrics (clarity, detail, effectiveness, relevance, logic, trust, satisfaction), demonstrated the highest average scores, affirming its ability to produce "clearer, more reasonable results" and performance "comparable to state-of-the-art methods" [9]. A key innovation of LANE is its ability to achieve high-quality explanations without fine-tuning the LLM, thereby reducing computational costs, though it introduces a dependency on external LLMs like GPT and their associated API costs [9].

Other notable approaches include RecExplainer by Microsoft, which uses LLMs to generate textual explanations by simulating the recommendation model's computational logic [7]. It aligns the recommendation model and the LLM through a series of distinct tasks, including next item prediction and item ranking, integrating ID embeddings from the recommendation system as another modality. Frameworks like M6-Rec and P5 also incorporate explanation generation as part of their multi-task capabilities, demonstrating significant improvements over baselines in text quality and explainability [8,19]. Furthermore, efforts like "Personalized prompt learning for explainable recommendation" leverage LLMs' generative abilities to provide user-understandable explanations for recommendation outcomes [22,23]. Works such as LLMHG and LLM-PKG also leverage LLMs to enhance interpretability, often by integrating knowledge graphs or semantic reasoning [4].

While XRec and LANE both achieve substantial advancements in explainable recommendation, they adopt distinct strategies. XRec focuses on integrating collaborative filtering signals directly into LLMs via lightweight adapters, leveraging the LLM's language generation capabilities to explain traditional recommendation logic [17]. In contrast, LANE strategically aligns non-fine-tuned LLMs with existing recommendation systems using semantic embeddings and advanced prompting techniques (zero-shot for preferences, Chain-of-Thought for explanations), emphasizing the generation of logical and user-acceptable reasons [9]. Both frameworks, despite their different architectural choices, report producing high-quality explanations that are "clearer, more reasonable results" and achieve performance "comparable to state-of-the-art methods" [9,13]. However, a common challenge across these LLM-based explainable recommendation methods is the potential for `HallucinationRisk`â€”where explanations might be plausible but factually incorrectâ€”and `ConsistencyIssue`â€”where explanations may not accurately reflect the model's true reasoning or may accompany incorrect rankings [19,22]. Overcoming these limitations remains a critical area for future research.
#### 4.1.2 Sequential Recommendation
The application of Large Language Models (LLMs) to sequential recommendation represents a significant advancement in predicting future user preferences based on their interaction history [8,11]. This critical task, aimed at understanding and forecasting user behavior sequences, benefits from LLMs' capabilities in capturing complex patterns and semantic meanings from textual data [19,21].

One prominent approach is exemplified by the **P5** framework, which unifies multiple recommendation scenarios, including sequential recommendation, into a text-to-text paradigm [8,12]. Utilizing models like T5 as a backbone, P5 processes user purchase sequences as natural language input and generates next-item recommendations as text, effectively mapping collaborative filtering behaviors onto a language modeling task [8]. While smaller P5 models (P5-S) have shown competitive performance on specific datasets, larger models (P5-B) demonstrate superior generalization ability with unseen prompts [19]. Similarly, **M6-Rec** also transforms all recommendation tasks into text generation, inherently supporting sequential recommendation by textualizing user and item features [12].

Beyond unified frameworks, several advanced techniques have been developed to address specific challenges in sequential recommendation. **LLM-ESR** (Large Language Models Enhancement for Long-tailed Sequential Recommendation) enhances Sequential Recommendation Systems (SRS) by leveraging LLM semantic embeddings to improve recommendations for long-tail users and items, which traditionally suffer from data sparsity [4,17]. This model employs a dual-view modeling approach, integrating LLM semantics with traditional SRS collaborative signals, and utilizes a retrieval-enhanced self-distillation technique to refine user preference representations without increasing computational overhead [17]. Another innovative method, **iLoRA**, customizes LLM fine-tuning for individual user sequences by integrating instance-wise LoRA (Low-Rank Adaptation) with a Mixture-of-Experts (MoE) framework [17]. This design creates diverse experts for varied user preferences and uses a sequence representation-guided gating function to mitigate negative transfer, thus adapting to diverse behavioral patterns more effectively [17]. While LLM-ESR's effectiveness relies on the quality of LLM embeddings and collaborative signals, iLoRA may incur higher computational costs due to its MoE architecture and demands careful handling of long sequences [17].

For specific application domains, such as article recommendation, models like **SINGLE** (Alibaba) have emerged [4,11]. SINGLE models user viewing flow using LLMs to capture both static and instant user preferences from previously clicked articles. It establishes interactions between user click history and candidate articles and adaptively learns different interest perspectives for candidate matching. Online A/B tests demonstrated a 2.4% improvement over baselines, leading to more personalized and diverse article recommendations [11].

Addressing the challenge of lifelong sequential behavior comprehension and the limitations of LLMs with long user behavior sequences, Huawei's **ReLLa** (Retrieval-enhanced Large Language Model) offers a retrieval-augmented approach [5,11]. ReLLa proposes Semantic User Behavior Retrieval (SUBR) for zero-shot tasks and retrieval-enhanced guided tuning (ReiT) for few-shot tasks. ReiT leverages SUBR for data augmentation during training. Experimental results on real-world datasets indicate ReLLa's superiority and its capacity for lifelong sequential behavior understanding, with few-shot ReLLa outperforming traditional CTR models trained on full datasets with less than 10% of the training data [5,11]. For instance, on MovieLens-1M, ReLLa (Vicuna-7B) achieved HR@10 of 0.3708 and NDCG@10 of 0.2970 in few-shot settings, surpassing models like P5 [5]. However, ReLLa's computational cost and its dependency on the retrieval module's quality remain considerations [5].

Several other models and techniques contribute to the landscape of LLM-enhanced sequential recommendation. Discriminative LLM approaches include **BERT4Rec** and **GPTRec**, which leverage Transformer architectures to model masked user behaviors or generate next items, respectively [19,22]. **UniTRec**, based on BART, uses its encoder for user history representations and its decoder for perplexity-based matching scores [19]. Traditional sequential models like SASRec are also integrated into frameworks such as **LANE**, where their embedding layers are initialized with semantic embeddings to provide contextualized user behavior representations rather than direct recommendations [9]. The implicit challenge of `LongSequenceHandling` is a recurring theme, with context length limits restricting the length of user behavior sequences and candidate items, potentially leading to suboptimal performance [1,26]. Proposed mitigation strategies include sliding window strategies, selecting representative items, and prompting techniques like recency-weighted sequential prompting [18,26]. Despite these innovations, `ComputationalCost` associated with processing and fine-tuning large models remains a significant concern [19,22]. Benchmarking efforts have shown LLMs to possess "moderate skill" in accuracy-based sequential recommendation tasks [13].

In summary, the integration of LLMs into sequential recommendation systems exhibits a diverse set of methodologies. Unified frameworks like P5 aim for broad applicability by transforming recommendation into a text generation task. Specialized techniques such as LLM-ESR and iLoRA focus on enhancing specific aspects like long-tail item recommendation and individual user adaptation, respectively. ReLLa, with its retrieval-enhanced design, specifically addresses the challenges of long sequence comprehension and demonstrates strong performance in zero-shot and few-shot settings. Meanwhile, SINGLE optimizes for particular domains like article recommendation. While these approaches showcase significant performance improvements and novel ways to leverage LLM capabilities, they collectively highlight ongoing challenges related to effectively handling long user behavior sequences and managing the substantial computational resources required for LLM-driven recommendation. The continuous evolution of these methods underscores the dynamic nature of this research area.
#### 4.1.3 Cold-Start and Long-tail Recommendation with LLMs
Large Language Models (LLMs) offer significant advantages in addressing the pervasive cold-start and long-tail problems in recommendation systems, scenarios characterized by data sparsity where users interact with few items, or items are rarely consumed [7,17,19,20]. Traditional recommendation systems often struggle with these issues due to their inability to effectively model and understand user or item interests with limited interaction data [3]. In contrast, LLMs leverage their vast pre-trained knowledge, extensive factual information, domain understanding, and common sense, coupled with zero-shot and few-shot learning capabilities, to infer preferences and generate representations even for new users, new items, or infrequently interacted items, thereby overcoming data sparsity [1,18,21,22,24,28].

LLMs are particularly promising for **near cold-start recommendations**, where user interaction history is minimal. Their core advantage lies in the ability to leverage **natural language preferences** in zero-shot or few-shot settings [19,20]. This allows users to quickly describe their likes and dislikes, leading to faster preference elicitation compared to providing example items [18,20,22,28]. Studies have shown that LLMs, using prompt-based techniques with natural language descriptions, can achieve competitive recommendation performance against strong item-based collaborative filtering methods in near cold-start scenarios [20,26]. For instance, a study using a PaLM variant demonstrated that LLM Language Few-shot (3) achieved an NDCG@10 of $0.650 \pm 0.026$ on an unbiased set of items in the movie domain, effectively handling 'unseen' items and showcasing their capacity for effective cold-start resolution [20]. The inherent ability of LLMs to understand and generate content from limited linguistic input makes them uniquely effective for processing 'unseen' items and 'unbiased sets' of both popular and less popular items [8,20].

Several methodologies highlight diverse approaches and their impact on performance in these challenging areas:
*   **LLM-ESR (Large Language Models Enhancement for Long-tailed Sequential Recommendation)**: Developed by Tencent, this framework targets long-tail user recommendation problems, particularly when users have interacted with very few items, leading to poor representation learning [4,7,17]. It employs a **dual-view modeling** approach, combining LLM-generated item representations from textual descriptions (Text-side) with traditional ID-based sequences (Collaborative Filtering side) using a Transformer. These views are fused via cross-attention and concatenation. Additionally, it introduces **retrieval-augmented self-distillation**, where the user's representation is refined by minimizing its L2 distance from similar retrieved user representations, enriching long-tail user representations without additional computational cost [7,17].
*   **ReLLa (Huawei)**: This retrieval-enhanced LLM tackles zero-shot and few-shot recommendation by employing Semantic User Behavior Retrieval (SUBR) to enhance test sample data quality and retrieval-enhanced guided tuning (ReiT) for data augmentation. ReLLa demonstrates strong performance with minimal training data, effectively addressing cold-start problems [11].
*   **BEQUE (Alibaba)**: Designed for long-tail search query rewriting in e-commerce, BEQUE uses LLMs to generate candidate rewrites, aligning them with online objectives to significantly improve metrics like GMV and transaction volume for sparse queries, overcoming semantic gaps in traditional methods [11].
*   **GENRE Framework**: Specifically addresses cold-start issues for long-tail or new users in news recommendation [3,28].
*   **ChatGPT-based approaches**: Preliminary studies and frameworks like ChatREC have found ChatGPT effective in cold-start scenarios by leveraging its extensive external knowledge and retrieving relevant content from databases to supplement prompts [21,28].
*   **Data Augmentation and Interaction Simulation**: Methods like LLM-InS (Large Language Model Interaction Simulator for Cold-Start Item Recommendation) and ColdAug (Large Language Models as Data Augmenters for Cold-Start Item Recommendation) directly target cold-start item recommendation by simulating interactions or augmenting data [4].
*   **Knowledge Transfer**: Models like P5 leverage pre-trained knowledge from rich domains to perform recommendation tasks on unseen items from other domains, demonstrating adequate performance for rating prediction and classification tasks [19]. Similarly, fine-tuning BERT can enhance accuracy and handle cold-start for new items with limited historical data by leveraging its textual understanding [21].

Despite these advancements, challenges remain, such as selecting representative examples for few-shot learning in cold-start scenarios [22]. Common limitations across these approaches include potential `ComputationalCost` for complex dual-view models like LLM-ESR, `DataBias` stemming from the LLM's pre-training data or specific user studies, and `DomainKnowledgeGap` where the LLM's general pre-training might not fully capture the nuances of specific niche domains [7,17,19,20,22]. Nevertheless, the capacity of LLMs to infer preferences from textual descriptions, rather than relying solely on interaction history, fundamentally shifts the paradigm for addressing data sparsity and enabling more efficient preference elicitation in cold-start and long-tail scenarios.
#### 4.1.4 Conversational Recommendation Systems
Large Language Models (LLMs) are instrumental in enhancing conversational recommendation systems, which inherently demand sophisticated dialogue management and accurate prediction of user interactions [17,28]. These systems capitalize on the natural language understanding (NLU) and natural language generation (NLG) capabilities of LLMs to cultivate more intuitive, dynamic, and responsive user experiences, thereby transcending conventional static recommendation paradigms [20,27]. The ability of LLMs to process natural language queries, comprehend context, and formulate informative responses is directly analogous to the intricate dialogue management required in target-driven conversational systems that guide users through complex decision-making processes [33]. This approach significantly improves user interaction and fosters a deeper understanding of nuanced user preferences [22].

A notable framework in this domain is **EPL (Experiential Policy Learning)**, specifically designed for target-driven conversational recommendation systems to optimize dialogue management and predict user interactions [17]. EPL operates on the principle of "learning from experience," employing an `experiential scoring function` to anticipate current dialogue states by drawing insights from similar historical dialogues stored in a long-term memory module [17]. A significant advancement within EPL is the **Tree-structured EPL (T-EPL)**, which showcases its adaptability through a training-free methodology that synergistically combines LLMs with **Monte Carlo Tree Search (MCTS)** [17]. This integration facilitates robust planning and decision-making within complex dialogue trajectories, effectively mitigating `ComputationalCost` and `Latency` issues by leveraging historical data for prediction. However, its performance is critically dependent on the quality and diversity of the historical dialogue data, and the inherent `DialogueManagementComplexity` can remain substantial [17].

In contrast to experience-driven methodologies, other frameworks prioritize interactive, prompt-based mechanisms. **Chat-REC** emerges as a prominent interactive recommendation framework that augments traditional recommenders by systematically converting user profiles and historical interactions into structured prompts for LLMs [3,21,22,28]. This framework acquires user preferences through `InContextLearning`, eliminating the need for explicit training, and iteratively refines candidate recommendations after each dialogue turn [3,28]. Chat-REC, often built upon models like ChatGPT, employs multi-turn dialogues to ascertain user needs before invoking an underlying recommendation system. It can also manage database retrieval to augment prompts, thereby addressing challenges such as cold-start items [21,22]. This approach emphasizes interactivity, explainability, and the dynamic capability to learn and iteratively refine preferences directly from dialogue context [3].

Beyond these foundational frameworks, several other methodologies and systems enrich the landscape of conversational recommendation. **RecLLM**, for instance, incorporates a dedicated dialogue management module, an LLM-based ranking module to align with user preferences, and an LLM-based user simulator for comprehensive system optimization [22]. RecLLM has been practically applied, such as fine-tuning LaMDA for conversational YouTube video recommendations [10]. **InstructRec** enables users to articulate their preferences and requirements using natural language instructions, which the LLM then interprets and executes to perform recommendation tasks aligned with user intent and task structure [28]. For managing multi-goal interactions, **UniMIND** utilizes a BART-base backbone to identify conversational objectives and generate appropriate responses, exhibiting competitive performance through multi-task learning fine-tuning [19]. Researchers have also investigated zero-shot prompting strategies for conversational recommendation (He et al.) and employed multi-task learning fine-tuning for models like BERT to enhance knowledge infusion for predicting response relevance (Penha and Hauff) [19]. Furthermore, the development of personalized agent recommendation platforms is optimizing the collaborative ecosystem among users, recommendation systems, and items, thereby elevating the interactive experience [18].

The application of LLMs in conversational recommendation also extends to critical ethical dimensions, such as fairness. Shen et al. devised a system that integrates user-item attribute fairness analysis by employing structured prompt templates to implicitly represent non-preference information. Their research demonstrated that fairness could be upheld without detriment to recommendation performance through the judicious application of masking strategies and the neutralization of non-preference entities [24]. Moreover, the exploration of generating personalized multimodal responses in conversational settings is gaining traction, exemplified by works such as PMG (Personalized Multimodal Response Generation with Large Language Models) [11].

Comparing these diverse approaches reveals distinct strategies for leveraging LLMs. EPL, with its principled reliance on historical experience and MCTS, provides a structured methodology for managing complex dialogue states and anticipating user behavior, particularly advantageous in target-driven interactions that necessitate meticulous planning [17]. Chat-REC, conversely, excels in dynamic, interactive preference elicitation through intuitive prompt engineering and iterative refinement, rendering it highly adaptable to evolving user needs [3,28]. While frameworks like UniMIND focus on multi-goal dialogue detection and response generation, emphasizing robust language understanding and fine-tuning [19], others like RecLLM construct comprehensive ecosystems complete with explicit dialogue management and user simulation components [22]. Common strengths across these LLM-enhanced systems include an improved user experience facilitated by natural language interaction and a superior understanding of nuanced user preferences [19,22]. However, shared limitations frequently encompass high `DialogueManagementComplexity`, potential `Latency` issues arising from real-time LLM inference, and the inherent `HallucinationRisk` associated with generative models [19,22]. The effectiveness of experience-based systems like EPL is also profoundly influenced by the quality and diversity of historical dialogue data [17]. These collective studies unequivocally demonstrate the transformative potential of LLMs in actualizing more intelligent, personalized, and engaging conversational recommendation systems, while simultaneously highlighting persistent challenges in performance, scalability, and ethical considerations such as fairness.
### 4.2 LLMs for Specific Recommendation Scenarios

**LLM Applications in E-commerce Recommendation**

| E-commerce Area          | LLM Application & Mechanism                                                                                                                                           | Key Benefits                                                                                                                                    | Example/Approach                                                                                                                            | Challenges/Considerations                                                                                                                                  |
| :----------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------ | :--------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Product Search & Discovery** | Deep natural language understanding to process queries and product descriptions. Rewriting long-tail queries. Optimizing voice search.                                 | Improved search quality, higher GMV, transaction volume, visitor count. Resolves lexical mismatches.                                            | BEQUE (Alibaba for Taobao Search), fine-tuned BERT for product ranking.                                                                     | `ScalabilityIssue` with vast inventories, `DomainKnowledgeGap` for niche products, computational overhead.                                               |
| **Personalized Recommendations** | Extracting nuanced features from product descriptions & user reviews. Enhancing user embeddings. Data-driven content generation.                                     | More accurate and relevant recommendations, enhanced user personalization, improved product presentation.                                     | P5 (evaluated on Amazon subsets), U-BERT (user representations from reviews), leveraging textual metadata for feature extraction.                 | Processing diverse user behavior sequences, high computational costs for real-time inference, ensuring relevance beyond textual similarity.                  |
| **Cold-Start Problem**   | Enhancing textual representations and enabling knowledge transfer across categories for new items/users with limited interaction data.                                      | Mitigates item cold-start, provides valuable recommendations even for new entities.                                                             | Knowledge transfer (e.g., from beauty to sports on Amazon), similar strategies in news recommendation.                                            | Requires effective knowledge integration, potential `HallucinationRisk` if LLMs generate non-existent items.                                             |
| **Customer Service**     | Conversational AI for automated support and query resolution.                                                                                                         | Improved customer satisfaction, efficient query handling.                                                                                       | Implied, but general LLM conversational capabilities are applicable.                                                                        | Ensuring domain-specific accuracy, integrating with CRM systems, handling complex customer issues.                                                        |
| **Business Intelligence** | Analyzing unstructured feedback (reviews, queries) to discern implicit user needs, evolving tastes, and trend forecasting.                                                  | Better understanding of market trends, informs strategic decision-making, captures nuanced customer insights traditional methods miss.            | Analyzing vast user review datasets for sentiment, unmet needs.                                                                               | Requires robust text analytics, overcoming `DataBias` in user feedback, ensuring actionability of insights.                                               |
| **Overarching**          | Textual richness of e-commerce data (reviews, descriptions, titles).                                                                                                      | Leverages LLM strengths in text processing. Tangible business outcomes.                                                                         | Alibaba's SINGLE (article recommendation) showing 2.4% A/B test improvement.                                                                | High `ComputationalCost` & `Latency`, `HallucinationRisk` (e.g., incorrect product details), `DomainKnowledgeGap` for specialized products.           |


**LLMs for Multi-modal and Graph-enhanced Recommendation**

| Scenario/Aspect          | LLM's Role & Mechanism                                                                                                                                                                       | Key Models/Approaches                                                                                                                      | Benefits & Innovations                                                                                                                               | Challenges/Considerations                                                                                                                                  |
| :----------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Multi-modal Recommendation** | Process & understand information from various sources (text, images, video) to create comprehensive user/item representations. Jointly encode data for holistic view.                               | MMRec, X-REFLECT (GPT-4V, LLaVA), VIP5.                                                                                                    | More nuanced user preferences, richer item characteristics, comprehensive user profiles by fusing modalities.                                                | Complex data integration, high computational demands, ensuring consistent semantic understanding across modalities.                                        |
| **Graph-enhanced Recommendation** | Address challenges of combining structural data with textual semantics. Infuse rich textual context into graph-based models. Bridge heterogeneous representation spaces.                          | DALR (Denoise Alignment with LLM for Rec): Align structural and textual features, mitigate noise.                                          | Enhances item and user representations, facilitates comprehensive understanding by combining semantic & structural insights.                               | Aligning distinct feature types, potential noise introduction from text, managing computational complexity of graph operations with LLMs.                   |
| **Knowledge Graph Integration** | Extract entities, relations, factual knowledge from unstructured text to build/expand KGs. Provide richer context for recommendations by grounding LLM responses.                             | LLMRG, SAGCN, LLMHG, LLM-KERec, GaCLLM, CSRec, KELLMRec, HRGraph, CoLaKG, LLM-PKG, AutoGraph, CIKG. KERAG_R (GraphRAG: GAT selects relevant triples). | Reduce `HallucinationRisk`, mitigate `DomainKnowledgeGap`, improve factual accuracy, provide structured domain-specific information.                           | Complexity of KG construction/maintenance, ensuring relevance of retrieved triples, balancing knowledge injection with potential noise.                      |
| **User Profile Enrichment** | LLMs (e.g., in Microsoft's Personalized Contextual Query Suggestion) project user interests onto public KGs to enrich prompts and user profiles.                                                | RLMRec (LLM-empowered representation complements collaborative signals).                                                                   | Enriches user profiles with structured knowledge, more accurate & context-aware suggestions.                                                                 | `ComputationalCost` of KG lookups, `DomainKnowledgeGap` if KG is incomplete, ensuring privacy with public KGs.                                            |

This section delves into the transformative role of Large Language Models (LLMs) in addressing specific and often intricate challenges within recommendation systems, thereby extending the capabilities of traditional approaches [2,4,14,15,17,31]. By leveraging their advanced natural language understanding, generation, and reasoning capabilities, LLMs enable novel solutions across various complex scenarios, moving beyond conventional ID-based methods to create more intelligent, personalized, and context-aware recommendation experiences.

The subsequent subsections comprehensively explore four critical areas where LLMs are making significant impacts. Firstly, in **User Profile Management**, LLMs fundamentally enhance the creation of user representations. They achieve this by extracting richer, more nuanced, and semantically comprehensive features from diverse user behavior dataâ€”ranging from product descriptions and reviews to interaction sequencesâ€”and facilitate dynamic profile updates based on real-time user engagement [9,14,15,19,31]. This capability allows for a deeper semantic understanding of user interests, moving beyond simplistic feature aggregation.

Secondly, the section on **Multi-modal and Graph-enhanced Recommendation** highlights how LLMs integrate heterogeneous data modalities, such as text, images, and video, to construct comprehensive user and item representations [4,14,23,31]. Simultaneously, LLMs infuse rich textual context into structural graph information, thereby enriching traditional graph neural networks and facilitating sophisticated reasoning over knowledge graphs. This dual integration allows for a more holistic understanding of items and users by combining semantic and structural insights, addressing the alignment between these distinct feature types [2,6,11,15,16].

Thirdly, **Preference Optimization and Alignment** examines advanced methodologies that fine-tune LLMs to accurately align with nuanced user preferences for personalized ranking tasks [17]. This involves leveraging explicit preference data through techniques like Softmax Direct Preference Optimization (S-DPO), aligning LLMs with collaborative filtering signals, and employing retrieval-enhanced strategies to capture intricate user preference dynamics, even in few-shot scenarios [5,9,11,15,23]. The goal is to enable LLMs to differentiate effectively between preferred and non-preferred items, enhancing recommendation precision.

Finally, **Domain-Specific Applications: E-commerce** showcases the practical deployment of LLMs within this text-rich and highly dynamic sector [11,14,18]. LLMs are instrumental in improving product search and discovery, delivering highly personalized recommendations, and addressing domain-specific challenges such as the cold-start problem. Their capacity for deep natural language understanding and generation directly translates into tangible business outcomes, optimizing various stages of the e-commerce user journey [19,24,28].

Across these diverse applications, a set of common challenges emerges, including concerns regarding user privacy, the substantial computational cost associated with processing and updating large datasets, and the complexity of mitigating data bias and noise [5,9,14,19,20]. Furthermore, researchers are actively working to address the `DomainKnowledgeGap` and `HallucinationRisk` inherent in general-purpose LLMs when applied to specialized domains, often through integration with knowledge graphs [4,6]. Despite these complexities, the integration of LLMs in these specific recommendation scenarios represents a significant paradigm shift, offering robust frameworks for building more intelligent and context-aware systems that adapt to evolving user needs and data landscapes. Each sub-section elaborates on the unique problems, details the LLM-based solutions, and analyzes their technical innovations and contributions, comparing methodologies and results to highlight diverse approaches and their impact on performance.
#### 4.2.1 User Profile Management
Large Language Models (LLMs) fundamentally transform user profile management in recommendation systems by significantly enhancing semantic understanding and feature extraction capabilities from diverse user behavior data [14,15,31]. This advancement moves beyond traditional ID-based features, enabling the creation of richer, more nuanced, and semantically comprehensive user representations [15].

A core contribution of LLMs is their ability to perform deep **semantic understanding and feature extraction**. By processing historical interaction data, such as product titles, reviews, and descriptions, LLMs leverage their sophisticated self-attention mechanisms to extract high-order features and infer underlying user interests [19,31]. For instance, the RLMRec framework explicitly employs LLMs to capture intricate semantic aspects of user behaviors and preferences by incorporating auxiliary textual signals to extract richer, high-order features that form user interest vectors [15]. Similarly, the LANE framework's "user multi-preference generation module" utilizes LLMs with zero-shot prompting to extract multiple preferences from a user's interaction sequence, semantically embedding these preferences for a more nuanced understanding of user interests [9]. Several models exemplify this, including U-BERT and UserBERT, which learn user representations by leveraging rich domain content and capturing implicit semantic interactions from reviews and unlabeled behavioral data respectively, often through self-supervised tasks like masked behavior prediction [19,21]. Other approaches, such as UNBERT for news recommendation, represent users based on the text of news they have browsed, forming user-news matching representations [19]. LLMs can also generate descriptive user preference keywords, like NIR, or extract them from reading histories (e.g., GENRE) to enrich profiles for applications such as news recommendation [21]. Microsoft's Personalized Contextual Query Suggestion builds an entity-centric user knowledge store from web search and browsing activity to enrich LLM prompts, demonstrating an effective aggregation of user interests [11]. The formula $u = \text{LLM}(\text{Item}_1, \text{Item}_2, \ldots, \text{Item}_n)$ succinctly represents this LLM-driven user profiling, where the LLM processes a sequence of interacted items (represented by their textual attributes) to generate a vectorial user representation [31]. This enhanced semantic understanding provides a more robust foundation for personalized recommendations.

LLMs also excel in facilitating **dynamic profile updates** based on real-time interactions. Unlike traditional methods that often require periodic retraining, LLMs can continuously adjust user representations as new interaction data becomes available [31]. For example, Chat-REC learns and dynamically updates user preferences by converting existing profiles and historical interactions into prompts, iteratively adjusting after each conversational exchange [28]. The SINGLE model, developed by Alibaba, utilizes LLMs to capture both users' continuous long-term preferences (e.g., skills, positions) and their immediate short-term interests through an "instant viewing flow modeling," showcasing adaptive user profile management [11]. Furthermore, frameworks like LLM-ESR refine user preference representations by leveraging richer interaction data from similar users, contributing implicitly to dynamic updates, while iLoRA dynamically adapts to diverse behavioral patterns through instance-wise LoRA in a Mixture-of-Experts (MoE) setup [17]. These capabilities allow user profiles to evolve with recent behaviors, ensuring up-to-date preference modeling and more responsive recommendation systems.

Moreover, LLMs possess the inherent capability for **cross-modal information fusion**, integrating various data modalities such as text, images, and audio into comprehensive user profiles [31]. For instance, user reviews (textual), viewed images (visual), and watched videos (audio) can be jointly encoded by LLMs to create a unified user representation, thereby capturing a holistic view of user preferences. This comprehensive approach enriches the depth and adaptability of user profiles, which is crucial for improving recommendation accuracy and relevance.

While LLMs offer significant advantages in providing a more precise understanding of customer preferences and overcoming the limitations of current user modeling techniques [3], their application in user profile management also introduces challenges. Concerns regarding user privacy are prominent, especially when raw interaction data is directly fed to external LLMs [9,19]. Additionally, the computational cost associated with continuously updating and processing large textual user profiles with LLMs can be substantial [9,19]. Despite these challenges, the ability of LLMs to process unstructured data, understand implicit user feedback, and derive semantically rich representations marks a new paradigm for user profile management in recommendation systems [14].
#### 4.2.2 Multi-modal and Graph-enhanced Recommendation
Large Language Models (LLMs) are increasingly recognized for their capacity to enhance recommendation systems by integrating diverse data modalities and leveraging structured graph information. This dual-pronged approach allows for the creation of richer item and user representations, facilitating more comprehensive and engaging recommendation experiences [14].

In the realm of **multi-modal recommendation**, LLMs offer a powerful mechanism to process and understand information from various sources, including text, images, and video [14]. Models such as `MMRec` (LLM Based Multi-Modal Recommender System) and `X-REFLECT` (Cross-Reflection Prompting for Multimodal Recommendation) demonstrate this capability by leveraging LLMs to integrate multiple modalities [4]. Notably, `X-REFLECT` utilizes advanced vision-language models like GPT-4V and LLaVA1.5-7B, showcasing the potential of multimodal LLMs to perform complex reasoning across different data types [4]. This cross-modal information fusion is crucial for building more comprehensive user profiles, jointly encoding data from user reviews (text), viewed images, and watched videos (audio/visual) to generate unified user representations [31]. The `VIP5` framework also explicitly addresses the integration of LLMs with multiple modalities for recommendation, further highlighting this burgeoning area [23]. Such integration moves beyond traditional text-based recommendations, enabling systems to capture more nuanced user preferences and item characteristics.

For **graph-enhanced recommendation**, LLMs play a pivotal role in addressing the challenges associated with combining structural data with textual semantics. Traditional graph neural networks, while adept at capturing complex user-item relationships, often rely heavily on ID-based data and tend to disregard valuable textual information [11,15]. LLMs can mitigate this by infusing rich textual context into graph-based models. A prominent example is DALR ("Denoise Alignment with Large Language Model for Recommendation"), a framework designed specifically for graph recommendation systems [2,16]. DALR tackles the critical challenge of aligning structural features derived from graphs with textual features generated by LLMs, while simultaneously mitigating noise [2]. It integrates graph structure representations with LLMs to capture intricate user-item interactions and employs an alignment paradigm to enhance representation performance by harmonizing semantic information from LLMs with structural features from graphs [2,16]. Furthermore, DALR incorporates a contrastive learning component to effectively eliminate noise and improve overall model performance [2,16].

Beyond direct integration like DALR, LLMs significantly assist in building, populating, and reasoning over knowledge graphs (KGs) to provide richer context for recommendations [4]. They can extract entities, relations, and factual knowledge from unstructured text, thereby facilitating the construction or expansion of KGs [4]. Numerous models leverage this synergy, including `LLMRG`, `SAGCN`, `LLMHG`, `LLM-KERec`, `GaCLLM`, `CSRec`, `KELLMRec`, `HRGraph`, `CoLaKG`, `LLM-PKG`, `AutoGraph`, and `CIKG`, all of which incorporate KGs with LLMs often assisting in various stages of graph utilization [4]. Microsoft's Personalized Contextual Query Suggestion, for instance, aggregates user interests and knowledge by projecting them onto a public knowledge graph, leveraging graph structures to enrich user profiles for LLM prompts [11].

Furthermore, models like `KERAG_R` exemplify advanced graph-enhanced recommendation by integrating KG information into LLM instructions via a novel GraphRAG component [6]. `KERAG_R` utilizes a pre-trained Graph Attention Network (GAT) to select relevant triples from the KG for specific users, thereby aligning structured knowledge graph features with the LLM's text-based processing, reducing redundancy, and mitigating computational costs and domain knowledge gaps associated with KGs [6]. Other works, such as "GraphTranslator: Aligning Graph Model to Large Language Model for Open-ended Tasks" and "Unifying Local and Global Knowledge: Empowering Large Language Models as Political Experts with Knowledge Graphs," directly address the fusion of graph models and KGs with LLMs [11]. The `RLMRec` framework from Baidu, while primarily focused on representation learning with textual data, integrates LLM-empowered representation to complement collaborative signals captured by graph-based methods, suggesting a cross-view alignment of textual and structural features [11,15]. This integration is crucial to overcome the limitation of LLMs overemphasizing textual features by introducing KGs or user behaviors [10]. Even models like `T-EPL`, which integrate LLMs with Monte Carlo Tree Search for conversational recommendation, implicitly exhibit a form of graph-like reasoning through their tree-structured decision-making processes [17]. While some papers, such as [18], mention the use of ChatGPT with knowledge bases to construct "inference graphs" for enhanced user representations, they do not extensively detail specific multi-modal or graph-enhanced models. This collective effort underscores the transformative potential of LLMs in building more intelligent and context-aware recommendation systems through multi-modal integration and graph-enhanced reasoning.
#### 4.2.3 Preference Optimization and Alignment
Optimizing Large Language Models (LLMs) to accurately align with nuanced user preferences is a critical challenge in recommendation systems, particularly in personalized ranking scenarios [17]. This alignment ensures that recommendations not only are relevant but also reflect the subtle distinctions between highly preferred and less desirable items.

One advanced method for explicitly leveraging preference data in ranking is Softmax Direct Preference Optimization (S-DPO) [17]. S-DPO addresses the limitation of existing LLM-based recommender systems that often fine-tune primarily on positive samples, thus failing to fully exploit comparative preference information. The technique introduces an alternative Direct Preference Optimization (DPO) loss function combined with a softmax sampling strategy that incorporates multiple negative samples from user preference data [17]. This design is intended to inject explicit ranking information directly into the LLMs, thereby enhancing their capacity to differentiate effectively between preferred and non-preferred items for personalized recommendations [17]. While S-DPO offers strengths in utilizing preference data for improved ranking, its practical application faces challenges related to `PreferenceElicitationComplexity` for collecting suitable negative samples and potential `DataBias` if these samples are not representative [17].

Beyond direct preference optimization, several frameworks focus on aligning LLMs with collaborative information to capture user preferences. The GANPrompt framework, for instance, employs a two-stage optimization strategy to balance diversity and accuracy in LLM recommendations [9]. Its second stage specifically fine-tunes recommendation LLMs by aligning them with collaborative information. This is achieved by mapping collaborative information vectors ($v_{collab}$), typically generated by a pre-trained traditional collaborative filtering model, into the same latent space as the LLM's input representation: $$e_{LLM\_input} = \text{Map}(v_{collab}) \oplus \text{Description}$$ where $\text{Description}$ refers to item descriptions [9]. This integration is crucial for personalized ranking tasks by effectively incorporating user preference signals derived from collaborative filtering [9]. Similarly, RLMRec aims to improve user preference learning by capturing intricate semantic aspects of user behaviors through LLM-empowered representation learning [15]. It utilizes a "cross-view alignment" mechanism that aligns the semantic space learned by LLMs with collaborative relational signals, supported theoretically by mutual information maximization, to reduce `DataBias` or `Noise` introduced by implicit feedback [15].

Other approaches leverage retrieval-enhanced strategies and customized prediction heads for preference alignment. ReLLa, developed by Huawei for few-shot recommendation, utilizes Retrieval-enhanced Guided Tuning (ReiT) [5,11]. By incorporating Semantic User Behavior Retrieval (SUBR) as a data augmentation technique during training, ReLLa effectively aligns the LLM's predictions with user preferences even with limited samples [11]. This strategy enhances the alignment of LLM recommendations with actual user behavior, particularly for complex sequential patterns, though it can introduce `DataBias` if the retrieval module is biased and `PreferenceElicitationComplexity` remains in defining optimal retrieval [5]. Additionally, CLLM4Rec from LinkedIn introduces a recommendation optimization adjustment strategy by adding a polynomial likelihood item prediction head to its pre-trained backbone, facilitating the efficient generation of multiple item recommendations while avoiding spurious information [11]. Beyond user preferences, broader alignment concerns include ethical considerations, as exemplified by "UP5: Unbiased Foundation Model for Fairness-aware Recommendation," which focuses on optimizing LLM behavior to align with ethical preferences and minimize bias in recommendations [23].

A critical evaluation of incorporating negative preferences reveals nuanced insights. While S-DPO employs negative samples within its DPO loss framework to establish a ranking signal, a separate study investigated the direct impact of including explicit negative preferences (disliked items or descriptions) in zero-shot prompts [20]. Surprisingly, this research found no meaningful improvements in language-based recommendations when incorporating both positive and negative preferences (`Pos+Neg` variants) compared to using only positive preferences in the tested LLM configurations [20]. Furthermore, using only negative preferences resulted in performance at or below the popularity baseline [20]. This suggests that the mere presence of negative preference signals does not guarantee improved performance; rather, the method and context of their integration are crucial. The limitations noted in this finding, such as potential `DataBias` in the implementation and dataset, along with the inherent `PreferenceElicitationComplexity` of gathering accurate negative preferences, warrant further investigation to generalize these observations [20]. These findings underscore the ongoing complexity in effectively translating diverse user preference signals, including explicit negative feedback, into robust LLM-based recommendation performance. Benchmark tasks such as "Rating Prediction" and "Direct Recommendation" serve as crucial measures for understanding and optimizing these complex preference dynamics [13].
#### 4.2.4 Domain-Specific Applications: E-commerce
The e-commerce sector presents a highly relevant and impactful domain for the deployment of Large Language Models (LLMs) in recommendation systems, primarily due to its inherent textual richness and the complexity of user interactions [11,14,18]. LLMs are particularly adept at processing the vast quantities of unstructured textual data common in e-commerce, such as product descriptions, user reviews, and queries [19]. This capability enables LLMs to enhance various facets of the e-commerce user journey, offering seamless and personalized experiences across diverse channels [14].

A significant advantage of LLMs in e-commerce lies in their capacity for **deep natural language understanding and generation**. This directly translates to improvements in product search and discovery. For instance, systems like BEQUE, developed by Alibaba for Taobao Search, demonstrate the efficacy of LLMs in improving long-tail query rewriting. Its real-world deployment has yielded substantial gains in Gross Merchandise Volume (GMV), transaction volume, and visitor count, underscoring the practical impact of LLMs in optimizing product discovery [11]. LLMs also hold promise for optimizing voice search and addressing lexical mismatches between user queries and product listings through fine-tuned models like BERT in multi-task learning frameworks for product ranking [14,24].

Beyond search, LLMs contribute significantly to **personalized recommendations**. They achieve this by extracting nuanced features from detailed product descriptions and user reviews, thereby enhancing user embeddings and overall personalization strategies [14,19]. The multi-task model P5, for example, has been evaluated on Amazon subsets (Toys, Beauty, Sports), demonstrating its capability for sequential and top-k recommendations, while U-BERT focuses on enhancing user representations from reviews within Amazon datasets [19]. Furthermore, LLMs can generate data-driven and engaging product content, which not only improves product presentation but also aids in feature extraction for downstream recommendation tasks [14].

LLMs also extend their utility to broader e-commerce operations. In **customer service**, their capabilities in conversational AI can facilitate automated support and query resolution, though specific e-commerce focused instances are implied rather than detailed in the reviewed digests. For **business intelligence**, LLMs can analyze unstructured feedback data to discern implicit user needs and evolving tastes, contributing to trend forecasting and strategic decision-making, which traditional methods often struggle to capture [14]. The ability to process diverse user behavior sequences, encompassing clicks, add-to-cart actions, and purchases, is crucial for preference modeling, although translating these heterogeneous behaviors into natural language prompts for LLMs presents a challenge [26].

However, deploying LLMs in e-commerce also presents unique **challenges and requires specific adaptations**. The domain is characterized by **vast and dynamic item catalogs** and highly specific user behaviors [14]. Challenges include `ScalabilityIssue` and `ComputationalCost` when dealing with extremely large and diverse product inventories, as well as a potential `DomainKnowledgeGap` if LLMs lack specialized expertise for niche product categories [19]. To mitigate these, approaches include leveraging offline processing for item understanding, as exemplified in technical article recommendation where LLMs condense long documents into high-precision representations to manage computational overhead [28]. Moreover, integrating LLMs with knowledge graphs (KGs) can bridge the `DomainKnowledgeGap` and reduce `HallucinationRisk` by providing access to detailed product knowledge, as seen in `LLM-PKG` which focuses on explainable recommendations in e-commerce using product KGs [4,6].

LLMs are also instrumental in addressing **domain-specific requirements** such as the **cold-start problem**. By enhancing textual representations and enabling knowledge transfer across categories (e.g., from beauty to sports in Amazon), LLMs can effectively mitigate item cold-start in e-commerce [19]. Similar strategies have proven successful in news recommendation, where LLMs address cold-start and user profile modeling issues specific to the domain [3,23]. The effectiveness of LLM-driven item and user context understanding is further supported by studies in analogous domains. For instance, in technical article recommendation, an LLM-based approach demonstrated significant improvements over state-of-the-art news recommendation models, with NDCG@5 increasing from 0.281-0.289 to 0.323 and HR@5 from 0.289-0.298 to 0.334 [28]. These results indicate the potential for similar performance gains in e-commerce when LLMs are adapted to understand complex product information and user purchase behaviors. Overall, the evidence suggests that LLMs offer a robust framework for improving key performance indicators and meeting the unique demands of the e-commerce recommendation landscape.
## 5. Key Challenges and Mitigation Strategies

**LLM Biases and Mitigation Strategies in Recommendation**

| Bias Type               | Description                                                                                                                                                                                                                                                                                         | Mitigation Strategy                                                                                                                                                                                                                                                                                                                                                                                                           | Key Benefits                                                                                                                                                                                                       |
| :---------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Position Bias**       | LLMs prioritize items appearing earlier in an input sequence, struggle with order, leading to incorrect rankings.                                                                                                                                                                                   | - Random sampling of input sequences.                                                                                                                                                                                                                                                                                                                                                                                 | Improves fairness in item presentation, ensures all items have equal chance of being considered regardless of position.                                                                                         |
|                         |                                                                                                                                                                                                                                                                                                     | - Shuffling candidate item lists and averaging scores for ranking.                                                                                                                                                                                                                                                                                                                                                    |                                                                                                                                                                                                                    |
| **Popularity Bias**     | LLMs tend to over-recommend items that are widely discussed or frequently appear in their pre-training corpus, marginalizing niche/long-tail items. Evident in GPT-4 favoring popular items.                                                                                                         | - Infusing collaborative-based knowledge into LLMs (via fine-tuning or hybrid methods) to balance textual understanding with user behavior patterns.                                                                                                                                                                                                                                                                  | Promotes diversity, increases discoverability of long-tail items, reduces `HomogeneityIssue`.                                                                                                                      |
|                         |                                                                                                                                                                                                                                                                                                     | - Employing diversity-promoting generators (e.g., GANPrompt's diversity data generator with diversity constraints).                                                                                                                                                                                                                                                                                                   |                                                                                                                                                                                                                    |
| **Fairness Bias**       | LLMs can reflect and perpetuate societal biases from their training data (e.g., gender, race), leading to unfair or controversial recommendations.                                                                                                                                                 | - Using structured prompt templates with placeholders to neutralize non-preference entities (e.g., demographic characteristics) in conversational RS.                                                                                                                                                                                                                                                              | Ensures equitable treatment across user groups, reduces discriminatory outcomes, enhances trust.                                                                                                                   |
|                         |                                                                                                                                                                                                                                                                                                     | - Developing unbiased foundation models (e.g., UP5: Unbiased Foundation Model for Fairness-aware Recommendation).                                                                                                                                                                                                                                                                                                     |                                                                                                                                                                                                                    |
| **Amplification Bias**  | Occurs when typical decoding processes (e.g., length normalization) over-prioritize items containing "ghost tokens" with high generation probabilities, skewing item scores.                                                                                                                       | - **D3 (Decoding Matters):** Disabling 'ghost tokens' in length normalization during decoding.                                                                                                                                                                                                                                                                                                                         | Prevents over-prioritization of certain items, ensures fairer scoring based on true relevance rather than decoding artifacts.                                                                                    |
| **Homogeneity Problem** | LLMs tend to generate multiple similar or repetitive items, reducing diversity, reinforcing existing preferences, and leading to `echo chambers`. Exacerbated by over-reliance on textual patterns.                                                                                                   | - **D3 (Decoding Matters):** Introducing a text-free auxiliary model to encourage the generation of less frequent tokens.                                                                                                                                                                                                                                                                                             | Increases diversity of recommendations, prevents repetitive suggestions, broadens user exposure to varied content.                                                                                                   |
|                         |                                                                                                                                                                                                                                                                                                     | - GANPrompt's diversity data generator (mentioned above for popularity bias).                                                                                                                                                                                                                                                                                                                                          |                                                                                                                                                                                                                    |
| **Content Bias**        | LLMs may prioritize textual similarity over actual user preferences (e.g., BERT focusing on content).                                                                                                                                                                                                 | - Fine-tuning LLMs with task-specific knowledge that balances textual understanding with behavioral signals (e.g., user-item co-consumption patterns).                                                                                                                                                                                                                                                           | Ensures recommendations are aligned with actual user behavior and preferences, not just semantic content.                                                                                                          |
| **Negative Transfer**   | Over-generalization from uniform fine-tuning can lead to unfairness for individual users, failing to capture specific differences.                                                                                                                                                                | - iLoRA (Instance-wise LoRA with Mixtures of Experts): Dynamically adapts to diverse behavioral patterns of individual users.                                                                                                                                                                                                                                                                                       | Ensures individualized adaptation, prevents 'one-size-fits-all' recommendations that may be unfair to certain users.                                                                                               |
| **Ethical Use**         | LLMs can lead to discriminatory outcomes, compromise trustworthiness, violate ethical principles (fairness, accountability, transparency). `HallucinationRisk` also degrades trust.                                                                                                                 | - Incorporating ethical principles into design & operation. - Rigorous research into safety, robustness, non-discrimination, and explainability. - Projects like MoralBench and UP5. - Explainability (e.g., LANE) helps build trust despite `HallucinationRisk` if managed effectively. | Builds trustworthy and equitable recommendation experiences, fosters responsible AI development, enhances user confidence and acceptance of LLM-powered systems. |


![Robustness and Generalizability of LLM-based Recommendation](https://modelbest-prod.oss-cn-beijing.aliyuncs.com/SurveyGo/picture/Um62lgv2l80OqhK0uFBp3_Robustness%20and%20Generalizability%20of%20LLM-based%20Recommendation.png)


**Mitigation Strategies for Domain Knowledge Gap & Hallucinations**

| Challenge/Problem                   | Description                                                                                                                                                                                                    | Mitigation Strategy                                                                                                                                                                                                                                     | Key Benefits                                                                                                                                                    | Trade-offs/Considerations                                                                                                                                         |
| :---------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :-------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **`DomainKnowledgeGap`**            | LLMs lack specific, fine-grained domain knowledge essential for accurate and relevant recommendations. General pre-training insufficient for niche domains.                                                  | **1. Knowledge Graph (KG) Integration:** Integrate external KGs into LLM instructions. Utilize GATs to select relevant knowledge triples.                                                                                                   | Grounds LLM responses, reduces factual errors, enhances accuracy, provides structured domain info.                                                              | `ComputationalCost` of KG integration, potential for noisy KG data, complexity of balancing external knowledge with LLM's inherent knowledge.                     |
|                                     |                                                                                                                                                                                                                | **2. Fine-tuning on Domain-Specific Data:** Align LLMs with specific domain data (e.g., UniSRec for item description texts).                                                                                                                           | Improves performance for target domain, learns specific patterns.                                                                                               | `ComputationalCost` of fine-tuning large models, risk of overfitting to specific domain, requires high-quality domain data.                                       |
| **`HallucinationRisk`**             | Generation of plausible but factually incorrect, non-existent, or irrelevant information (e.g., incorrect item names, authors, rankings).                                                                    | **1. Retrieval-Augmented Generation (RAG):** Retrieve factual information from KGs/databases to ground LLM outputs. (e.g., KERAG_R).                                                                                                                  | Ensures factual accuracy, reduces misleading recommendations, enhances trustworthiness.                                                                         | Retrieval latency, quality dependence on external sources, potential for conflicts between retrieved info and LLM's generated text.                               |
|                                     |                                                                                                                                                                                                                | **2. Generative Diversity & Grounding:** Use GAN-based diversity data generation (GANPrompt) to ensure varied/realistic outputs. Implement decoding strategies that align generated items with actual inventory (e.g., Multi-Facet Indexing).               | Enhances robustness, prevents spurious information, ensures generated items are real/available.                                                                 | Complexity of GAN training/decoding strategies, potential for reduced creativity if too constrained.                                                            |
|                                     |                                                                                                                                                                                                                | **3. Selective Knowledge Infusion:** Extract explicit knowledge but sample only recommendation-effective information (Ant Group).                                                                                                                             | Prevents infusion of noisy/irrelevant info.                                                                                                                     | Requires careful modeling of relevance, potential for human bias in selection criteria.                                                                           |
| **Misinterpretation/Inaccuracy**    | LLMs might misinterpret complex domain content (e.g., technical articles) or over-prioritize popular items in pre-training.                                                                                 | **1. Contextual Understanding & Summarization:** Use LLMs for "high-precision extraction" and summarization of complex content (e.g., GENRE framework for news).                                                                                        | Captures nuanced meanings, prevents misinterpretations, reduces `HallucinationRisk` from shallow processing.                                                    | Loss of detail in summarization, still requires human oversight for critical content.                                                                          |
|                                     |                                                                                                                                                                                                                | **2. Decoding Strategies:** Address "amplification bias" (over-prioritizing items with 'ghost tokens'). D3 disables ghost tokens in length normalization.                                                                                             | Mitigates unfair or skewed recommendations, improves accuracy.                                                                                                  | Complexity of decoding modifications, ensuring broad applicability across tasks.                                                                                |
| **General Challenges**              | `ComputationalCost` for fine-tuning & knowledge extraction. Multilingual/niche domain limitations. `Popularity bias` from pre-training data.                                                                | **1. Vertical Domain-Specific LLMs:** Tailor LLMs to specific domains (future direction). **2. Bias-Aware Design:** Consider popularity bias in evaluation metrics.                                                                                 | Improves specialized recommendation effectiveness, better handling of non-English/niche content.                                                              | Requires substantial investment for each domain, maintaining diverse training data for base LLMs.                                                              |


The integration of Large Language Models (LLMs) into recommender systems (RS) represents a transformative paradigm, yet it is accompanied by a spectrum of formidable challenges that impede widespread adoption and optimal performance [17,19]. While LLMs offer unprecedented semantic understanding and generation capabilities, their application in the complex and dynamic environment of recommendation systems is still in its nascent stages, requiring substantial research and engineering efforts [21,27]. These challenges largely stem from the inherent differences between LLM pre-training objectives and the specific requirements of recommendation tasks, leading to issues across representation alignment, sequential behavior understanding, knowledge integration, operational efficiency, system robustness, and fairness.



![Strategies for Bridging the Semantic Gap (ID-LLM Alignment)](https://modelbest-prod.oss-cn-beijing.aliyuncs.com/SurveyGo/picture/rjyAJKWbbVuFA3JBfjkjD_Strategies%20for%20Bridging%20the%20Semantic%20Gap%20%28ID-LLM%20Alignment%29.png)

A primary hurdle lies in **Bridging the Semantic Gap: ID-LLM Alignment**. Traditional recommender systems predominantly rely on discrete ID-based representations, which effectively capture collaborative patterns but lack rich semantic information. In contrast, LLMs excel at processing continuous, semantically dense textual data [7,26]. The discrepancy between these "heterogeneous representation spaces" arises because LLMs are not inherently designed to understand the abstract identifiers crucial for personalized recommendations, often suffering from `TextOnlyReliance` when naively applied [15]. Mitigation strategies vary in their approach: some directly integrate IDs into LLMs by expanding vocabulary or mapping IDs to natural language tokens, aiming for a tighter coupling [10,11]. Others leverage cross-modal alignment through sophisticated pre-training objectives and contrastive learning, aligning representations in a shared embedding space while allowing each modality to retain its strengths [7,15]. Prompt-based methods inject collaborative embeddings as prompts or latent vectors to guide LLM reasoning [7,9], and dual-view modeling implicitly combines LLM semantics with collaborative signals [17]. These approaches entail trade-offs regarding `ComputationalCost`, `FeatureAlignmentComplexity`, and `PromptDesignComplexity` versus the degree of personalization and semantic enrichment achieved [7,19].

Another significant challenge is **Handling Long Sequential User Behaviors**, often termed the "lifelong sequential behavior incomprehension problem" [5]. LLMs struggle to effectively process, summarize, and extract critical knowledge from extensive interaction histories, even with large context windows, due to their difficulty in discerning meaningful patterns from diffuse and noisy information [5,11]. This is exacerbated by the constrained context windows of LLMs and the heterogeneity of real-world user behaviors [19,24]. Mitigation strategies include retrieval-enhanced methods that selectively retrieve relevant information to provide a focused context to the LLM [5,6], as well as sliding window techniques to manage sequence length [18,21]. Other methods focus on summarization or selection of representative items to condense history [18,28], or architectural enhancements like multi-segment late interaction and specialized LoRA variants to process longer sequences more efficiently [17,28]. These solutions often balance improved `LifelongSequentialBehaviorComprehension` with increased `ComputationalCost` and potential information loss [5,19].

**Incorporating Domain-Specific Knowledge & Preventing Hallucinations** is crucial, as pre-trained LLMs, despite their vast general knowledge, suffer from a `DomainKnowledgeGap` and a consequent `HallucinationRisk` [4,6]. This can lead to the generation of plausible but factually incorrect or irrelevant recommendations. To counter this, external domain-specific knowledge, often structured as knowledge graphs, is integrated into LLMs to ground responses and enhance accuracy through retrieval augmentation [4,23]. Fine-tuning on domain-specific datasets [1,21], employing generative diversity techniques to ensure varied and realistic outputs [9], and specialized decoding strategies to mitigate amplification biases are also critical [17]. The primary trade-off here involves the `ComputationalCost` of knowledge extraction and fine-tuning versus the accuracy and reliability of recommendations, especially given the risk of introducing noise from external knowledge sources [7,27].



**Efficiency, Scalability, and Integration Challenges & Solutions**

| Challenge/Problem                           | Description                                                                                                                                                             | Mitigation Strategy                                                                                                                                                                                                                                                                  | Key Benefits                                                                                                                                                    | Trade-offs/Considerations                                                                                                                                                      |
| :------------------------------------------ | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **`InferenceLatency` & `ComputationalCost`**| Substantial size, memory footprint, and complexity of LLMs make real-time, large-scale deployment challenging. High cost of proprietary LLM APIs.                           | **1. Engineering Optimizations:** Early exiting, parameter sharing, pruning (M6-Rec). Multi-segment late interaction (M6-Rec).                                                                                                                                               | Reduces computational burden, improves responsiveness, enables real-time applications.                                                                          | Requires significant engineering effort, potential minor performance degradation.                                                                                      |
|                                             |                                                                                                                                                                         | **2. Parameter-Efficient Fine-tuning (PEFT):** LoRA, prompt tuning, option tuning.                                                                                                                                                                                                   | Lowers computational costs, reduces trainable parameters, faster training/adaptation.                                                                           | Minor performance trade-offs vs. full fine-tuning, `PromptDesignComplexity`.                                                                                           |
|                                             |                                                                                                                                                                         | **3. In-Context Learning (ICL):** Freezes LLM parameters, avoids extensive fine-tuning.                                                                                                                                                                                               | Minimizes fine-tuning cost, reduces computational demands for adaptation.                                                                                       | `PromptDesignComplexity`, less task-specific specialization, potentially `HallucinationRisk`.                                                                          |
|                                             |                                                                                                                                                                         | **4. Model Distillation:** Transfers knowledge from large LLMs to smaller, more efficient models (LEADER, DLLM2Rec, SLMRec).                                                                                                                                                            | Improves practicality for deployment, reduces resource consumption.                                                                                             | Performance gap compared to large LLM, complex distillation process, may lose some nuance.                                                                             |
| **`ScalabilityIssue`**                      | Inability to scale to massive user bases and item catalogs due to LLM size and computational demands. Many works limited to offline experimental settings.                  | **1. Two-Stage Training Approaches:** Inject LLM knowledge into traditional ranking models offline (CTRL).                                                                                                                                                                           | Avoids online inference costs, leverages LLM insights without real-time burden.                                                                                 | Efficiency of knowledge injection, scalability of daily incremental training for large industrial systems are concerns.                                               |
|                                             |                                                                                                                                                                         | **2. Hybrid Strategies:** Use LLMs as controllers (ChatREC) or integrate with existing black-box RS without fine-tuning LLM (LANE).                                                                                                                                                  | Leverages LLM capabilities without replacing infrastructure, maintains efficiency of traditional systems.                                                       | Integration complexity, may not fully harness LLM power if interaction is limited.                                                                                     |
| **Integration Complexity**                  | Bridging the ID-centric nature of traditional RS with LLMs. Need for seamless interaction and knowledge transfer.                                                         | **1. Modular Frameworks:** RLMRec (model-agnostic) enhances existing recommenders with LLM-empowered representation.                                                                                                                                                              | Modularity, improved integration with traditional systems, allows leveraging LLM semantics without full system overhaul.                                        | Requires careful design of interfaces between modules, potential for data mismatch.                                                                                    |
|                                             |                                                                                                                                                                         | **2. Decreasing API Costs & Open-Source LLMs:** Emerging access to high-performance open-source models (Llama3, Qwen2).                                                                                                                                                              | Alleviates cost concerns, simplifies local deployment, fosters more research into sophisticated models.                                                         | Still significant hardware requirements for local deployment, challenges in fine-tuning/customization.                                                                 |
| **Limited Real-World Applicability**        | Many academic studies lack proven efficacy in massive real-world deployments. Offline experimental nature.                                                              | **1. Online A/B Test Validation:** Focus on deploying and validating solutions with real users (Meta's "Actions Speak Louder than Words," Alibaba's BEQUE, SINGLE).                                                                                                                | Demonstrates real-world impact and performance gains, proves industrial feasibility.                                                                            | Requires substantial engineering effort, significant resources, complex experimentation setup.                                                                          |
|                                             |                                                                                                                                                                         | **2. Cost-Effective Ranking Methods:** Prioritize list-wise ranking for efficiency.                                                                                                                                                                                                   | Better improvements per unit cost compared to point-wise/pair-wise.                                                                                             | LLM output format may not always conform to list-wise needs, may struggle with structural consistency.                                                                   |

The practical viability of LLM-based recommenders is heavily constrained by **Efficiency, Scalability, and Integration with Traditional Systems**. `InferenceLatency`, `ComputationalCost`, and `ScalabilityIssue` arise from the substantial size, memory footprint, and complexity of LLMs, making real-time, large-scale deployment challenging [15,19]. Mitigations include engineering optimizations (e.g., early exiting, late interaction, pruning) [19,28], two-stage training approaches to inject LLM knowledge offline [4,12], parameter-efficient fine-tuning (PEFT) methods like LoRA to reduce trainable parameters [9,19], in-context learning to minimize fine-tuning, and model distillation to transfer knowledge to smaller, more efficient models [4,23]. Hybrid strategies, such as using LLMs as controllers or integrating them with black-box traditional systems, aim to leverage LLM capabilities without incurring prohibitive costs [9,15]. The ongoing decrease in LLM API costs and the emergence of high-performance open-source models are expected to alleviate these concerns, simplifying local deployment and comprehensive experimentation [27].

Moreover, ensuring **Robustness and Generalizability** is paramount. LLMs are sensitive to noise and variations in input, and their performance can degrade when applied to new domains, users, or languages [9,11]. Noise mitigation is addressed through contrastive learning, mutual information maximization, and selective retrieval [15,16]. To improve generalizability, research focuses on domain adaptation through vertical domain-specific LLMs, individualized adaptation methods like iLoRA, and frameworks designed for zero-shot cross-domain recommendation [10,17]. The trade-offs involve balancing domain specificity with broad applicability, and managing the complexity of adaptation mechanisms against the risk of negative transfer across different user profiles or data characteristics [20,28].

Finally, **Addressing Bias and Homogeneity** is a critical ethical and performance challenge. LLMs can exhibit various biases, including position bias (prioritizing items appearing earlier) [18,22], popularity bias (over-recommending frequently mentioned items) [19,26], and fairness bias (perpetuating societal biases) [22,26]. These biases lead to a `HomogeneityIssue`, where recommendations lack diversity [17]. Mitigation strategies include random sampling or shuffling for position bias [21,22], structured prompt templates and unbiased foundation models for fairness [23,24], and sophisticated decoding strategies (e.g., D3 to disable "ghost tokens") to counter amplification bias and enhance diversity [17]. Infusing collaborative knowledge and employing diversity-promoting generators also help mitigate popularity and homogeneity biases [9,19]. This category of challenges emphasizes the crucial balance between recommendation accuracy and the ethical implications of fairness and diversity in AI systems [14].

In conclusion, while LLM-enhanced recommender systems hold immense promise, their widespread and effective deployment hinges upon surmounting these interconnected challenges. The overarching theme across mitigation strategies is the development of hybrid, retrieval-augmented, and parameter-efficient approaches that allow LLMs to leverage their semantic power while being grounded by domain-specific knowledge, collaborative signals, and practical system constraints. Future research must continue to focus on creating more efficient, robust, generalizable, and ethically sound solutions that balance the sophisticated capabilities of LLMs with the real-world demands of recommendation [21,27].
### 5.1 Bridging the Semantic Gap: ID-LLM Alignment
The integration of Large Language Models (LLMs) into recommendation systems presents a significant challenge: bridging the semantic gap between traditional ID-based representations and the rich, text-based representations inherently understood by LLMs [10,26]. This discrepancy stems from the discrete nature of ID embeddings, which primarily capture collaborative patterns, versus the continuous and semantically rich textual features that LLMs process [7]. Addressing this "heterogeneous representation space" is crucial for LLMs to effectively leverage their deep semantic understanding while retaining the personalized and collaborative signals essential for accurate recommendations [2,4,16]. Furthermore, traditional graph-based recommenders often disregard textual information, leading to less informative representations, while current LLM integrations can suffer from `TextOnlyReliance` [15]. This necessitates robust strategies for aligning these distinct representation paradigms.

Several advanced strategies have emerged to tackle this alignment challenge, varying in their approach to integrating or aligning ID tokens with LLM representations.

**1. Direct ID Integration and Vocabulary Extension:**
One direct approach involves expanding the LLM's vocabulary to explicitly recognize and process traditional IDs. **CLLM4Rec** from LinkedIn, for instance, extends the pre-trained LLM's vocabulary with user and item ID tokens to model both collaborative and content semantics [11]. This framework employs a novel soft and hard prompting strategy, combining heterogeneous soft (user/item) tokens with hard (vocabulary) tokens, alongside homogeneous item/vocabulary tokens in the main text, to facilitate stable and effective language modeling within RS-specific corpora [11]. Similarly, the **P5** framework maps user and item IDs to natural language sequences and utilizes "whole-word embedding" to ensure ID features maintain unified embeddings even after tokenization, thereby preserving personalization capabilities without an excessive increase in ID features [10,12]. Other works also advocate for extending LLM vocabulary to include user/item IDs and employing joint training to align these ID representations with the text space, thereby linking abstract LLM representations with concrete user/item identities [18]. Methods like "How to Index Item IDs for Recommendation Foundation Models" and "IDGenRec: LLM-RecSys Alignment with Textual ID Learning" also explore explicit learning for integrating symbolic IDs into LLM frameworks [23]. While these strategies aim to imbue LLMs with a direct understanding of IDs, they often introduce `ComputationalCost` and `FeatureAlignmentComplexity` in managing expanded vocabularies or mapping schemes [7,19].

**2. Cross-Modal Alignment through Pre-training and Contrastive Learning:**
Another prominent category of strategies focuses on aligning ID and textual representations through sophisticated pre-training objectives and contrastive learning.
*   **FLIP** (Towards Fine-grained Alignment between ID-based Models and Pretrained Language Models for CTR Prediction) from Huawei proposes a two-stage pre-training approach [4,7]. The initial stage uses Masked Language Model (MLM)-like tasks to reconstruct masked text and ID representations using contextual information from both modalities. The subsequent stage applies contrastive learning, treating ID and text representations of the same feature as positive pairs, pulling them closer in the embedding space [7]. This robust alignment enhances fine-grained integration for tasks like CTR prediction, though it can incur significant `ComputationalCost` due to its complex pre-training and bimodal management [7].
*   **RLMRec** (Representation Learning with Large Language Models for Recommendation) by Baidu tackles alignment through cross-view optimization of mutual information [11,15]. RLMRec integrates auxiliary textual signals and employs LLMs for user/item profiling. Crucially, it aligns the semantic space derived from LLMs with collaborative relational signals from traditional ID-based recommendation systems, theoretically underpinned by mutual information maximization to improve representation quality [15]. This model-agnostic framework enhances existing recommenders, improving performance and `RobustnessIssue` to noise [15].
*   The **DALR** (Denoise Alignment Framework) addresses the semantic gap by aligning structural representations, typically from graph-based recommender systems, with textual representations from LLMs [2,16]. DALR enhances overall representation performance through an alignment paradigm that leverages LLMs for semantic information and integrates a contrastive learning component to improve alignment and mitigate noise [2,16]. This framework is specifically designed to bridge the heterogeneous representation spaces between graph-based and language-based systems [2].
*   **CTRL** also employs a two-stage training process, aligning traditional model sample embeddings with LLM-generated embeddings by converting traditional samples into LLM-compatible prompts [12]. However, its scalability in large industrial systems is questioned due to the potential need for daily incremental pre-training for massive data [12].

**3. Prompt-based Alignment and Embedding Injection:**
This category leverages the LLM's prompt mechanism or directly injects collaborative embeddings into the LLM's latent space.
*   **ClickPrompt** from Huawei adopts a novel method where intermediate embeddings from ID models are directly used as prompts (prefixes) for an LLM at each Transformer layer [7]. This approach converts features into text, concatenates them with ID embeddings, and feeds them into the LLM. It effectively aligns ID-based CTR models and LLMs through prompt generation, enabling LLMs to adapt to CTR prediction tasks without full fine-tuning. However, its effectiveness heavily relies on `PromptDesignComplexity` and incurs `ComputationalCost` from running both models [7].
*   **GANPrompt** injects "collaborative information" from a pre-trained traditional collaborative filtering model directly into the LLM's latent space [9]. This involves generating collaborative vectors for users and items and then mapping them to the LLM's feature space to ensure compatibility. The final input combines these collaborative vectors with item descriptions, enabling LLMs to effectively utilize traditional recommendation signals [9].
*   **LANE** replaces traditional item ID embeddings with "semantic embeddings" of item titles, generated using Sentence-BERT [9]. It then employs a "semantic alignment module" with multi-head attention to align sequence features from the recommendation model with LLM-derived "user multi-preferences" [9]. The alignment process transforms the sequence feature matrix $H_{seq}$ and user multi-preference embeddings $e_{pref}$ into an aligned vector:
    $$Aligned = \text{LayerNorm}(\text{MultiHeadAttention}(Q=H_{seq}, K=e_{pref}, V=e_{pref}) + H_{seq})$$
    followed by a Point-wise Feed-Forward Network and another Layer Normalization [9]. This significantly improves recommendation performance and interpretability.
*   The concept of continuous prompts (soft prompts) for users and items, rather than discrete text representations, has also been proposed to fuse ID information into LLMs' semantic space, enhancing their understanding of user-item interactions [19].

**4. Dual-View Modeling:**
**LLM-ESR** implicitly addresses the semantic gap by combining LLM semantic information with traditional collaborative signals through a dual-view modeling approach [17]. This method integrates the rich textual understanding of LLMs with interaction-based collaborative filtering patterns, particularly improving recommendations for `long-tail items` [17]. Additionally, "Zero-Shot Next-Item Recommendation" implicitly handles this by using traditional methods for recall and LLMs for subsequent ranking, though it does not delve into explicit alignment techniques [28].

**Trade-offs between Preserving Collaborative Signals and Leveraging Semantic Understanding:**
These diverse alignment strategies present inherent trade-offs between preserving collaborative signals and leveraging semantic understanding. Methods that directly integrate ID tokens or map IDs to natural language (e.g., CLLM4Rec, P5) aim for a tighter coupling, enabling LLMs to *learn* to represent collaborative patterns within their own token space. This can offer strong personalization but risks diluting the original collaborative signals if not carefully managed [18,26].

Conversely, strategies relying on cross-modal alignment through pre-training (e.g., FLIP, RLMRec, DALR) often focus on aligning *representations* in a shared embedding space, allowing each modality to retain its intrinsic strengths while benefiting from the other. RLMRec, by maximizing mutual information between LLM semantic space and collaborative relational signals, explicitly seeks to enhance representation quality by balancing both views [15]. DALR similarly aims to align structural (collaborative) and textual (semantic) features, thereby improving overall representation performance [2]. These methods strive for a more balanced integration, where collaborative filtering still grounds the personalization, and LLMs provide semantic enrichment.

Prompt-based methods (e.g., ClickPrompt, GANPrompt, LANE) typically aim to inject collaborative information *into* the LLM's processing pipeline, making the LLM "aware" of traditional signals. ClickPrompt's use of ID model embeddings as prompts allows the LLM to adapt to CTR prediction tasks, essentially guiding its semantic reasoning with collaborative context [7]. GANPrompt explicitly maps collaborative vectors into the LLM's feature space, ensuring compatibility [9]. LANE's multi-head attention for semantic alignment effectively fuses semantic item titles with LLM-derived user preferences, bridging the gap between semantics and user-item interactions [9]. These methods often preserve the integrity of collaborative signals by leveraging a pre-trained traditional model, then using the LLM for refined semantic understanding and ranking.

The complexity of these alignment strategies varies significantly. Pre-training methods like FLIP and DALR involve intricate multi-stage processes and significant computational resources [7,16]. Prompt-based methods like ClickPrompt face challenges in `PromptDesignComplexity`, as the quality of prompts is crucial for effectiveness [7]. Integrating ID tokens directly into LLMs requires careful management of vocabulary expansion and potentially large-scale fine-tuning. Overall, the field is moving towards more sophisticated fusion techniques that aim to harness the semantic power of LLMs without sacrificing the crucial personalization capabilities derived from collaborative filtering, leading to enhanced recommendation performance, particularly for challenges like `long-tail items` and `RobustnessIssue` to noise [15,17].
### 5.2 Handling Long Sequential User Behaviors
Large Language Models (LLMs) confront a significant challenge in recommendation systems, termed the "lifelong sequential behavior incomprehension problem" [5]. This problem arises from the inherent difficulty LLMs experience in effectively processing, summarizing, and extracting critical knowledge from extensive user interaction histories, even when the context window is theoretically large enough to accommodate the full sequence [5,11]. The core issue is not merely the length but the LLM's struggle to discern meaningful patterns and user intent from diffuse information embedded within long text contexts [5]. For instance, LLMs often exhibit suboptimal performance when asked to predict the next item based on a lengthy, unrefined list of past interactions, such as movie titles and genres [5].

A primary underlying cause of this challenge is the constrained context window of LLMs, which limits the maximum input sequence length for user behaviors and candidate items [1,18,19,22,24]. For example, models like GPT-3.5-turbo-instruct are restricted to approximately 4,096 tokens, a capacity quickly consumed by system prompts and extensive user history [19]. Furthermore, presenting LLMs with more context can inadvertently introduce "more noise," which degrades recommendation quality [1]. Traditional sequential modeling often addresses homogeneous sequences, whereas real-world user behavior is diverse and heterogeneous, adding another layer of complexity to sequential comprehension for LLMs [12].

To mitigate the "lifelong sequential behavior incomprehension problem," retrieval-enhanced methods have emerged as a promising direction. The ReLLa framework, for example, introduces Semantic User Behavior Retrieval (SUBR) as a core component [5,11]. SUBR is designed to enhance the data quality of both testing and training samples by compressing and enriching lengthy user behavior sequences. Specifically, for each item in a user's historical sequence, SUBR retrieves a small set of semantically similar items, leveraging techniques such as Sentence-BERT and K-Nearest Neighbors (KNN) search on item textual attributes [5]. The descriptions of these retrieved items are then used to augment the original item's representation. This process effectively provides a more focused and relevant context for the LLM, reducing the cognitive load required to extract critical knowledge from extensive sequences [5].

The effectiveness of SUBR-like approaches is notable, as demonstrated by the superior recommendation performance achieved in both zero-shot and few-shot settings, signaling enhanced `LifelongSequentialBehaviorComprehension` [5]. For few-shot scenarios, ReLLa further incorporates Retrieval-enhanced Instruction Tuning (ReiT), which fine-tunes the LLM on a mixed dataset of original and SUBR-augmented user behavior sequences, thereby explicitly teaching the LLM to leverage the enriched context [5]. While effective, such retrieval steps introduce computational overhead, particularly for real-time recommendation, as each item in the sequence may require a retrieval operation. The quality of item embeddings and the retrieval model itself also critically influence SUBR's performance [5]. Similarly, KERAG_R employs a pre-trained Graph Attention Network (GAT) to selectively retrieve the most relevant triples from knowledge graphs, thereby managing input context length and reducing noisy information, which shares conceptual similarities with SUBR's selective augmentation [6].

Beyond retrieval-augmented approaches, several other strategies have been explored to address the challenges of handling long sequential user behaviors. One common technique is the **sliding window strategy**, which segments long sequences into smaller, manageable chunks to fit within the LLM's context window [18,21,22,26]. Sun et al. (2023) applied a sliding window prompting strategy for candidate item re-ranking, where items are sorted within a window, which then slides to achieve an overall ranking [21]. Hou et al. (2023) utilized **recency-weighted sequential prompting** to help LLMs perceive sequential information in user history while mitigating position bias [21].

Another strategy involves **summarization or selection of representative items**. This includes using LLMs to summarize extensive user browsing histories offline, leveraging their `CoT` (Chain-of-Thought) capabilities to extract logical patterns and condense information into manageable representations for downstream tasks [28]. Platforms like YiYi AI, which summarize lengthy academic papers, implicitly demonstrate the potential of LLMs to distill key information from extended inputs, a mechanism relevant for user behavior sequences [33]. Selecting "representative items" from user behavior sequences also reduces length while aiming to preserve critical information [18,22]. However, these summarization and selection methods risk losing some potentially valuable information from the complete sequence [22].

Furthermore, some methods focus on pre-processing or architectural enhancements. Wang and Lim employed a collaborative filtering-based module to pre-compute and narrow down a candidate set of movies, ensuring it fits into the LLM's prompt, though this might introduce `ColdStart` issues for the pre-computation module and incur `ComputationalCost` [19]. M6-Rec proposes a **multi-segment late interaction** technique, caching results from initial transformer layers to improve the efficiency of processing longer sequences and mitigate inference latency and computational overhead [28]. iLoRA, designed for sequential recommendation, uses `instance-wise LoRA` within a `Mixture-of-Experts (MoE)` framework and a `sequence representation-guided gating function` to dynamically adapt to diverse and potentially long user behavioral patterns, thereby addressing `NegativeTransfer` and enhancing individualization [17]. Additionally, frameworks like LANE integrate embedded item titles from user history into adapted traditional sequential recommendation models (e.g., SASRec) to generate sequence feature vectors, while GANPrompt enhances historical interaction data with a diversity encoder [9]. The development of Small Language Models (SLMs) also suggests efforts to optimize LLMs for efficient processing of long user sequences, potentially through better management of context and computational resources [23].

In summary, while LLMs offer great promise for recommendation, their ability to comprehend and leverage lifelong sequential user behaviors is fundamentally challenged by context window limitations, computational overhead, and the intrinsic difficulty in extracting salient information from noisy, heterogeneous, and extensive historical data. Retrieval-enhanced methods, alongside segmentation, summarization, and architectural innovations, represent diverse approaches to overcome these hurdles, each with its own trade-offs regarding computational cost, information retention, and real-time applicability. The ongoing research in this area seeks to balance comprehensive understanding of user behavior with the practical constraints of LLM-based recommendation systems.
### 5.3 Incorporating Domain-Specific Knowledge & Preventing Hallucinations
A critical challenge in leveraging Large Language Models (LLMs) for recommendation systems is their inherent `DomainKnowledgeGap` and the consequent `HallucinationRisk` [4,6]. Pre-trained LLMs, while possessing vast general knowledge, often lack the specific, fine-grained domain knowledge essential for accurate and relevant recommendations [10,18]. This limitation can lead to the generation of plausible but factually incorrect, non-existent, or irrelevant information, a phenomenon known as hallucination [10,11]. Examples of such hallucinations include recommending non-existent items or books, misattributing authors, or producing incorrect rankings with flawed explanations [8,10]. Even in tasks like academic paper translation and summarization, ensuring factual accuracy and domain relevance is paramount to prevent scientific misinterpretations or fabricated citations [33].

To mitigate the `DomainKnowledgeGap` and `HallucinationRisk`, a primary strategy involves enriching LLMs with external, domain-specific knowledge, often in the form of knowledge graphs (KGs) [4,23]. Models like Knowledge-Enhanced Retrieval-Augmented Generation (GraphRAG), specifically KERAG_R, exemplify this approach [6]. KERAG_R integrates additional information from a knowledge graph into LLM instructions, employing a pre-trained Graph Attention Network (GAT) within its GraphRAG component. The GAT selectively identifies and extracts the most relevant knowledge triples for target users, thereby grounding LLM responses and significantly enhancing recommendation accuracy while reducing factual errors and hallucinations [6]. Other notable works such as LLMRG, SAGCN, LLMHG, LLM-KERec, GaCLLM, CSRec, KELLMRec, HRGraph, CoLaKG, LLM-PKG, AutoGraph, and CIKG also leverage knowledge graphs to inject domain-specific knowledge and guide LLM reasoning, aiming to improve factual accuracy and reduce hallucination risk [4]. Similarly, research on "Path Language Modeling over Knowledge Graphs for Explainable Recommendation" and "Knowledge Graph Large Language Model (KG-LLM) for Link Prediction" also focuses on integrating structured knowledge to enhance LLM capabilities [23].

A crucial aspect of integrating external knowledge is striking a balance between enriching LLMs and preventing the introduction of redundant or noisy information that can impair reasoning [6]. KERAG_R's GAT addresses this by selectively retrieving pertinent knowledge, filtering out irrelevant data [6]. Another strategy is seen in the Ant Group's work, which extracts explicit knowledge from LLMs but then models a distribution to sample only the knowledge effective for recommendation, thus preventing the infusion of noisy or irrelevant information into item embeddings [7]. Microsoft's Personalized Contextual Query Suggestion further illustrates this by building an entity-centric user knowledge store based on web activity and public KGs to enhance LLM prompts, ensuring personalized and contextually relevant suggestions without introducing extraneous data [11].

Beyond direct KG integration, several other strategies contribute to mitigating hallucinations and the `DomainKnowledgeGap`:
*   **Fine-tuning**: Fine-tuning LLMs is a common method to align them with specific domain data and improve performance [1,21]. UniSRec, for instance, focuses on learning transferable representations by associating item description texts [24].
*   **Generative Diversity and Grounding**: The GANPrompt framework, through its GAN-based diversity data generation, enriches item descriptions and combines LLM embedded knowledge with collaborative filtering information. This approach enhances the robustness and accuracy of recommendations, implicitly reducing hallucinations by ensuring realistic and varied outputs [9]. Similarly, CLLM4Rec from LinkedIn aims to avoid the production of spurious information (a form of hallucination) through recommendation optimization and a polynomial likelihood item prediction head [11]. To address the "generation alignment challenges" where LLMs might generate items not present in the actual item corpus, methods like "Multi-Facet Indexing," "FM-Index alignment," and two-stage alignment processes (semantic token generation followed by weighted matching with real items) are proposed to ensure generated items correspond to real inventory [18].
*   **Contextual Understanding**: For complex domain content, such as news or technical articles, LLMs can be utilized for "high-precision extraction" and summarization to capture nuanced meanings and prevent misinterpretations or `HallucinationRisk` that could arise from shallow processing [28]. The GENRE framework specifically addresses the `DomainKnowledgeGap` in news recommendation by leveraging LLMs to understand complex news content [28].
*   **Decoding Strategies**: Some techniques focus on addressing "amplification bias," a form of `HallucinationRisk` where "ghost tokens" with high generation probability can inflate item scores. D3, for instance, proposes disabling these ghost tokens in length normalization to mitigate this issue [17].

Despite these advancements, fully addressing the `DomainKnowledgeGap` and `HallucinationRisk` remains an ongoing challenge. The computational cost associated with fine-tuning large LLMs and extracting knowledge often leads researchers to rely on general-purpose models, potentially resulting in recommendations lacking specialized knowledge or containing inaccuracies [7,27]. Furthermore, while LLMs possess vast world knowledge, their general pre-training may not adequately cover specific niche domains or effectively handle multilingual contexts, as evidenced by issues in non-English data or domains with limited textual content [8,20]. The presence of "popularity bias," where frequently mentioned items in pre-training corpora receive higher rankings, also implicitly points to a `DomainKnowledgeGap` that can lead to less relevant recommendations [26]. While qualitative evaluations sometimes note that LLMs can generate "clearer, more reasonable results" for explanations, suggesting a degree of factuality and coherence, this does not universally translate to preventing hallucinations in actual recommendations [13]. Therefore, while current approaches significantly improve the reliability and accuracy of LLM-based recommendations, continuous research is needed to ensure robustness across diverse and specialized domains.
### 5.4 Efficiency, Scalability, and Integration with Traditional Systems
The successful deployment of Large Language Models (LLMs) in recommendation systems is critically challenged by concerns surrounding inference latency, overall system efficiency, computational resource demands, and seamless integration with existing traditional architectures [7,12,14,15,19,26,27]. The substantial computational costs associated with training and inference, alongside the inherent large model sizes and memory footprints, engender considerable skepticism regarding their industrial feasibility in real-time, large-scale recommendation scenarios [10,18,22,28]. For instance, the high cost of proprietary LLM APIs, such as GPT-4, has limited large-scale experimental evaluation in much academic research, though a positive outlook suggests that decreasing API costs and the rise of high-performance open-source models like Llama3 and Qwen2 could alleviate these concerns and simplify local deployment [27].

A primary objective in enhancing efficiency is reducing inference latency. M6-Rec addresses this by introducing a "multi-segment late interaction" mechanism. This technique involves caching the outputs from the initial layers of the transformer, thereby reducing the computational burden during real-time recommendations and improving the feasibility of LLM integration in time-sensitive applications [19,28]. Similarly, engineering optimizations such as early exiting, parameter sharing, and pruning are employed in M6-Rec to reduce model size and ensure responsive user experiences, even on mobile devices [19].

A critical analysis from "The Elephant in the Room" highlights that current LLM applications often exhibit inefficiency and significant parameter redundancy within recommendation contexts [7]. The paper proposes an efficient utilization method that leverages an ID-based sequential modeling framework, initializing its item embeddings with those derived from a pre-trained language model fine-tuned on behavior sequences [7]. This strategy aims to maximize LLM effectiveness by integrating their rich semantic embeddings into more efficient ID-based models, thereby addressing computational costs and scalability issues, albeit with potential integration complexities related to fine-tuning and knowledge transfer [7]. Furthermore, CLLM4Rec improves efficiency by optimizing multi-item recommendation generation, avoiding spurious information through a specialized adjustment strategy [11].

Various strategies are being explored to mitigate the substantial computational and integration challenges. Engineering optimizations during both training (e.g., random length sampling, sample sampling) and inference (e.g., batch inference logic, late interaction, option tuning) are crucial for managing computational costs, as demonstrated by M6-Rec [12]. To reduce the need for real-time online LLM inference, which often incurs prohibitive costs and latency, approaches like offline processing for tasks such as document summarization and user behavior modeling for long document recommendation are adopted [28].

Two-stage training approaches represent another mitigation strategy, designed to inject LLM knowledge into traditional ranking models offline, thereby circumventing additional online inference costs. For instance, `CTRL` (Connect Collaborative and Language Model for CTR Prediction) aims to efficiently integrate collaborative and language models using such a paradigm [4]. However, for large-scale industrial systems, the efficiency of knowledge injection and the scalability of daily incremental training within these two-stage approaches, such as `CTRL`, remain significant concerns [12].

Beyond these, parameter-efficient fine-tuning (PEFT) techniques like LoRA, prompt tuning, and option tuning are critical for reducing the number of trainable parameters, thereby lowering computational costs and accelerating training times [9,19]. In-context learning (ICL) offers an alternative by freezing LLM parameters, thus avoiding extensive fine-tuning and reducing computational demands [19]. Model distillation techniques, exemplified by `LEADER`, `DLLM2Rec`, and `SLMRec`, transfer knowledge from large LLMs to smaller, more efficient models, enhancing practicality [4,23]. LANE explicitly aims to reduce costs by integrating LLMs with existing black-box recommendation models without requiring fine-tuning of the LLM itself, showcasing a hybrid approach to leverage LLM capabilities while maintaining efficiency [9]. Moreover, model-agnostic frameworks like RLMRec enhance existing recommenders through LLM-empowered representation learning, offering modularity and improved integration with traditional ID-based systems [15]. Even using LLMs as controllers within existing frameworks, as seen in ChatREC, rather than replacing entire infrastructures, represents a strategic approach to manage integration complexity [21]. Microsoft's approach for personalized contextual query suggestion, utilizing a lightweight user knowledge store and existing search log infrastructure, exemplifies addressing privacy, compliance, and scalability without costly LLM retraining [11].

Despite these advancements, the feasibility and effectiveness of LLM-based solutions for large-scale, real-time recommendation scenarios vary significantly. Meta's "Actions Speak Louder than Words" represents a breakthrough, demonstrating high performance; however, its implementation demands substantial engineering effort and computational resources, placing it largely within the reach of major tech companies [12]. Conversely, models like `NoteLLM` have shown non-substantial improvements despite their computational overhead, questioning their practical utility in certain applications [12]. Furthermore, approaches such as `Prompt Learning for News Recommendation` face significant online inference challenges, rendering them unsuitable for large-scale industrial deployment due to their offline experimental nature [12]. List-wise ranking methods are highlighted as a more cost-effective strategy for item ranking, demonstrating better improvements per unit cost compared to multi-call point-wise or pair-wise approaches [1].

Overall, while promising research and engineering efforts are underway, the industrial applicability and scalability of many LLM-based recommendation systems remain a concern. Many reported works are often limited to offline experimental settings, lacking proven efficacy in massive real-world deployments. The current landscape indicates that LLM applications in search, advertising, and recommendation are still nascent, with a scarcity of work capable of fundamentally altering classic paradigms or achieving widespread real-world adoption [11]. The inherent nature of LLM outputs, which may not always conform to expected formats for list-wise recommendation tasks and the time-consuming nature of pairwise combinations, further complicates their direct application and scalability [26]. Therefore, balancing performance, efficiency, and real-world deployability remains a critical area of ongoing research and development.
### 5.5 Robustness and Generalizability
Robustness and generalizability are paramount concerns in the development and deployment of Large Language Model (LLM)-based recommendation systems. The inherent reliance on prompts and the aspiration for zero-shot capabilities necessitate methods that can maintain accuracy and performance even in the presence of noise or when applied to new, unseen scenarios [9].

Noise issues are a significant concern, particularly when integrating diverse data sources such as graph structures and LLM-generated textual features [2,16]. Frameworks like the Denoise Alignment Framework (DALR) address this by employing a contrastive learning component specifically designed to eliminate noise and improve model performance, thereby enhancing robustness in LLM-enhanced graph recommendation systems [2,16]. Similarly, the RLMRec framework explicitly analyzes its efficiency and robustness under noisy data. By incorporating auxiliary textual signals and aligning semantic spaces with collaborative signals via mutual information maximization, RLMRec inherently aims to provide richer, more stable representations, thus improving robustness against noisy implicit feedback data [11,15]. Furthermore, the KERAG_R model enhances robustness by selecting only the most relevant triples from knowledge graphs using a pre-trained Graph Attention Network (GAT), thereby mitigating the adverse effects of redundant and noisy information on the LLM's reasoning process [6]. The sensitivity of LLMs to input variations and prompt shots also poses a robustness challenge; increasing "prompt shots" or "history items" can introduce more noise, adversely affecting performance [1]. To counter this, GANPrompt explicitly aims to enhance robustness by employing a GAN-based diversity data generation method that produces varied and semantically rich item descriptions, thereby ensuring the LLM receives diverse input and leading to more robust recommendations [9].

LLMs' generalizability to new users and items is simultaneously a strength, particularly for addressing cold-start problems, and a significant challenge, especially concerning domain specificity [10,11]. For instance, approaches like `Prompt Learning for News Recommendation (Prompt4NR)` demonstrate high application value due to their effectiveness in news recommendation, leveraging the LLM's language ability [28]. However, this method is critically noted to be "only effective in the news recommendation domain," implying poor generalizability to domains with less textual content or different data characteristics, such as video or product recommendations [11,12,28]. Experimental setups limited by factors such as small user study scale (e.g., 153 raters) and restriction to English-only preferences also highlight generalizability issues, as conclusions cannot be definitively extended to other languages or cultures [20]. A practical example illustrates this limitation, where attempts to replicate an LLM-based system with Arabic data using existing open-source T5 models consistently failed, recommending only generic items like "football" due to insufficient support for non-English data and translation errors [8]. This underscores the crucial impact of language and domain coverage on LLM performance.

To mitigate generalizability limitations, various strategies have emerged. The concept of "Vertical Domain-Specific LLMs for Recommender Systems" is proposed as a future direction, suggesting that tailoring LLMs to specific domains could lead to better recommendation results and implicitly address cross-domain generalizability issues [10]. iLoRA addresses the "negative transfer" issue that arises when uniformly applying fine-tuning methods like LoRA to LLMs for sequential recommendation, which can fail to capture individual user differences. By introducing `instance-wise LoRA` combined with a `Mixture-of-Experts (MoE)` framework and a `sequence representation-guided gating function`, iLoRA dynamically adapts to diverse behavioral patterns, thereby enhancing model generalizability and robustness across different user profiles [17]. ReLLa further enhances the generalizability of LLMs for sequential recommendation by improving their lifelong sequential behavior comprehension across different user behavior sequences. It demonstrates improved performance in both zero-shot and few-shot settings, indicating better generalization capability to unseen users or items [5,11]. Additionally, frameworks like `RecG` (A Zero-Shot Generalization Framework for LLM-Driven Cross-Domain Sequential Recommendation) explicitly aim to improve cross-domain generalizability, while the use of Knowledge Graphs and robust embedding guidance techniques (e.g., in `DaRec`) contribute to more robust and generalizable representations by providing structured, domain-specific information [4]. The "YiYi AI" platform, designed to serve researchers across diverse academic fields, exemplifies the need for robustness and generalizability across varied terminology, syntax, and conceptual complexity in handling heterogeneous content [33].

Furthermore, LLMs used in recommendations can exhibit various biases inherited from their training data or architectural characteristics, impacting both robustness and generalizability [22]. These include position bias, where LLMs prioritize items appearing earlier in sequences; popularity bias, leading to over-representation of popular items; and fairness bias, which can manifest as biased recommendations based on sensitive attributes [22]. While random sampling can mitigate position bias, addressing popularity and fairness biases remains particularly challenging due to their deep roots in the foundational training data and model architecture [22]. Efforts such as "UP5: Unbiased Foundation Model for Fairness-aware Recommendation" contribute to robustness by focusing on bias reduction, aiming for greater reliability across different user groups and broader generalizability across tasks and domains [23]. These biases can ultimately reduce the fairness and diversity of recommendations, limiting model generalizability across diverse user demographics or item categories [22]."
### 5.6 Addressing Bias and Homogeneity
The integration of Large Language Models (LLMs) into recommendation systems introduces significant technical challenges related to inherent model biases, which can compromise recommendation fairness and diversity [3,21,24,26]. These biases often manifest in several forms:

One prominent challenge is **position bias**, where LLMs tend to prioritize items appearing earlier in an input sequence and struggle to accurately capture the order of behavioral sequences in generated recommendations [1,18,22,26]. This inherent ordering bias can lead to incorrect rankings of recommended items. Another critical issue is **popularity bias**, where items that are widely discussed and frequently appear in the LLM's pre-training corpus tend to be ranked higher [18,22,26]. This phenomenon restricts the diversity of recommendations and often marginalizes niche or long-tail items, leading to a `HomogeneityIssue` [8,19,28]. Research, such as that involving GPT-4, has reported a tendency towards recommending popular items and exhibiting better performance on data from English-speaking regions, further illustrating this bias [19]. Furthermore, **fairness bias** arises when pre-trained LLMs reflect and perpetuate societal biases present in their training data, leading to unfair recommendations based on sensitive user attributes like gender or race [10,18,22,26]. These biases collectively reduce diversity and raise ethical concerns, as they can lead to discriminatory or unrepresentative outcomes [14,28].

Beyond these inherent biases, LLM-based recommendation systems also face challenges such as **amplification bias** and the **homogeneity problem**, which stem from typical decoding processes [17]. The amplification bias occurs when standard length normalization mechanisms over-prioritize items containing "ghost tokens" with generation probabilities close to 1. Simultaneously, the homogeneity problem describes the model's tendency to generate multiple similar or repetitive items for a user [17]. This can be exacerbated by an over-reliance on textual patterns rather than collaborative behavior, as demonstrated by findings that BERT tends to prioritize content-based knowledge [19].

To address these critical issues, several innovative solutions have been proposed. For position bias, mitigation strategies include random sampling of input sequences [22] and methods involving shuffling candidate item lists and averaging their scores for ranking [21]. Mitigating popularity and fairness biases is more complex due to their intrinsic link with LLM pre-training data [22]. Approaches include using structured prompt templates with placeholders to neutralize non-preference entities that reflect demographic characteristics, thereby addressing bias without impacting performance [24]. Another strategy involves infusing additional knowledge, such as collaborative-based knowledge, into LLMs through fine-tuning to balance textual understanding with user behavior patterns [19].

A notable innovation specifically targeting amplification bias and homogeneity is **D3 (Decoding Matters)**. D3 directly confronts these issues by proposing to disable ghost tokens in length normalization during the decoding process [17]. Furthermore, it introduces a text-free auxiliary model designed to encourage the generation of tokens less frequently produced by LLMs. This dual approach significantly reduces amplification bias and enhances recommendation diversity by actively countering homogeneity, preventing the over-recommendation of similar items or the propagation of biases inherent in LLM generation [17]. Another approach to enhance diversity is **GANPrompt**, which uses a Generative Adversarial Network (GAN) framework to construct a "diversity data generator." This generator incorporates multi-dimensional attribute information and is optimized with a diversity constraint to prevent the generation of single and repetitive textual content, thereby promoting variety in generated recommendations [9]. Similarly, **RLMRec** aims to mitigate noise and bias in implicit feedback by leveraging LLM-empowered representations to capture intricate semantic aspects of user behaviors, which can inherently reduce data bias stemming from limited interaction data [15].

The importance of addressing fairness and mitigating bias extends beyond specific algorithmic solutions, encompassing a broader commitment to ethical AI. General LLM research rigorously investigates these concerns, with projects like "Fairness in AI and Machine Learning" exploring various facets of user-oriented and personalized fairness, including specific papers such as "User-oriented Fairness in Recommendation" and "Fairness-aware Federated Matrix Factorization" [23]. Furthermore, works like "Probing into the Fairness of Large Language Models: A Case Study of ChatGPT" and "MoralBench: Moral Evaluation of LLMs" directly investigate and evaluate fairness and ethical considerations in LLMs [23]. Initiatives like "UP5: Unbiased Foundation Model for Fairness-aware Recommendation" aim to develop inherently unbiased foundation models [23]. The field explicitly recognizes "bias and fairness in LLM-powered recommendation systems" as a critical research area, emphasizing the ethical use of generative models and the need to evaluate and mitigate unfairness [14]. This underscores the paramount importance of addressing ethical considerations and building trust to foster trustworthy and equitable recommendation experiences [14,20].
## 6. Evaluation and Benchmarking in LLM-based Recommendation
The advent of Large Language Models (LLMs) has introduced a paradigm shift in recommendation systems, necessitating a re-evaluation of established assessment methodologies to adequately capture their unique capabilities and limitations. This section provides a comprehensive overview of the critical aspects involved in evaluating and benchmarking LLM-based recommenders, integrating insights from the identification of key tasks and metrics, the characteristics of datasets, and the empirical performance observed in current research [10,13,22].



**Key Recommendation Tasks and Metrics for LLM-based RS**

| Task Category                   | Specific Tasks                                                                            | Key Traditional Metrics                                                                                             | LLM-Specific/Enhanced Metrics                                                                                                                               | Challenges for LLMs                                                                                                                                                                                                                                                                     |
| :------------------------------ | :---------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Traditional RS Tasks**        | - Rating Prediction                                                                       | - MAE, MSE, RMSE (for numerical predictions)                                                                          |                                                                                                                                                             | - Precision in numerical output.                                                                                                                                                                                                                                                        |
|                                 | - Top-K Recommendation / Item Ranking (point-wise, pair-wise, list-wise)                  | - NDCG, MRR, HR@k, Precision@k, Recall@k, MAP@k                                                                       |                                                                                                                                                             | - Autoregressive nature struggles with consistent list-based outputs.                                                                                                                                                                                                                   |
|                                 | - Sequential Recommendation / Next Item Prediction                                        | - NDCG, HR@k, MRR                                                                                                     |                                                                                                                                                             | - Capturing long-range dependencies, `LongSequenceHandling`.                                                                                                                                                                                                                          |
|                                 | - CTR Prediction                                                                          | - AUC, LogLoss                                                                                                        |                                                                                                                                                             | - Aligning with ID-based data, `ComputationalCost` for real-time.                                                                                                                                                                                                                       |
|                                 | - Cold-Start & Long-Tail Recommendation                                                   | - NDCG, HR@k (especially in sparse data scenarios)                                                                    |                                                                                                                                                             | - Inferring preferences from minimal data, avoiding `HallucinationRisk` for unseen items.                                                                                                                                                                                              |
|                                 | - i2i Recall                                                                              | - Precision, Recall                                                                                                   |                                                                                                                                                             | - Understanding implicit relationships from text.                                                                                                                                                                                                                                       |
| **LLM-Specific & Novel Tasks**  | - Explainable Recommendation                                                            |                                                                                                                       | - Qualitative Human Assessment (clarity, detail, effectiveness, relevance, logic, trust, satisfaction)                                                    | - Ensuring generated explanations are coherent, relevant, truthful, and comprehensible. `HallucinationRisk` in explanations.                                                                                                                                                           |
|                                 |                                                                                           |                                                                                                                       | - Quantitative NLP Metrics (ROUGE, BLEU) for text quality. FMR, FCR, DIV, USR for explanation characteristics.                                             | - Lack of standard benchmarks for explanation quality.                                                                                                                                                                                                                                  |
|                                 | - Conversational Recommendation Systems                                                   |                                                                                                                       | - Qualitative Human Assessment (conversational coherence, user satisfaction, responsiveness). ROUGE, BLEU for generated responses.                        | - Maintaining conversational coherence, user satisfaction, managing `DialogueManagementComplexity`, `Latency`.                                                                                                                                                                         |
|                                 | - Review Summarization                                                                    |                                                                                                                       | - ROUGE, BLEU (for summary quality).                                                                                                                        | - Generating concise, informative, and unbiased summaries.                                                                                                                                                                                                                              |
|                                 | - Generative Recommendation (new/creative items)                                          |                                                                                                                       | - Novelty metrics, diversity metrics. Qualitative assessment for relevance and utility of novel items.                                                     | - Evaluating quality/relevance of entirely novel content (standard metrics inadequate). Ensuring generated items are feasible/real. `HallucinationRisk`.                                                                                                                                |
|                                 | - Query Rewriting/Suggestion                                                              | - A/B testing on business metrics (GMV, transaction volume, visitor count). Qualitative assessment of relevance.        |                                                                                                                                                             | - Maintaining accuracy and relevance for long-tail queries.                                                                                                                                                                                                                           |
| **Overarching Evaluation Needs**|                                                                                           | - Business Metrics (GMV, conversion rates, click-through rates) in online A/B tests.                                  | - User Studies (for subjective experience, trust, utility). NPHardEval benchmarks for reasoning abilities.                                                  | - Adequacy of traditional metrics for generative/interpretive LLM outputs. Need for comprehensive, unbiased datasets. High cost of LLM APIs limiting experiments. |

The evaluation framework for LLM-based recommendation systems is inherently multifaceted, beginning with a distinction between traditional recommendation tasks and novel, LLM-specific generative and interpretability tasks. Traditional tasks, such as rating prediction, top-K recommendation, sequential recommendation, CTR prediction, cold-start, long-tail, and item-to-item recall, leverage established metrics like Normalized Discounted Cumulative Gain (NDCG), Mean Reciprocal Rank (MRR), Hit Rate (HR), Precision, Recall, Mean Average Precision (MAP), Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE). However, LLMs excel in and introduce new tasks, including explainable recommendation, conversational recommendation, review summarization, and generative recommendation. These unique capabilities demand a broader set of evaluation criteria, often integrating qualitative human assessments and Natural Language Processing (NLP) metrics such as ROUGE and BLEU scores, alongside novel quantitative measures like Feature Matching Ratio (FMR) and Feature Coverage Ratio (FCR) for explanation quality. The challenge intensifies with the autoregressive nature of LLMs, which can lead to structural inconsistencies in list-based outputs or the generation of entirely novel, unquantifiable content, highlighting the inadequacy of traditional metrics alone.

The efficacy of LLM-based recommenders is profoundly influenced by the datasets used for training, fine-tuning, and evaluation. Research employs a diverse range of datasets across domains like movies (e.g., MovieLens, ReDial), books (e.g., Amazon Books), music (e.g., Last.fm), news (e.g., MIND-small), e-commerce (e.g., Amazon Review, Yelp), and technical articles. These datasets vary significantly in structure and textual richness, from explicit titles to comprehensive user reviews and long documents, each impacting LLM performance differently. A persistent challenge is the reliance on existing datasets that are often "small, old," and prone to "overlap with LLM training data," potentially biasing zero-shot/few-shot evaluations by allowing models to "remember" rather than genuinely reason [18,19,26]. This underscores the critical need for novel, unbiased datasets, particularly those designed for parallel preference evaluation (e.g., language-based vs. item-based), to accurately assess LLMs in contexts like cold-start scenarios. The high cost of accessing advanced LLM APIs further constrains comprehensive benchmarking, limiting experiments to smaller data subsets.



**Empirical Performance of LLMs in Recommendation**

| Aspect/Comparison           | Observation/Finding                                                                                                                                                                                                                                                                                       | Key Influencing Factors                                                                                                                                                                                                 | Implications/Challenges                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| :-------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Accuracy-based Tasks**    | - Often exhibit "moderate skill" or "general performance."                                                                                                                                                                                                                                                | - Availability of interaction data: Traditional models "outperformed" LLMs when ample interaction data is available.                                                                                                     | - LLMs are not always superior to highly optimized traditional models for tasks where rich interaction data exists.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
|                             | - Significantly outperform simple baselines (Random, Popularity).                                                                                                                                                                                                                                         | - `No-tuning paradigm` usually "cannot surpass the performance of RS models specifically trained and optimized."                                                                                                       | - Direct, out-of-the-box application of generic LLMs may not be competitive.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
|                             | - Fine-tuned LLMs "still show some gap compared to traditional models."                                                                                                                                                                                                                                   | - `Fine-tuning quality`: Can improve performance but may not close the gap entirely.                                                                                                                                    | - Continued need for specialized optimization techniques.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
|                             | - "Perform poorly" in list-wise recommendation tasks.                                                                                                                                                                                                                                                     | - LLM training data and auto-regressive generation patterns.                                                                                                                                                          | - Inadequacy of LLM generation for structured list formats.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| **Interpretability-based Tasks**| - Performance "comparable to state-of-the-art methods."                                                                                                                                                                                                                                               | - Strong NLU and NLG capabilities of LLMs.                                                                                                                                                                            | - LLMs excel where natural language generation is key (e.g., providing explanations), offering a distinct advantage over black-box traditional systems.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
|                             | - Capable of generating "clearer, more reasonable results" (e.g., LANE, XRec).                                                                                                                                                                                                                            | - Sophistication of prompting (e.g., `Chain-of-Thought`).                                                                                                                                                             | - Enhances user trust and transparency.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| **Influencing Factors**     | - `Prompt Engineering`: Multi-prompt ensemble strategies (Prompt4NR) yield "substantial improvements."                                                                                                                                                                                                    | - Quality and design of prompts directly impact output.                                                                                                                                                               | - `PromptDesignComplexity` becomes a major factor for achieving optimal results.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
|                             | - `In-Context Examples`: Few-shot prompting generally "much better" than zero-shot; zero-shot "surpassed Random and Pop baselines."                                                                                                                                                                       | - Leveraging limited examples within the prompt.                                                                                                                                                                      | - Few-shot learning is highly effective, especially for cold-start.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|                             | - Increasing prompt shots/history items can introduce "Noise," degrading performance.                                                                                                                                                                                                                     | - `Information overload`: Not all context is beneficial.                                                                                                                                                              | - Careful selection and quantity of context are crucial.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
|                             | - `Retrieval Augmentation`: `ReLLa` and `KERAG_R` show "superiority over existing baseline models" by enhancing input quality.                                                                                                                                                                            | - Providing focused, relevant external information to the LLM.                                                                                                                                                          | - Crucial for improving performance, especially when raw sequences are problematic.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| **Domain-Specific Strengths** | - LLMs demonstrate best overall performance across multiple domains (e.g., ChatGPT).                                                                                                                                                                                                                      | - Intrinsic LLM knowledge and adaptability.                                                                                                                                                                           | - Potential for broad application, but performance varies by domain/data characteristics.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
|                             | - Excel in long document recommendation (e.g., technical articles) with "substantial improvements" (NDCG@5 up to 0.323).                                                                                                                                                                             | - Strong NLU capabilities for complex text.                                                                                                                                                                           | - Valuable for content-rich domains.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
|                             | - "Competitive" in cold-start scenarios, leveraging external knowledge/language-based preferences (`LLM Language Few-shot (3)` competitive with CF).                                                                                                                                                  | - Zero/few-shot learning, vast pre-trained knowledge.                                                                                                                                                                 | - Key advantage for mitigating data sparsity, a long-standing RS problem.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| **Industrial Applicability**| - Many studies are "offline survey-experimental type," lacking "industrial applicability" or "clear practical industrial application."                                                                                                                                                               | - `Online inference latency`, `ComputationalCosts`, `ScalabilityIssues`. High cost of LLM APIs.                                                                                                                       | - Significant gap between academic research and real-world deployment. Practical deployment requires substantial engineering and resource investment.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
|                             | - Some LLM recommendation models struggle with efficiency, showing "parameter redundancy and suboptimal performance."                                                                                                                                                                                 | - Lack of specific optimization for recommendation tasks in generic LLMs.                                                                                                                                             | - LLMs often need careful "alignment, fine-tuning, or knowledge integration" to achieve beneficial performance.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
|                             | - Breakthroughs with online A/B tests (Meta's "Actions Speak Louder than Words," Alibaba's BEQUE & SINGLE, Huawei's ReLLa) demonstrate real-world impact.                                                                                                                                              | - Targeted LLM integration, substantial engineering effort, optimized for industrial scale.                                                                                                                             | - Proves that with sufficient investment, LLMs can yield significant performance gains and real-world applicability in industrial systems.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| **Known Issues**            | - "Incorrect Ranking with Explanations," refusal to answer, "PositionalBias," `HallucinationRisk` (creating non-existent things).                                                                                                                                                                   | - Inherent limitations of generative models, specific biases (e.g., position, popularity, factual accuracy).                                                                                                        | - These issues undermine user trust and system reliability, necessitating robust mitigation strategies.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |

Empirical performance analysis reveals a nuanced landscape. While LLMs often demonstrate "moderate skill" or "general performance" in accuracy-focused traditional tasks, often being "outperformed" by highly optimized traditional models when ample interaction data is available, they show "comparable to state-of-the-art methods" performance in interpretability-based tasks, generating "clearer, more reasonable results" [13,21,22]. Factors like sophisticated prompt engineering (e.g., multi-prompt ensemble strategies), the number of in-context examples (few-shot outperforming zero-shot), and particularly retrieval augmentation (e.g., ReLLa, KERAG_R) significantly influence performance, often leading to substantial improvements. LLMs also exhibit domain-specific strengths, excelling in long document recommendation and proving "competitive" in cold-start scenarios by leveraging external knowledge or language-based preferences. Despite promising offline results, a significant gap exists between academic research and industrial applicability, primarily due to online inference latency, computational costs, and scalability issues, with many studies described as "offline survey-experimental type" and lacking clear practical industrial application [1,10,11,12,20,22]. Nonetheless, recent breakthroughs validated by online A/B tests (e.g., Meta's "Actions Speak Louder than Words," Alibaba's BEQUE and SINGLE) demonstrate that targeted LLM integration can yield significant performance gains and real-world impact, despite challenges like "Incorrect Ranking with Explanations," refusal to answer, positional bias, and `HallucinationRisk` [1,7,10].

In conclusion, evaluating LLM-based recommendation systems demands an evolving, hybrid approach that reconciles traditional accuracy metrics with advanced NLP assessments and rigorous qualitative human evaluations. Addressing the limitations of current datasets, fostering the development of new, unbiased benchmarks, and surmounting practical challenges related to efficiency and scalability are paramount. Future research must focus on developing comprehensive evaluation frameworks that robustly assess the unique generative and interpretive capabilities of LLMs while ensuring their practical applicability and societal impact within the complex landscape of recommendation. This will pave the way for a more holistic understanding and effective deployment of LLMs in future recommendation paradigms.
### 6.1 Key Recommendation Tasks and Metrics
Large Language Models (LLMs) are being increasingly applied to a diverse array of recommendation tasks, presenting both opportunities and specific challenges for integration. These tasks can be broadly categorized into traditional recommendation paradigms and those that leverage the unique generative and natural language understanding capabilities of LLMs.

**Key Recommendation Tasks Addressed by LLMs:**

1.  **Traditional Recommendation Tasks**:
    *   **Rating Prediction**: This task involves predicting a user's numerical rating for an item [10,13,18,19]. Challenges for LLM integration include handling the precise numerical output and distinguishing it from generative text.
    *   **Top-K Recommendation/Item Ranking**: The objective is to identify and rank the most relevant items for a user [1,10,27]. This encompasses various ranking granularities, including `point-wise`, `pair-wise`, and `list-wise ranking` [21,28]. A significant challenge here is that LLMs, due to their autoregressive training, might struggle with generating list-based recommendations consistently, potentially deviating from instructed formats or producing incorrect structures [18,26].
    *   **Sequential Recommendation / Next Item Prediction**: This task focuses on predicting the next item a user will interact with based on their historical sequence of interactions [3,5,8,13,18,29]. LLMs are applied to improve sequential understanding, especially in zero-shot and few-shot scenarios [11].
    *   **CTR Prediction**: A common task in online advertising and recommendation, aiming to predict the likelihood of a user clicking on a recommended item [7,12,27].
    *   **Cold-Start Recommendation**: Addressing the challenge of recommending items to new users or recommending new items with limited interaction data [20].
    *   **Long-tail Recommendation**: Improving recommendations for less popular items or users with niche interests [7].
    *   **i2i Recall**: Enhancing item-to-item recall, crucial for finding similar items [12].

2.  **LLM-Specific Generative and Interpretability Tasks**:
    *   **Explainable Recommendation**: Generating natural language explanations for recommended items [3,7,8,13,17,18,27]. The primary challenge lies in ensuring the generated explanations are coherent, relevant, truthful, and comprehensible to users.
    *   **Conversational Recommendation Systems**: Facilitating interactive recommendation experiences where LLMs engage in dialogue with users to refine recommendations [17,23,27]. This requires robust natural language understanding and generation, as well as maintaining conversational coherence and user satisfaction.
    *   **Review Summarization**: Condensing multiple user reviews into concise, informative summaries to aid user decision-making [3,8,13,18].
    *   **Generative Recommendation**: Generating new, potentially unseen items or creative recommendations based on user preferences and context [11,23]. A significant challenge is effectively evaluating the quality and relevance of newly generated content, which standard metrics may not fully capture [18,26].
    *   **Query Rewriting/Suggestion**: Improving search quality by rewriting long-tail queries or providing personalized, contextually relevant query suggestions [11].

**Standard Evaluation Metrics and Their Applications:**

For traditional recommendation tasks, a suite of standard metrics is commonly employed to quantify recommendation quality.

*   **Ranking-focused Metrics**: These metrics assess the quality of an ordered list of recommendations:
    *   **Normalized Discounted Cumulative Gain (NDCG)**: Measures the ranking quality by giving higher scores to relevant items appearing at higher ranks [1,5,18,19,20,23,28]. The formula is $$NDCG(k) = \frac{DCG}{IDCG}$$ where $$DCG(k) = \frac{1}{|U|} \sum _{u=1}^{|U|} \sum _{i=1}^{k} \frac{G_i}{\log _2 (i + 1)}$$. Here, $G_i$ represents the gain from the item at position $i$ in the ranked list, and IDCG is the ideal DCG for a perfect ranking.
    *   **Mean Reciprocal Rank (MRR)**: Evaluates how high the first relevant item appears in the ranked list, with higher scores for relevant items found earlier [1,19]. It is calculated as $$MRR = \frac{1}{|U|} \sum _{u=1}^{|U|} \frac{1}{\text{rank}^*_u}$$, where $\text{rank}^*_u$ is the rank of the first relevant item for user $u$.
    *   **Hit Rate (HR)** or **Hit@k**: Measures whether a target item is present in the top-K recommendations [5,19,23,28]. $$HR@k = \frac{1}{|U|} \sum _{u=1}^{|U|} (Hit@k)_u$$, where $(Hit@k)_u$ is 1 if a relevant item is within the top $k$ for user $u$, and 0 otherwise.
    *   **Precision and Recall**: Standard classification metrics adapted for recommendation, often denoted as P@k and R@k, measuring the proportion of relevant items among recommended ones and the proportion of relevant items found, respectively [19,23]. $$P@k = \frac{1}{k} \sum _{i=1}^{k} \text{rel}(i)$$ and $$R@k = \frac{1}{|T|} \sum _{i=1}^{k} \text{rel}(i)$$.
    *   **Mean Average Precision (MAP@k)**: Averages the Average Precision (AP@k) across all users, providing a single-figure measure of ranking quality, especially useful when there are multiple relevant items [19]. $$MAP@k = \frac{1}{|U|} \sum _{u=1}^{|U|} (AP@k)_u$$.

*   **Rating Prediction Metrics**: For tasks involving numerical rating predictions:
    *   **Mean Absolute Error (MAE)**: Averages the absolute difference between predicted and actual ratings [19]. $$MAE = \frac{1}{N} \sum _{u,i} \left| \hat{y}_{u,i} - y_{u,i} \right|$$.
    *   **Mean Squared Error (MSE)** and **Root Mean Squared Error (RMSE)**: Penalize larger errors more heavily, with RMSE maintaining the same unit as the rating scale [18,19]. $$MSE = \frac{1}{N} \sum _{u,i} \left( \hat{y}_{u,i} - y_{u,i} \right) ^2$$ and $$RMSE = \sqrt{\frac{1}{N} \sum _{u,i} \left( \hat{y}_{u,i} - y_{u,i} \right) ^2}$$.

**Application of Metrics in Empirical Studies and Business Contexts:**

In empirical studies, LLM-based recommenders are evaluated using these standard metrics, often benchmarking against traditional CTR models [11]. For instance, ReLLa, a retrieval-augmented LLM for sequential recommendation, was benchmarked against traditional CTR models like DCNv2, DIN, and SIM, demonstrating significant outperformance in few-shot scenarios [11]. Online A/B tests often employ business-oriented metrics to directly measure real-world impact. For example, in long-tail query rewriting, improvements are quantified by **Gross Merchandise Volume (GMV), transaction volume, and visitor count** [11]. Article recommendation systems have shown tangible improvements, such as a 2.4% increase, in online A/B tests [11].

**Adequacy of Current Metrics for Unique LLM Capabilities:**

While traditional metrics are suitable for evaluating accuracy-based tasks like rating prediction and item ranking, they fall short in assessing the unique generative and interpretive capabilities of LLM-based systems.

*   **Explainability**: The quality of explanations generated by LLMs requires more nuanced evaluation beyond standard performance metrics. Studies have employed qualitative human assessment, using expert scoring across multiple indicators such as clarity, detail, effectiveness, relevance, logic, trust, and user satisfaction [9]. Quantitative metrics like **Feature Matching Ratio (FMR), Feature Coverage Ratio (FCR), Feature Diversity (DIV), and Unique Sentence Ratio (USR)** are also proposed to validate and characterize the generated explanations [19].
*   **Conversational Fluency and Generative Quality**: For conversational recommendation and tasks like review summarization or generative recommendation, metrics typically used in natural language processing (NLP) are more appropriate. These include **ROUGE (Recall-Oriented Understudy for Gisting Evaluation)** and **BLEU (Bilingual Evaluation Understudy)** scores, which measure the overlap and similarity between generated and reference texts [19]. However, evaluating truly "generative recommendation" â€” where LLMs might create previously unseen or novel items â€” remains an open question, as standard metrics cannot effectively assess this capability if the generation process is not constrained to historical data [18,26].
*   **Challenges in Evaluation**: A key challenge arises from LLMs' autoregressive training, which can lead to deviations from instructed output formats, especially for list-based recommendations, and difficulties in ensuring structural correctness or preventing refusals to answer [18]. Furthermore, human assessment of qualities like contextual relevance, personalization, and utility is often necessary for tasks like personalized contextual query suggestion [11]. The NPHardEval benchmarks, designed to assess reasoning abilities, are also relevant for complex, reasoning-heavy recommendation tasks [23].

In conclusion, while traditional metrics provide a foundational assessment for LLM-based recommenders, there is an evident need for a more comprehensive evaluation framework that incorporates both qualitative human judgments and specialized NLP metrics to adequately capture the unique strengths of LLMs in tasks like explanation generation, conversational interaction, and novel content generation. This hybrid approach is crucial for a holistic understanding of LLM performance in modern recommendation systems.
### 6.2 Datasets for LLM-based Recommendation
The efficacy of Large Language Models (LLMs) in recommendation systems (RS) is profoundly influenced by the characteristics of the datasets employed for training, fine-tuning, and evaluation. Research in this domain utilizes a diverse array of datasets, categorized primarily by domain and exhibiting varied data structures [1,5].

**Representative Datasets and Their Structures:**

Commonly adopted datasets span multiple domains, each presenting distinct features and influencing experimental design.
*   **Movie Domain:** Datasets such as MovieLens-1M, MovieLens-20M, and MovieLens-25M are widely used [1,19]. These typically include user IDs, item IDs, ratings, timestamps, and crucial textual metadata such as movie titles and genres, enabling the construction of user behavior sequences and semantic representation of items [5]. Conversational datasets like ReDial and TG-ReDial also focus on movie recommendations, providing annotated conversations between users and recommenders [19].
*   **Book Domain:** Amazon Books and Goodreads Book Reviews are prominent examples, featuring user-book interactions, reviews, and book attributes [1,19].
*   **Music Domain:** Datasets like Amazon Music, LFM-2M, and Last.fm provide user-artist/track listening events [1,26].
*   **News Domain:** MIND-small (Microsoft News Dataset) is a benchmark for news recommendation, comprising news articles and extensive user interactions [1,19].
*   **E-commerce and Products:** Datasets such as Amazon Review (across various categories), Yelp, Tmall, and RetailRocket contain product reviews, ratings, user-item interactions, and behavioral data [19,26]. Internal datasets like Alibaba ATA are also utilized for specific tasks like article recommendation [11].
*   **Gaming:** The Steam dataset captures user reviews, purchases, and game bundle data [19,26].
*   **Technical Articles/Long Documents:** Platforms akin to CSDN and Zhihu contribute datasets with millions of samples and hundreds of thousands of candidate long documents, characterized by strong logical structures and dynamic content influx [28]. Similarly, academic papers form the corpus for LLM applications in platforms like YiYi AI, showcasing the use of domain-specific, complex textual data [33].
*   **Specialized Datasets:** Novel datasets are designed for specific tasks, such as BEQUE for query rewriting using rejection sampling and auxiliary task mixing [11]. Additionally, user interaction history and search logs, especially from sources like Microsoft, are leveraged to build entity-centric user knowledge stores, relying on implicit behavioral data and potentially public knowledge graphs [11]. `UserBert` also utilizes unlabeled behavioral data for pre-training tasks [24].

**Influence of Dataset Nature on Experimental Design and LLM Performance:**

The inherent nature of these datasets significantly dictates experimental design and the observed performance of LLMs. Datasets in domains like movies, books, and music often feature "explicit or popular titles," allowing LLMs to leverage concise textual identifiers. In contrast, the news domain, exemplified by MIND-small, is characterized by "content-based attributes rather than title attributes," necessitating LLMs to process and understand richer, longer textual content [1]. This distinction underscores how LLM performance varies across domains, with models needing to adapt their understanding and generation capabilities based on the textual granularity available. For instance, the LANE framework emphasizes item titles for user interaction sequences, highlighting the reliance on textual item metadata for representation [9]. Similarly, the conversion of CTR prediction samples into textual descriptions and the use of user historical item text sequences for generating user interest preferences demonstrate the reliance on textual features and the potential for synthetic data generation to enrich datasets for LLM training in recommendation contexts [7].

**Challenges and Opportunities in Dataset Availability and Quality:**

Despite the variety, the field faces significant challenges regarding dataset availability and quality. A pervasive issue is the reliance on existing datasets that are often "small, old" and may "overlap with LLM training data" [19,26]. This overlap can bias zero-shot/few-shot evaluations, potentially leading to an overestimation of LLM capabilities by allowing models to "remember" pre-existing information rather than genuinely reasoning [18]. Such limitations can "affect recommendation results" and impede a true assessment of LLMs' recommendation prowess [26].

Furthermore, there is a notable lack of suitable test datasets that fully capture the linguistic and generative aspects LLMs leverage [19,22]. The high cost associated with advanced LLM APIs like GPT-4 often constrains researchers to conduct experiments with "a very small portion of data," thereby limiting the scope and reliability of benchmarking efforts [27]. This highlights a critical need for more robust, unbiased datasets, particularly for specific LLM-based tasks such as language-based preference evaluation [20,26]. The scarcity of support for non-English data in existing open-source models also presents a challenge for broader application [8].

**Novel Datasets for Parallel Preference Evaluation:**

Addressing this critical gap, a significant contribution comes from novel datasets specifically designed to compare language-based and item-based preferences directly [20]. One such dataset was collected through a two-phase user study involving 153 raters in the movie domain, chosen for its familiarity to participants. In Phase 1, raters provided natural language descriptions of both liked (`descr+`) and disliked (`descr-`) movies, alongside naming five liked (`itemr,j+`) and five disliked (`itemr,j-`) example movies. Phase 2 involved these raters assessing recommendations from various sample pools, including unbiased popular, less popular, personalized item-based (SP-EASE), and personalized language-based (SP-BM25-Fusion) recommendations [20].

This dataset is characterized by its inclusion of parallel item-based and language-based preferences from the same raters, ensuring consistency in comparisons. It also features ratings for both "seen" and "unseen" items, with an emphasis on creating an "Unbiased Set" for fair evaluation. Although small-scale, this design choice was deliberate to ensure consistency and relevance for near cold-start conversational settings, where minimal preference information is typically available. This innovative dataset allows for a direct quantitative comparison between LLM-based methods utilizing natural language preferences and traditional item-based collaborative filtering techniques, providing invaluable insights into their respective strengths and weaknesses [20].
### 6.3 Empirical Performance Analysis
The empirical performance of Large Language Models (LLMs) in recommendation tasks presents a nuanced landscape, demonstrating both promising advancements and inherent limitations when compared against established baselines.

Current research indicates that LLMs often exhibit "moderate skill" or "general performance" in accuracy-focused recommendation tasks, such as sequential or direct recommendation [10,13,22]. For instance, studies comparing LLMs (e.g., ChatGPT, text-davinci-002, text-davinci-003) against traditional models like Matrix Factorization (MF) and Neural Collaborative Filtering (NCF) reveal that while LLMs significantly outperform simple baselines like Random and Popularity, they are often "outperformed" by traditional models when "given enough user-item interactions," highlighting the continued value of explicit interaction data for these conventional approaches [1]. Furthermore, systems built solely on a no-tuning paradigm typically "cannot surpass the performance of recommendation models specifically trained and optimized" for particular tasks and datasets, and the overall performance of fine-tuned LLMs "still shows some gap compared to traditional models" [21,26,27]. Specifically, LLMs "perform poorly" in list-wise recommendation tasks due to their training data and auto-regressive generation patterns [22,26]. Some pure text-based LLM recommendation models have even been noted for "parameter redundancy and suboptimal performance" when directly applied [7].

Conversely, in interpretability-based tasks, LLMs demonstrate performance "comparable to state-of-the-art methods" and are capable of generating "clearer, more reasonable results" [13,21,22]. For example, `LANE` achieved optimal explanation quality across seven metrics, including clarity, logic, and satisfaction [9]. `XRec` also surpasses traditional explainable recommendation systems in generating comprehensive and meaningful explanations [17]. These findings underscore LLMs' strong natural language understanding and generation capabilities, which are crucial for providing transparent and understandable recommendations.

Several factors significantly influence LLM performance. The sophistication of prompt engineering plays a vital role. Multi-prompt ensemble strategies, as demonstrated by `Prompt4NR`, can yield "substantial improvements" in news recommendation performance, surpassing single-prompt results [21,24]. The number of in-context examples (zero-shot vs. few-shot) also impacts performance. While zero-shot prompting generally "surpassed Random and Pop baselines," indicating LLMs' inherent capabilities, few-shot prompting typically performed "much better" in most scenarios, showcasing the effectiveness of in-context learning [1]. However, increasing the number of prompt shots or history items did not consistently lead to better results, as additional context could introduce "Noise," negatively impacting performance [1]. In near cold-start scenarios, `LLM Language Few-shot (3)` was competitive with item-based collaborative filtering, yet increasing examples beyond three did not yield further improvements [20]. Retrieval augmentation, as exemplified by `ReLLa` and `KERAG_R`, has emerged as a critical technique; `ReLLa` showed "superiority over existing baseline models" by enhancing the input quality to the LLM via semantic retrieval, while directly feeding long, raw sequences to LLMs often resulted in poor performance [5,6].

LLM performance can vary significantly across different recommendation domains. For instance, `ChatGPT` demonstrated the best overall performance across four tested domains, while the `P5` model's performance, though generally "good," varied by dataset [1,3]. In specific domains, such as long document recommendation (e.g., technical articles), LLM-based methods (e.g., chatglm6b/chatm6) achieved "substantial improvements" over state-of-the-art news recommendation models, with `NDCG@5` reaching 0.323 compared to 0.281-0.289 for traditional models [28]. Moreover, LLMs excel in cold-start scenarios, where they act as "competitive" recommenders, particularly when leveraging external knowledge or language-based preferences, showing "significant competitiveness" against item-based collaborative filtering methods [20,26,28]. `LLM-ESR` enhances sequential recommendation for long-tail users and items without additional computational overhead [17]. These variations can be attributed to diverse data characteristics (e.g., text richness, sequence length) and inherent model limitations (e.g., handling long sequences, positional bias) [1].

Despite these advances, a critical analysis reveals that many studies are of an "offline survey-experimental type" and often "lack industrial applicability" or have "unclear practical industrial application" [1,10,11,12,20,22]. This is largely due to challenges such as online inference latency, computational costs, and scalability issues [1,10,12,28]. The high cost of LLM APIs often restricts experiments to "a very small part of the data," hindering robust benchmarking [27]. The "Elephant in the Room" paper explicitly states that some LLM recommendation models struggle with efficiency, indicating that LLMs often need careful "alignment, fine-tuning, or knowledge integration" to achieve beneficial performance [7]. Furthermore, issues such as "Incorrect Ranking with Explanations," refusal to answer, and "PositionalBias" have been observed, alongside the risk of `HallucinationRisk` where LLMs "create some things that do not exist" [1,10].

However, there have been notable breakthroughs demonstrating real-world impact through online A/B tests. Meta's "Actions Speak Louder than Words" is recognized as a "significant breakthrough," being the first to surpass traditional recommendation system recall and ranking modules in a large-scale industrial setting [12]. Similarly, Alibaba's `BEQUE` showed "significant improvements" in GMV, transaction volume, and visitor count through online A/B tests and has been deployed since October 2023 [11]. Another Alibaba system, `SINGLE`, achieved a "2.4% improvement" in online A/B tests, leading to more personalized and diverse articles [11]. `ReLLa` from Huawei demonstrated "superiority over existing baseline models" and, in few-shot settings using less than 10% of training samples, "outperformed traditional CTR models" (DCNv2, DIN, SIM) trained with the entire dataset [11]. These examples highlight that while substantial engineering challenges persist, targeted LLM integration can yield significant performance gains and real-world applicability in industrial systems.
## 7. Ethical Considerations and Societal Impact
The deployment of Large Language Models (LLMs) in recommendation systems necessitates a thorough examination of ethical considerations and their potential societal impact, particularly concerning value alignment, user privacy, and various forms of bias. A critical aspect is **Value Alignment**, which ensures that LLM outputs align with human values and social norms, especially in sensitive recommendation contexts [16]. Approaches such as In-Context Learning (ICL) are explored to imbue LLMs with value principles, investigating how different value sets influence the perceived fairness and trustworthiness of recommendations [16]. The challenge lies in adapting LLMs to the dynamic and diverse nature of human values, which evolve across time and cultures. To address this, On-the-fly Preference Optimization (OPO) has been proposed, utilizing an external memory to store and update alignment rules without necessitating model retraining, thereby allowing for flexible customization of human values [16]. Furthermore, interpretability frameworks, such as LANE, enhance Value Alignment by generating "explainable reasons" that foster user understanding and trust, potentially mitigating data biases through transparent reasoning [9]. For platforms like "YiYi AI," Value Alignment is crucial for maintaining scholarly integrity and accuracy in academic translation and summarization, preventing misrepresentation or `HallucinationRisk` [33]. The broader "Explainable AI" project also underscores Value Alignment for human comprehension and trust [23].

Privacy challenges represent another significant ethical concern in data-intensive LLM-based recommendation systems [10,11,19]. While privacy auditing and differential privacy are often discussed in the context of Federated Learning (FL), particularly for DP-SGD in centralized settings, their principles can be conceptually extended to protect sensitive user information in LLM-driven recommendation [16]. However, applying centralized auditing methods to FL algorithms like DP-FedAvg and DP-FedSGD drastically increases computational costs, highlighting the need for novel methods tailored to distributed environments [16]. Mitigation strategies include anonymous authentication in blockchain-based FL, where users employ different identities for each training round, ensuring unlinkability between parameters and identities to enhance privacy without compromising accuracy or incurring high cryptographic costs [16]. Another practical approach, exemplified by Microsoft's Personalized Contextual Query Suggestion, involves constructing lightweight, entity-centric user knowledge stores by projecting user interests onto public knowledge graphs, effectively mitigating privacy, compliance, and scalability issues associated with deep personal user profiles [11]. This demonstrates efforts to balance personalization with privacy protection, acknowledging the inherent trade-offs between privacy and model utility.



**Ethical Considerations: LLM Biases and Mitigation**

| Bias Type               | Description                                                                                                                                                                        | Mitigation Strategies                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | Impact on RS                                                                                                       |
| :---------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- |
| **Position Bias**       | LLMs prioritize items presented earlier in textual sequences; struggle to capture true order.                                                                                        | - Random sampling of input sequences. <br> - Shuffling candidate lists and averaging scores.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | Incorrect ranking, reduced fairness in item exposure.                                                                      |
| **Popularity Bias**     | LLMs over-recommend frequently appearing/discussed items from pre-training corpus; marginalizes niche/long-tail items.                                                               | - Infusing collaborative knowledge through fine-tuning. <br> - Diversity-promoting generators (e.g., GANPrompt).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | Reduces diversity, leads to `HomogeneityIssue`, limits user discovery of novel content.                                    |
| **Fairness Bias**       | LLMs reflect societal biases from training data (e.g., gender, race), leading to discriminatory or stereotypical recommendations.                                                     | - Structured prompt templates to neutralize non-preference entities. <br> - Unbiased foundation models (e.g., UP5). <br> - Addressing fairness is a critical research area (e.g., MoralBench, Probing Fairness of ChatGPT).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | Unequal treatment, raises ethical concerns, compromises trustworthiness.                                                   |
| **Amplification Bias**  | Typical decoding processes over-prioritize items with "ghost tokens," skewing scores.                                                                                                | - D3 (Decoding Matters): Disabling 'ghost tokens' in length normalization.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | Skewed or unfair recommendations.                                                                                          |
| **Homogeneity Issues**  | LLMs generate similar/repetitive items, reducing diversity, reinforcing preferences, leading to `echo chambers`.                                                                     | - D3: Auxiliary model to encourage generation of less frequent tokens. <br> - GANPrompt: Diversity data generator with diversity constraints.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | Reduced diversity, lack of serendipity, reinforces existing preferences, forms `echo chambers`.                            |
| **Content Bias**        | LLMs prioritize textual similarity over actual user preferences (e.g., BERT focus on content).                                                                                       | - Fine-tuning LLMs with task-specific knowledge to balance textual understanding with behavioral signals.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | Recommendations that are textually similar but do not reflect user co-consumption patterns.                                |
| **Negative Transfer**   | Over-generalization from uniform fine-tuning, leading to unfairness for individual users.                                                                                            | - iLoRA (Instance-wise LoRA with MoE) for individualized adaptation.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | Inaccurate or unfair recommendations for specific users.                                                                   |
| **Value Alignment**     | Ensuring LLM outputs align with human values and social norms, especially in sensitive contexts.                                                                                     | - In-Context Learning (ICL) to imbue value principles. <br> - On-the-fly Preference Optimization (OPO) with external memory for dynamic value customization. <br> - Interpretability frameworks (e.g., LANE) for transparent reasoning. <br> - Ensuring scholarly integrity and preventing misrepresentation (YiYi AI).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Leads to inappropriate or untrustworthy recommendations.                                                                   |
| **Privacy Challenges**  | Risk of exposing sensitive user information in data-intensive LLM-based RS.                                                                                                        | - Conceptual extension of privacy auditing and differential privacy (from FL). <br> - Anonymous authentication in blockchain-based FL. <br> - Lightweight, entity-centric user knowledge stores (e.g., Microsoft's Contextual Query Suggestion).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | Violation of user privacy, legal/ethical risks.                                                                            |
| **`HallucinationRisk`** | Generation of plausible but factually incorrect, non-existent, or misleading recommendations (impacts trust).                                                                        | - Knowledge-Augmented Generative Recommendation (KAGR) with verifiable explanations using updated knowledge graphs. <br> - LLMs as controllers (deciding between recommending existing items or generating novel ones). <br> - Clearer justifications (explainability) to enhance trust.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | Degrades user trust, provides incorrect information, reduces utility of recommendations.                                   |
| **Overall Goal**        | Ensuring LLM-based RS are safe, robust, non-discriminatory, and explainable. Balancing recommendation accuracy with ethical implications.                                          | - Continued diligent research into safety, robustness, non-discrimination, and explainability. <br> - Ethical use of generative models, integrating fairness, accountability, transparency.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | Compromises user trust, limits broad adoption, potential for negative societal impact if left unaddressed.                  |

Bias issues are pervasive in LLM-based recommendation systems, stemming from the vast knowledge bases LLMs are trained on, as well as the inherent overfitting challenges observed in traditional recommender systems [10,28]. These biases can lead to unequal treatment, reduced diversity, and compromised trustworthiness [14,19,22]. Several types of biases have been identified:
*   **Position Bias**: LLMs tend to prioritize items presented earlier in textual sequences, influencing ranking results [1,21,22]. Mitigation strategies include random sampling, shuffling candidate lists, and score averaging [21,22].
*   **Popularity Bias**: Due to the frequent appearance of popular items in LLM training corpora, LLMs often recommend them more often, which can reduce diversity and is considered a challenging `DataBias` to mitigate [19,22].
*   **Fairness Bias**: Pre-trained LLMs can exhibit biases related to sensitive attributes (e.g., gender, race), leading to assumptions about user groups and potentially controversial recommendations [18,22,26]. Approaches like neutralizing non-preference attributes through careful prompt templating have been proposed to address this in conversational recommendation systems [18,24].
*   **Amplification Bias**: This bias, addressed by frameworks like D3, refers to the potential for LLMs' decoding strategies to over-prioritize items due to "ghost tokens," resulting in unfair or skewed recommendations [17].
*   **Homogeneity Issues**: LLMs can generate similar or repetitive items, reducing diversity, reinforcing existing preferences, and leading to `echo chambers` [17,19,28]. The D3 framework mitigates this through novel decoding methods, while GANPrompt's emphasis on diversity in generated prompts also contributes to more varied outcomes [9,17].
*   **Content Bias**: LLMs, particularly those focused on NLP like BERT, may prioritize textual similarity over actual user preferences, potentially leading to recommendations that are textually similar but do not reflect user-item co-consumption patterns [19]. Fine-tuning LLMs with task-specific knowledge can help balance textual understanding with behavioral signals [19].
*   **Negative Transfer**: Over-generalization from uniform fine-tuning can lead to unfairness for individual users, a challenge that iLoRA addresses through instance-wise LoRA and Mixtures of Experts (MoE) for individualized adaptation [17].

To underscore the importance of addressing fairness and mitigating bias, general LLM research actively investigates these issues. Projects such as "MoralBench" and "Probing into the Fairness of Large Language Models: A Case Study of ChatGPT" directly examine bias and moral aspects within LLMs [23]. The recognition that LLMs, with their vast knowledge, can potentially "break" the limitations of traditional systems and mitigate inherent biases is crucial [3,28]. However, this potential must be realized through diligent research into safety, robustness, non-discrimination, and explainability, which are critical future directions for trustworthy LLM-based recommender systems [10]. Explainability, in particular, enhances user trust by providing clearer justifications for recommendations, despite the `HallucinationRisk` that can degrade this trust if not managed effectively [10,19]. Ultimately, ensuring the ethical use of generative models in sensitive domains like e-commerce, and integrating principles of fairness, accountability, and transparency, are paramount for building trustworthy and equitable recommendation experiences [14,18].
## 8. Future Directions and Open Problems

**Key Future Directions & Open Problems in LLM-based Recommendation**

| Problem Area                           | Description of Challenge                                                                                                                                                                                                                | Proposed Future Directions / Solutions                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| :------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **ID-LLM Alignment & Multi-modality**  | Disparity between LLM's linguistic pre-training and ID-based structured data. `TextOnlyReliance` limits application.                                                                                                                   | - Develop advanced multi-modal fusion architectures and specialized LLMs aligning text, IDs, images, video, audio at multiple layers. <br> - Novel architectural designs or unified embedding spaces that understand both ID and text semantics. <br> - Holistic integration of LLMs with collaborative signals, moving to collaborative learning within "Two Tower" architectures.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| **Nuanced User Preference & Behavior** | Including negative preferences doesn't consistently improve results. LLMs struggle with "lifelong sequential behavior incomprehension" (long/complex user data).                                                                         | - Sophisticated negative preference integration (contrastive learning, psychology-informed models, generating negative samples). <br> - Advanced dialogue management in conversational systems, robust to noise, inferring implicit needs (external KGs, multi-modal inputs). <br> - Continuous refinement of elicitation and utilization of nuanced user preferences and dynamic behavioral changes.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| **Efficiency & Scalability**           | High inference costs and computational requirements impede widespread deployment in real-world, large-scale industrial settings. Many works lack immediate industrial applicability.                                                   | - Engineering optimizations: quantization, pruning, knowledge distillation, RAG architectures (minimize online LLM inference). <br> - Parameter-efficient integration (advanced PEFT beyond LoRA). <br> - Specialized LLM architectures / inference optimization (early exiting, faster decoding, custom hardware). <br> - Leverage decreasing LLM API costs and high-performance open-source models (Llama3, Qwen2).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
| **Bias, Fairness & Generalizability**  | LLMs inherit/amplify biases (popularity, demographic, position, content, fairness) leading to homogeneous, unfair, or stereotypical recommendations. Need for broader generalizability across languages/cultures.                         | - Develop specific quantitative metrics and methodologies for bias detection/mitigation (debiasing at data, pre-training, fine-tuning, post-processing stages). <br> - Prioritize cross-cultural and multilingual validation, requiring better multilingual LLMs or cross-lingual adaptation. <br> - Embed ethical principles (fairness, accountability, transparency) inherently into design. <br> - Enhance resilience to perturbations and protect user privacy.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| **Dynamic User Profile Management**    | Traditional user profiles are static, fail to capture evolving interests. LLMs struggle with "lifelong sequential behavior incomprehension" for long sequences.                                                                          | - Encourage LLM-based systems for dynamic, evolving natural language user profiles (continuous updates, reconciling inconsistencies). <br> - Leverage lifelong/continual learning paradigms. <br> - Advanced techniques beyond sliding windows for long user behavior sequences. <br> - Adaptive fine-tuning (instance-wise adaptation) in real-time, balancing personalization and cost (MoE, novel PEFT).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| **Prompt Engineering & Fine-tuning**   | Current prompt engineering is brittle; simple prompts often suboptimal. Complexity of manual prompt design and generalization across datasets/languages.                                                                           | - Adaptive Instruction Tuning with Meta-Learning for Recommendation (AIMLR): LLMs learn to automatically generate effective, context-aware prompts. <br> - Improve representation of users/items within prompts for personalization. <br> - Refine fine-tuning strategies for stronger sequence-to-sequence models (large datasets, diverse languages). <br> - Optimize balance between fine-tuning and prompting.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| **Hallucination & Domain Knowledge Gap**| LLMs' generative nature + incomplete domain knowledge lead to plausible but incorrect/non-existent recommendations. `HallucinationRisk` undermines trust.                                                                         | - Knowledge-Augmented Generative Recommendation (KAGR) with Verifiable Explanations: Integrate specialized, continuously updated KGs and reasoning. <br> - Precise, context-aware knowledge extraction/integration. <br> - Develop vertical domain-specific LLMs. <br> - Explore LLMs as controllers in interactive systems (decide between existing vs. novel items for better control over factual accuracy).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| **Evaluation & Benchmarking**          | Lack of comprehensive metrics beyond traditional accuracy, especially for generative capabilities. Need for robust evaluation methods for list-wise, novel item generation, explainability, diversity, fairness. New datasets needed. | - Establish Community-driven Benchmarks for Generative and Ethical Recommendation (CBGER). <br> - Novel datasets for explainability, diversity, novelty, fairness of LLM-generated recommendations. <br> - Develop robust evaluation methods for novel item evaluation (no historical data) and consistency of LLM-generated explanations. <br> - Research on controlling LLM output format/content for RS requirements (e.g., list-wise tasks).                                                                                                                                                                                                                                                                                                                                                                                                                                                      |

The burgeoning field of Large Language Models (LLMs) for recommendation systems (RS) presents numerous challenges and opportunities for future research. This section synthesizes these into an integrated framework of critical problems and proposes actionable, innovative solutions aimed at rectifying existing shortcomings and advancing the state of the art.


**Problem:** Current approaches often exhibit limited benefit from simple combinations of language and item preferences, primarily due to the inherent disparity between LLMs' linguistic pre-training objectives and the ID-based, structured nature of traditional recommendation data. This creates a significant challenge in seamlessly aligning discrete item IDs with continuous textual semantics [19,20]. Furthermore, LLMs' reliance on text limits their application to primarily text-driven scenarios [11].

**Solution:** Future research should focus on developing advanced multi-modal fusion architectures and specialized LLM architectures that explicitly process and align embeddings from textual descriptions and item IDs at multiple layers [15,20]. This involves exploring deeper integration mechanisms to adapt to diverse recommendation types and scales, such as leveraging LLMs to generate rich, semantic user/item text embeddings for traditional collaborative filtering or within "Two Tower" architectures [9,12]. Novel architectural designs or unified embedding spaces that inherently understand both ID and text semantics are crucial to bridge the feature alignment complexity [7,21]. A holistic integration of LLMs with collaborative signals, moving beyond mere combination to collaborative learning, could further deepen dual-view modeling [17]. Additionally, extending to multimodal data (images, video, audio) with LLMs can enhance intelligence and personalization in complex scenarios [9,21].

**Impact:** These solutions foster a deeper synergy between traditional collaborative signals and semantic understanding, enabling more accurate, personalized, and broadly applicable recommendation models that overcome the inherent mismatch between language and item preferences. This will lead to enhanced collaborative filtering and graph representation learning by aligning collaborative information with semantic textual information [11].


**Problem:** Existing research indicates that including negative preferences does not consistently yield meaningful improvements, suggesting a superficial understanding or integration of user dislikes [20]. Moreover, LLMs often exhibit "lifelong sequential behavior incomprehension," struggling to process and reason over complex and long user behavioral data, which limits their ability to capture evolving user interests and subtle shifts in preference [5].

**Solution:** Research should advocate for sophisticated negative preference integration, potentially involving alternative prompt structures, explicit contrastive learning, or psychology-informed models of aversion to capture complex user dislikes and nuanced feedback [20]. Future work can explore richer forms of negative feedback, including implicit signals, and develop methods to balance positive and negative preference data more effectively. Investigating how LLMs can *generate* plausible negative samples for training could be a novel direction [17]. To address the dynamic nature of user preferences and long-term behavioral patterns, advanced dialogue management in conversational systems should be explored, focusing on making them robust to noise and enhancing reasoning capabilities to infer implicit user needs, possibly through external knowledge graphs or multi-modal inputs [17].

**Impact:** By refining the elicitation and utilization of nuanced user preferences, especially negative feedback and dynamic behavioral changes, recommendation systems can become more accurate, responsive, and robust, leading to a more satisfactory user experience that reflects complex individual tastes and evolving interests.


**Problem:** High inference costs and computational resource requirements remain a significant impediment to the widespread deployment of LLM-based recommendation systems in real-world, large-scale industrial settings [14,22]. Many current works are still "offline survey-experimental type" and lack immediate industrial applicability [11].

**Solution:** A concerted effort is required on engineering optimizations and novel architectural designs for efficiency. This includes quantization, pruning, knowledge distillation, and Retrieval-Augmented Generation (RAG) architectures that minimize online LLM inference, ensuring practical feasibility for large-scale industrial systems [7,14]. Parameter-efficient integration strategies and advanced fine-tuning techniques (e.g., advanced PEFT methods beyond LoRA) are crucial to reduce computational costs during training and adaptation [7,22]. Specialized LLM architectures or inference optimization techniques (e.g., early exiting, faster decoding, custom hardware acceleration) are also necessary to minimize inference latency and enable real-time applications [3,10]. The continuing decrease in LLM API costs and the emergence of high-performance open-source models (e.g., Llama3, Qwen2) will further facilitate research into more sophisticated models and integration strategies leveraging these accessible resources [27].

**Impact:** These solutions will make LLM-based recommendation systems industrially viable and scalable, enabling their deployment in real-time applications across massive user bases without prohibitive computational expenses or latency issues.


**Problem:** LLMs can inherit and amplify biases (e.g., popularity, demographic, position, content, fairness) from their vast training data, potentially leading to homogeneous, unfair, or stereotypical recommendations [22,23]. There is also a critical need for broader generalizability across diverse languages and cultures, alongside concerns regarding safety, robustness, and user privacy [10,20].

**Solution:** The development of specific quantitative metrics and methodologies for bias detection and mitigation is paramount. This includes exploring debiasing techniques tailored for LLM-based RS at various stages: data collection, pre-training, fine-tuning, or post-processing [22,26]. Prioritizing cross-cultural and multilingual validation is essential to ensure fairness and prevent the perpetuation of stereotypes in recommendations, requiring better multilingual LLMs or sophisticated cross-lingual adaptation techniques [8,20]. Furthermore, future LLM recommendation systems must inherently incorporate ethical principles like fairness, accountability, and transparency into their design and operation [10,21]. Enhancing resilience to perturbations and protecting sensitive user data are also vital for building trustworthy systems [10].

**Impact:** Addressing these ethical concerns will promote fairness, diversity, and robustness in recommendations, ensuring equitable treatment of different user groups and item categories, thereby enhancing user trust and broadening the global applicability of LLM-based RS.


**Problem:** Traditional user profiles often possess a static nature, failing to adequately capture the evolving interests and preferences of users over time [31]. LLMs, while capable of understanding textual context, struggle with "lifelong sequential behavior incomprehension" and have limitations in handling long user behavior sequences, impeding the creation of truly dynamic and adaptive user representations [5,21].

**Solution:** Research should encourage LLM-based systems that enable dynamic and evolving natural language user profiles through continuous updates and reconciliation of inconsistencies over time [31]. This can leverage lifelong learning or continual learning paradigms to adapt to changing user interests, and employ advanced techniques beyond sliding windows to handle long user behavior sequences more effectively [21,26]. Adaptive fine-tuning mechanisms, such as instance-wise adaptation, should be extended to dynamic, real-time settings that continuously learn from new user interactions while balancing personalization and computational costs, possibly through sophisticated Mixture-of-Experts (MoE) gating mechanisms or novel parameter-efficient tuning (PEFT) techniques [17].

**Impact:** By enabling dynamic and continuously updated user profiles, recommendation systems can adapt in real-time to evolving user interests, providing more relevant and personalized recommendations that accurately reflect current preferences and behavioral patterns.


**Problem:** Current prompt engineering often exhibits brittleness, and simple prompts frequently lead to sub-optimal performance across diverse recommendation tasks [10]. The complexity of prompt design and the need for robust techniques that generalize across diverse datasets and languages represent significant hurdles [8,26].

**Solution:** Future work should focus on Adaptive Instruction Tuning with Meta-Learning for Recommendation (AIMLR), a paradigm where LLMs learn to automatically generate effective, context-aware prompts for diverse recommendation tasks, thereby reducing reliance on manual prompt engineering [10]. This includes improving the representation of users and items within prompts for enhanced personalization [26]. Research should also explore the optimal balance between fine-tuning and prompting techniques for tailoring LLMs to specific tasks, along with refining fine-tuning strategies for stronger sequence-to-sequence models, particularly for large datasets and diverse languages [14,21].

**Impact:** These advancements will make LLM-based recommendation systems more adaptive, robust, and less reliant on labor-intensive manual prompt engineering, enabling them to achieve superior performance across a wider array of complex recommendation scenarios.


**Problem:** The inherent generative nature of LLMs, coupled with their often incomplete domain-specific knowledge, can lead to the generation of plausible but factually incorrect, non-existent, or misleading recommendations [6,33]. This "hallucination risk" and "domain knowledge gap" undermine user trust and the utility of LLM-generated outputs.

**Solution:** Advocating for Knowledge-Augmented Generative Recommendation (KAGR) with Verifiable Explanations is crucial. This approach involves integrating specialized, continuously updated knowledge graphs and reasoning mechanisms to provide factual grounding and prevent the generation of misleading or factually incorrect recommendations [6,10]. More precise and context-aware knowledge extraction and integration mechanisms, potentially incorporating user-specific feedback or external knowledge graphs, can guide the LLM's knowledge application, thereby reducing hallucination risks [7]. The development of vertical domain-specific LLMs, tailored for particular areas, can improve recommendation effectiveness and reduce the effort required from domain experts [10,12]. Furthermore, exploring the role of LLMs as controllers in interactive systems, deciding between recommending existing items or generating novel ones, represents a future direction for more dynamic and adaptive recommendation experiences with better control over factual accuracy [22].

**Impact:** By grounding LLM outputs in verifiable facts and domain-specific knowledge, these solutions will significantly enhance the trustworthiness and reliability of generative recommendations, ensuring accuracy and providing transparent explanations to users.


**Problem:** The current evaluation landscape for LLM-based recommendation systems lacks comprehensive metrics beyond traditional accuracy, especially for generative capabilities. There is a significant need for robust evaluation methods for list-wise tasks, novel item generation, explainability, diversity, novelty, and various fairness metrics, as well as new, suitable datasets [13,22]. The challenge of controlling LLM output format and content to align with recommendation system requirements also needs to be addressed [22].

**Solution:** Establishing Community-driven Benchmarks for Generative and Ethical Recommendation (CBGER) is essential. These benchmarks should include novel datasets specifically designed for evaluating explainability, diversity, novelty, and various fairness metrics for LLM-generated recommendations [13,22]. Future research should develop robust evaluation methods, including metrics for novel item evaluation that might not have historical interaction data, and techniques to ensure the accuracy and consistency of LLM-generated explanations [7,22]. Moreover, research is needed on how to better control LLM output format and content to align with recommendation system requirements, improving performance on list-wise recommendation tasks [22].

**Impact:** The establishment of comprehensive and standardized benchmarks will foster more holistic and responsible model development, provide clearer guidance for research directions, and enable more meaningful comparisons and tracking of progress in the evolving field of LLM-based recommendation.

In conclusion, the path forward for LLM-based recommendation systems involves a multi-faceted approach, addressing foundational issues from model architecture and efficiency to ethical considerations and comprehensive evaluation. By tackling these challenges with innovative and actionable solutions, the field can mature, realizing the full potential of LLMs to revolutionize how users discover and interact with information and products.
## 9. Conclusion
The integration of Large Language Models (LLMs) into recommendation systems marks a significant evolution in the field, moving beyond the constraints of traditional ID-based approaches towards more semantic-rich, personalized, and robust recommendation experiences [7]. A foundational overview categorizes LLM applications into discriminative and generative paradigms, detailing various adaptation strategies such as fine-tuning, prompting, and instruction tuning [18,22,26]. These methodologies leverage LLMs' inherent capabilities in natural language understanding, generation, and complex reasoning, which address long-standing limitations of traditional systems, including data sparsity, cold-start problems, and a general lack of semantic understanding [3,19].

LLMs have profoundly enhanced recommendation systems in several key areas. They offer competitive solutions for near cold-start scenarios, particularly when utilizing language-based user preferences, performing comparably to fully supervised collaborative filtering methods without specific task training [20]. This capability is further reinforced by LLMs' vast world knowledge, enabling them to provide valuable recommendations even for new items and users [1]. Moreover, LLMs significantly improve interpretability by generating comprehensive, user-acceptable explanations, often without extensive fine-tuning, as demonstrated by frameworks like LANE that use Chain-of-Thought prompting [9,10,13]. Systems like XRec further exemplify this advancement in explanation generation [17].

Beyond explainability, LLMs contribute to superior representation learning. Models like GANPrompt generate diverse and rich item representations by combining LLMs with GANs and collaborative knowledge [9]. RLMRec, a model-agnostic framework, enhances existing recommenders by integrating LLM-empowered representation learning, capturing intricate semantic aspects of user behaviors and preferences and mitigating issues like noise and bias from implicit feedback [11,15]. LLMs are also critical for advanced user profile management, extracting high-order features from user behavior sequences and integrating diverse data modalities for richer, more adaptive user representations [31]. Addressing challenges like "lifelong sequential behavior incomprehension" in long user sequences, retrieval-enhanced frameworks such as ReLLa, employing Semantic User Behavior Retrieval and Retrieval-enhanced Instruction Tuning, have shown superior performance in sequential recommendation [5,11]. Furthermore, knowledge-augmented approaches like KERAG_R enhance LLM-based recommendation by integrating structured knowledge graphs to mitigate hallucination risks and improve preference estimation [6].

Despite these significant advancements, the field remains in an exploratory stage, facing substantial challenges [27]. Key concerns include high computational costs and inference latency, which can impact industrial applicability and user experience [10,12,19]. The risk of hallucination (generating incorrect or non-existent recommendations), model biases (e.g., positional, popularity, fairness, amplification), and limitations in handling long user sequences due to context length constraints persist [10,17,18,22,26]. Additionally, bridging the semantic gap between ID-based and language-based representations and refining prompt design complexity are ongoing research areas [1,11].

The future trajectory of LLM-empowered recommendation systems is dynamic and promising, poised for continuous evolution and breakthroughs [28,30]. It will likely involve deeper integration, generation of more diverse explanations, reduction of computational overhead, and incorporation of multimodal user behaviors [9]. The anticipated reduction in LLM API costs and the proliferation of high-performance open-source models are expected to further catalyze innovation [27]. To fully realize the promise of LLM-powered recommender systems, continued emphasis must be placed on addressing ethical considerations, including safety, fairness, explainability, and privacy [10]. Further research should focus on robust, scalable solutions, particularly for multi-modal and large-scale industrial applications, and developing more sophisticated evaluation metrics for generative outputs to ensure comprehensive progress [22,26].

## References

[1] å¤§è¯­è¨€æ¨¡åž‹åœ¨æŽ¨èç³»ç»Ÿä¸­çš„åº”ç”¨æŽ¢ç´¢ [http://k.sina.com.cn/article_2674405451_9f68304b019014ti2.html](http://k.sina.com.cn/article_2674405451_9f68304b019014ti2.html) 

[2] å®žéªŒå®¤ç»„ä¼šæŠ¥å‘Šæ‘˜è¦ [http://idke.ruc.edu.cn/cslm/syslh2024/13bffb966e194fb5a05415814ec61a7a.htm](http://idke.ruc.edu.cn/cslm/syslh2024/13bffb966e194fb5a05415814ec61a7a.htm) 

[3] LLMåœ¨æŽ¨èåŸŸçš„æ¸—é€ï¼šæŽ¢ç´¢æŽ¨èæ–°èŒƒå¼ [https://baijiahao.baidu.com/s?id=1772115000339195072&wfr=spider&for=pc](https://baijiahao.baidu.com/s?id=1772115000339195072&wfr=spider&for=pc) 

[4] LLM å¢žå¼ºæŽ¨èç³»ç»Ÿï¼šçŸ¥è¯†ã€äº¤äº’ä¸Žæ¨¡åž‹å¢žå¼º [https://github.com/Applied-Machine-Learning-Lab/Awesome-LLM-Enhanced-Recommender-Systems](https://github.com/Applied-Machine-Learning-Lab/Awesome-LLM-Enhanced-Recommender-Systems) 

[5] ReLLa: æ£€ç´¢å¢žå¼ºLLMåœ¨æŽ¨èé¢†åŸŸçš„ç»ˆèº«åºåˆ—è¡Œä¸ºç†è§£ [http://www.paperreading.club/page?id=179486](http://www.paperreading.club/page?id=179486) 

[6] KERAG_R: çŸ¥è¯†å¢žå¼ºæ£€ç´¢ä»¥æå‡LLMæŽ¨èæ€§èƒ½ [https://arxiv.org/abs/2507.05863](https://arxiv.org/abs/2507.05863) 

[7] LLMå¼•é¢†æŽ¨èç³»ç»Ÿå˜é©ï¼š2024å¤§åŽ‚é¡¶ä¼šå·¥ä½œæ€»ç»“ [https://www.51cto.com/aigc/3329.html](https://www.51cto.com/aigc/3329.html) 

[8] LLMsåœ¨æŽ¨èç³»ç»Ÿä¸­çš„æŽ¢ç´¢ä¸Žå®žè·µ [https://blog.itpub.net/70018536/viewspace-2952057/](https://blog.itpub.net/70018536/viewspace-2952057/) 

[9] èµµæ´ªç§‘ï¼šå¤§è¯­è¨€æ¨¡åž‹èµ‹èƒ½æŽ¨èç³»ç»Ÿç ”ç©¶ä¸Žå®žè·µ [https://mp.weixin.qq.com/s?__biz=MzA5NjU4OTgxMg==&mid=2651497866&idx=1&sn=6a27793c068281adb77312a8b3e609c2&chksm=8a0e991b07cc30af047fe1f98a80c983197c5d8b102acea6cef1760e3698f764d958ac073d51&scene=27](https://mp.weixin.qq.com/s?__biz=MzA5NjU4OTgxMg==&mid=2651497866&idx=1&sn=6a27793c068281adb77312a8b3e609c2&chksm=8a0e991b07cc30af047fe1f98a80c983197c5d8b102acea6cef1760e3698f764d958ac073d51&scene=27) 

[10] å¤§æ¨¡åž‹æ—¶ä»£çš„æŽ¨èç³»ç»Ÿ [https://www.cnblogs.com/ambition-hhn/p/17677343.html](https://www.cnblogs.com/ambition-hhn/p/17677343.html) 

[11] WWW'24ï¼šå¤§è¯­è¨€æ¨¡åž‹ä¸ŽæŽ¨èç³»ç»Ÿç»“åˆçš„æœ€æ–°ç ”ç©¶è¿›å±• [https://www.zhihu.com/question/634738906/answer/3430768383](https://www.zhihu.com/question/634738906/answer/3430768383) 

[12] å¤§è¯­è¨€æ¨¡åž‹èµ‹èƒ½æŽ¨èç³»ç»Ÿï¼šä¸‰æ¡æŽ¢ç´¢è·¯å¾„ [https://news.sohu.com/a/780284294_121119001](https://news.sohu.com/a/780284294_121119001) 

[13] LLMRecï¼šå¤§è¯­è¨€æ¨¡åž‹åœ¨æŽ¨èä»»åŠ¡ä¸Šçš„åŸºå‡†æµ‹è¯• [https://hub.baai.ac.cn/view/29251](https://hub.baai.ac.cn/view/29251) 

[14] LEMA 2024: LLMèµ‹èƒ½ä¸‹ä¸€ä»£ç”µå•†åº”ç”¨ [http://www.wikicfp.com/cfp/servlet/event.showcfp?eventid=181368&copyownerid=188076](http://www.wikicfp.com/cfp/servlet/event.showcfp?eventid=181368&copyownerid=188076) 

[15] RLMRec: LLMsèµ‹èƒ½è¡¨ç¤ºå­¦ä¹ ä»¥æå‡æŽ¨èç³»ç»Ÿ [https://dl.acm.org/citation.cfm?id=3645458](https://dl.acm.org/citation.cfm?id=3645458) 

[16] LLMçš„ä»·å€¼å¯¹é½ä¸Žè”é‚¦å­¦ä¹ éšç§å®¡è®¡ [http://idke.ruc.edu.cn/cslm/syslh2024/](http://idke.ruc.edu.cn/cslm/syslh2024/) 

[17] LLMsèµ‹èƒ½æŽ¨èç³»ç»Ÿï¼šæœ€æ–°ç ”ç©¶è¿›å±•ä¸Žåˆ›æ–°æ€è·¯ [https://www.zhihu.com/question/634738906/answer/29498817876](https://www.zhihu.com/question/634738906/answer/29498817876) 

[18] LLM åœ¨æŽ¨èç³»ç»Ÿä¸­çš„åº”ç”¨ç»¼è¿° [https://blog.csdn.net/2301_79838167/article/details/146442651](https://blog.csdn.net/2301_79838167/article/details/146442651) 

[19] LLMsåœ¨æŽ¨èç³»ç»Ÿä¸­çš„æ–¹æ³•è®ºä¸Žåº”ç”¨åˆ†æž [https://link.springer.com/article/10.1007/s10462-025-11189-8](https://link.springer.com/article/10.1007/s10462-025-11189-8) 

[20] LLMs åœ¨å†·å¯åŠ¨æŽ¨èä¸­çš„è¯­è¨€åå¥½è¡¨çŽ°ä¼˜äºŽååŒè¿‡æ»¤ [https://dl.acm.org/doi/fullHtml/10.1145/3604915.3608845](https://dl.acm.org/doi/fullHtml/10.1145/3604915.3608845) 

[21] LLMåœ¨æŽ¨èç³»ç»Ÿä¸­çš„å…¨é¢ç»¼è¿° [https://blog.csdn.net/witsmakemen/article/details/133968259](https://blog.csdn.net/witsmakemen/article/details/133968259) 

[22] å¤§æ¨¡åž‹åœ¨æŽ¨èç³»ç»Ÿä¸­çš„åº”ç”¨ï¼šç»¼è¿°ä¸Žå±•æœ› [https://blog.csdn.net/china1000/article/details/147796951](https://blog.csdn.net/china1000/article/details/147796951) 

[23] Yongfeng Zhang: LLM & AI Research [https://www.yongfeng.me/projects/](https://www.yongfeng.me/projects/) 

[24] LLMæŽ¨èç³»ç»Ÿç»¼è¿° [https://blog.csdn.net/qq_58273883/article/details/148335596](https://blog.csdn.net/qq_58273883/article/details/148335596) 

[25] LLM åŠ©åŠ›æŽ¨èç³»ç»Ÿï¼šæ¸¯å¤§ä¸Žç™¾åº¦ WSDM 2024 è®ºæ–‡è§£è¯» [https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/134410725](https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/134410725) 

[26] LLMåœ¨æŽ¨èç³»ç»Ÿä¸­çš„åº”ç”¨ç»¼è¿°ï¼šæ¨¡åž‹èŒƒå¼ã€æŒ‘æˆ˜ä¸Žæœªæ¥ [https://blog.csdn.net/qq_45284304/article/details/134088828](https://blog.csdn.net/qq_45284304/article/details/134088828) 

[27] æ·±åº¦èžåˆï¼šæŽ¨èç³»ç»Ÿä¸ŽLLMèµ„æºæ•´ç†ä¸Žè§£æž [https://blog.csdn.net/2401_84204413/article/details/140655450](https://blog.csdn.net/2401_84204413/article/details/140655450) 

[28] LLMåœ¨æŽ¨èé¢†åŸŸçš„æ¸—é€ä¸Žæ–°èŒƒå¼æŽ¢ç´¢ [https://blog.csdn.net/yunqiinsight/article/details/131724792](https://blog.csdn.net/yunqiinsight/article/details/131724792) 

[29] Caser, SASRec, BERT4Recï¼šåºåˆ—æŽ¨èæ¨¡åž‹è¯¦è§£ [https://blog.csdn.net/qq_38119106/article/details/118462780](https://blog.csdn.net/qq_38119106/article/details/118462780) 

[30] LLMä¸Žä¼ ç»ŸæŽ¨èç®—æ³•çš„æ¯”è¾ƒ [https://blog.csdn.net/universsky2015/article/details/143583525](https://blog.csdn.net/universsky2015/article/details/143583525) 

[31] LLMèµ‹èƒ½æŽ¨èç³»ç»Ÿï¼šç”¨æˆ·ç”»åƒç®¡ç†æ–°èŒƒå¼ [https://wenku.csdn.net/answer/23xh7mrovj](https://wenku.csdn.net/answer/23xh7mrovj) 

[32] ä¸€è¯‘ï¼šAIé©±åŠ¨çš„ç¿»è¯‘ä¸Žæ–‡çŒ®å¯¹æ¯”å¹³å° [https://www.yiyibooks.cn/__trs__/arxiv/2305.08845v2/index.html](https://www.yiyibooks.cn/__trs__/arxiv/2305.08845v2/index.html) 

[33] å­¦æœ¯è®ºæ–‡ç¿»è¯‘ä¸Žè¾…åŠ©é˜…è¯»å¹³å° [https://www.yiyibooks.cn/__trs__/arxiv/2310.06491v1/index.html](https://www.yiyibooks.cn/__trs__/arxiv/2310.06491v1/index.html) 

[34] ä¸€è¯‘ï¼šarXivè®ºæ–‡AIç¿»è¯‘å·¥å…· [https://www.yiyibooks.cn/__src__/arxiv/2407.04925v1/index.html](https://www.yiyibooks.cn/__src__/arxiv/2407.04925v1/index.html) 

