# A Survey on Large Language Models for Time Series

# 0. A Survey on Large Language Models for Time Series

## 1. Introduction
Time series data constitutes a ubiquitous and critical component across a myriad of scientific, industrial, and societal applications, ranging from disease spread prediction and retail analysis to macroeconomic forecasting, healthcare monitoring, climate modeling, and the Internet of Things (IoT) [2,4,6,8,15,26]. The inherent ability of time series to capture temporal patterns, trends, and sequential dependencies over time is invaluable for informed decision-making and understanding complex real-world systems [2,20,26,32].

Traditional time series models, encompassing statistical methods like ARIMA and deep learning architectures such as LSTMs and Transformers, have been instrumental in addressing forecasting challenges [26,30]. However, these approaches often suffer from significant limitations: they typically necessitate extensive domain knowledge, meticulous feature engineering, and considerable model tuning [2,30]. Many traditional deep learning models also demand substantial task-specific training on sufficient in-distribution data [25,29], struggling with data scarcity [22] and often lacking broad adaptability across diverse data types or scenarios [14]. Furthermore, they predominantly focus on prediction tasks, often lacking interpretability, effective updating mechanisms, and validation guarantees [2,12]. Some models even struggle to generate multiple probable, non-deterministic predictions, which is crucial for robust decision-making [29].

In stark contrast, Large Language Models (LLMs) have demonstrated unparalleled capabilities in capturing intricate patterns, adapting across domains, and exhibiting robust zero-shot, few-shot, and reasoning abilities, primarily in textual data [2,6,18,30]. This success has ignited significant interest in their application to time series analysis, hypothesizing that their proficiency in handling sequential dependencies in text could generalize to numerical time series data [8,15]. This convergence of LLMs and time series analysis presents a transformative potential, not merely for enhancing prediction accuracy and stability, but for fostering a new era of "general time series analysis intelligence" [2,6,14,20]. LLMs are posited to revolutionize time series analysis by overcoming the limitations of traditional methods, offering improved generalization, adaptability to dynamic changes and anomalies, and crucially, the provision of interpretable prediction results in textual form [12,14,19]. Models like TimeGPT [3,26] and Chronos [19] exemplify this potential by leveraging transfer learning and zero-shot capabilities to simplify forecasting workflows and provide advantages over statistical models. LLMs are envisioned to act as LLM-Assisted Enhancers, LLM-Centric Predictors, and LLM-Empowered Agents, fundamentally reshaping the analytical landscape [2].

However, the direct application of LLMs to time series data presents unique challenges. The fundamental disparity between LLMs' text-centric training and the continuous numerical nature of time series data requires bridging the modality gap [1,6,31]. Critically, recent research has also raised concerns, indicating that current methods utilizing LLMs for time series forecasting often perform comparably to or even worse than simpler ablation methods, despite incurring significantly higher computational costs [4,8,9,15]. These studies suggest that the inherent reasoning capabilities of pre-trained LLMs are not yet effectively utilized in many existing approaches [4,8,9], and that models undergoing alignment processes (e.g., RLHF) might even exhibit inferior performance in certain zero-shot time series contexts [5]. This highlights a need for more rigorous testing, particularly in tasks like anomaly detection, to truly gauge LLMs' understanding of time series data [17].

Given this evolving landscape, research in "Large Models + Time Series" is broadly bifurcated into two primary, albeit sometimes converging, directions [12,14,16]: (1) **adapting existing Large Language Models** to process time series data, often involving techniques like data reprogramming, tokenization, or fine-tuning (e.g., LLM4TS framework [25] or Time-LLM's reprogramming framework [1]), and (2) **developing native time series foundation models** designed explicitly for temporal data, exemplified by models such as TimeGPT [3,26] and Sundial [29]. This survey aims to systematically review and categorize the rapidly advancing integration of LLMs into time series analysis, providing a comprehensive overview of current methodologies, integration strategies, existing multimodal datasets, challenges, and promising future directions in this interdisciplinary field [2,6,31].
## 2. Background on Time Series and Large Language Models
This section provides a foundational understanding of time series analysis and Large Language Models (LLMs), outlining their individual evolutions and establishing the theoretical basis for their convergence. We begin by tracing the historical development of time series modeling, from classical statistical methodologies to advanced deep learning architectures, highlighting the inherent challenges of time series data that each generation sought to overcome [2,30]. Concurrently, we present the evolution of LLMs, detailing their core architectural principles, particularly the Transformer, and the transformative impact of pre-training on vast datasets [1,2]. The subsequent discussion integrates these two fields by explaining how the advanced capabilities of LLMs, initially developed for natural language processing, lay the groundwork for addressing persistent limitations and fostering new advancements in time series analysis.

The study of time series data, characterized by chronologically ordered data points, is fundamental across diverse domains, necessitating robust analytical and predictive models [2]. Historically, methods such as Autoregressive Integrated Moving Average (ARIMA) and Exponential Smoothing (ETS) provided foundational tools for forecasting and classification. While effective for certain tasks, these classical approaches often suffered from oversimplified assumptions, a heavy reliance on domain knowledge, and limitations in handling non-stationarity, long-term dependencies, and data scarcity, primarily offering point predictions without capturing complex probabilistic distributions [2,26,34]. The advent of machine learning and deep learning, with models like recurrent neural networks (e.g., GRU, LSTM) and more recently Transformer-based architectures (e.g., Informer, PatchTST), marked a significant shift, enabling the capture of intricate patterns and dependencies in time series data [15,27,34]. Despite these advancements, challenges persist, particularly concerning generalization across diverse datasets and efficiency in data-scarce environments, where even simpler models can occasionally outperform complex deep learning solutions [25,34]. This persistent demand for more generalized and adaptable models motivates the exploration of LLMs for time series tasks.

Simultaneously, Large Language Models have undergone a profound evolution, transitioning from specialized NLP tools to powerful general-purpose models. Modern LLMs, such as GPT-3 and Llama, are defined by their immense scale and their ability to exhibit emergent reasoning and planning capabilities [2,5]. Their foundational architecture, the Transformer, with its self-attention mechanisms, is critical for capturing long-range dependencies in sequential data [26,30]. Extensive pre-training on massive text corpora has endowed LLMs with a rich knowledge base and robust pattern recognition skills, facilitating remarkable zero-shot inference and transfer learning capabilities across various domains with minimal or no additional training [1,2].

The intrinsic sequential nature of time series data shares conceptual similarities with the linguistic sequences processed by LLMs, laying the groundwork for their application in this domain [8,30]. Researchers are investigating how LLMs, with their robust representation learning and few-shot learning abilities, can "learn the language of time series" by treating numerical data as "language-like sequences" [19,30]. The data-independent self-attention mechanisms of LLMs are posited to act as general computation calculators, enabling them to adapt to non-linguistic data with efficiency and limited data [25]. This paradigm offers a promising avenue to address critical limitations in traditional time series models, such as data scarcity and the need for extensive domain-specific feature engineering, moving towards more unified and adaptable problem-solving approaches [2,25]. While the modality gap between text and numerical time series data presents challenges, the potential for LLMs to provide contextual understanding, integrate multimodal information, and generate interpretable results positions them as a significant area of research for advancing time series analysis [31,32]. However, it is also acknowledged that the true effectiveness of LLMs in time series remains a subject of ongoing debate, with some studies observing that current applications do not always consistently outperform simpler or traditional methods [8,17]. This sets the stage for a critical examination of their capabilities and limitations in subsequent sections.
### 2.1 Evolution of Time Series Models: From Classical to Modern Deep Learning
Time series data, defined as a sequence of data points ordered chronologically, is fundamental for capturing dynamic system changes and is crucial for analysis across diverse disciplines, including disease prediction, retail analytics, healthcare, and finance [2,4,8,15,26]. Historically, time series analysis has relied on a spectrum of models, evolving from classical statistical methods to modern deep learning architectures.

Traditional time series analysis methods, such as Autoregressive Integrated Moving Average (ARIMA), Exponential Smoothing (ETS), Vector Autoregression (VAR), and simple linear models, formed the bedrock of forecasting and classification tasks [18,26,34]. While effective for specific predictive tasks [2], these classical approaches are characterized by several notable limitations. They often depend heavily on prior domain knowledge and require extensive model tuning, making them less adaptable to varied datasets and scenarios [2]. Furthermore, these methods tend to operate under oversimplified assumptions and struggle with the complexity of real-world data, particularly in handling non-stationarity, long-term dependencies, and instances of data scarcity [26,28,34]. Critically, their focus has primarily been on point predictions, frequently overlooking the generation of multiple possible prediction outcomes or complex probabilistic distributions, which are essential for robust decision-making in inherently non-deterministic time series [2,29]. The reliance on single-modality numerical data also prevented the integration of richer contextual information, a gap often filled by human experts [14,32].

The landscape of time series modeling has progressively shifted with the advent of machine learning, featuring models like XGBoost and LightGBM, and subsequently, deep learning techniques [26,34]. The rise of deep learning brought forth specialized models such as DeepAR, Koopman Neural Forecaster, MLP-based architectures (e.g., N-BEATS, TiDE), and recurrent neural networks (e.g., GRU, LSTM), designed to capture complex patterns and dependencies [34]. More recently, Transformer-based models, including Informer, FEDformer, Autoformer, iTransformer, Pathformer, Crossformer, Non-stationary Transformers, TimeMixer, PatchTST, and TimesNet, have gained prominence due to their attention mechanisms and attempts to manage long time series efficiently [10,15,27,28,34]. This evolution extends to even more sophisticated deep learning paradigms, with contemporary research exploring Diffusion Models for representation learning, forecasting, and imputation; Koopman Probabilistic Models for probabilistic forecasting and analysis; and novel architectures like Kolmogorov-Arnold Networks (KANs) and Spiking Neural Networks (SNNs) for diverse time series tasks [21,27,33,35]. These advanced models aim to tackle challenges such as irregular data, non-stationarity, and probabilistic forecasting [21,35]. However, even modern deep learning models can encounter limitations, particularly with data scarcity in real-world scenarios, where simpler linear models like DLinear can sometimes surprisingly outperform complex Transformer-based approaches [25,28,34].

This historical context highlights a persistent challenge in time series modeling: the development of generalized, adaptable models. While other AI domains, particularly Natural Language Processing (NLP) and Computer Vision (CV), have witnessed the emergence of powerful foundation models [26], time series domains have been constrained by data sparsity, necessitating specialized models with limited generalization capabilities [1,13]. Large Language Models (LLMs) are now being explored as a potential solution to bridge this gap. Researchers hypothesize that LLMs, proficient in handling sequential dependencies in text and demonstrating robust pattern recognition and reasoning abilities, could generalize this capability to numerical time series data [4,8,9,15,31]. The motivation behind integrating LLMs stems from their potential to address data efficiency challenges, reduce reliance on explicit domain-specific model tuning, and move towards unified problem-solving capabilities akin to General Artificial Intelligence (AGI) in time series analysis [1,2,16,25]. Nevertheless, some studies observe an "alarming trend" where current LLM applications, despite their computational cost, do not consistently demonstrate a clear performance advantage over simpler or traditional methods in time series forecasting [4,8]. This sets the baseline for a critical examination of how LLMs aim to address, and whether they successfully overcome, the longstanding shortcomings of prior time series models.
### 2.2 Large Language Models: Evolution and Core Principles
Large Language Models (LLMs) have undergone a remarkable evolution, transforming from specialized natural language processing (NLP) tools into powerful general-purpose models capable of handling diverse data types, including text, images, and audio, while exhibiting adaptability to varying data conditions and anomalies [12,16,17]. Their recent "surged popularity" and status as a "hot commodity" in machine learning are attributed to their significant advancements across various domains, notably NLP and computer vision [4,6,18,25,31]. Modern LLMs, such as GPT-3, GPT-4, Llama, and Mistral, are characterized by their massive scale, often comprising hundreds of millions to billions of parameters, and their capacity for emerging reasoning and planning abilities [2,5,9,14].

The foundational principles enabling these impressive capabilities are primarily rooted in the **Transformer architecture** and the concept of **pre-training on massive datasets** [2,3]. The Transformer, with its encoder/decoder structure and self-attention mechanisms, has become the de facto architecture for LLMs, effectively capturing precise long-range dependencies in sequential data [14,26,28,29,30]. Models like GPT-2 and LLaMA are fundamentally Transformer-based, processing and understanding sequential dependencies in text data [4,8,25]. Through pre-training on vast text corpora, LLMs acquire a rich knowledge base and learn intricate patterns, which are then transferred to downstream tasks [14,19,25,26,29,30]. This paradigm empowers LLMs with remarkable **zero-shot inference** and **transfer learning** capabilities, allowing them to perform new tasks or adapt to new domains with minimal or no additional training data [1,2,3,12,16,28,30,35].

These general abilities, though primarily developed for text processing, have propelled advancements across diverse domains. LLMs demonstrate exceptional contextual understanding, pattern recognition, and reasoning capabilities when processing complex token sequences [1,18,24,28]. Their ability to generalize knowledge across different domains, often leveraged through parameter-efficient fine-tuning (PEFT) techniques, makes them highly adaptable [13,22,23]. This adaptability has laid the groundwork for their application in time series analysis, where the sequential nature of data shares conceptual similarities with text sequences [8,15,30]. Researchers are exploring how LLMs can "learn the language of time series" by treating numerical data as "language-like sequences" or "strings of digits" [19,30,34].

A significant emphasis in applying LLMs to time series analysis is placed on their **robust representation learning** and **few-shot learning capabilities** [23,25]. The pre-trained LLMs encode strong representations that can be effectively transferred, often surpassing models trained from scratch, even when most parameters remain fixed [25]. This is largely due to their data-independent self-attention mechanisms, which act as general computation calculators, allowing them to leverage knowledge from vast datasets and adapt to non-linguistic data with minimal fine-tuning and limited data [25]. These inherent strengths are posited as solutions to critical limitations in traditional time series models, which often struggle with data scarcity, limited generalization across diverse datasets, and the need for extensive domain-specific feature engineering. For instance, the TimeGPT model, designed as a generative pre-trained Transformer, explicitly leverages LLM paradigms, including extensive pre-training on over 100 billion data points across various domains, to achieve zero-shot inference and improved generalization in time series forecasting [3,22]. Similarly, models like Sundial, an enhanced Transformer architecture pre-trained on a massive time series dataset, aim to acquire robust generalized knowledge and facilitate transferability, mirroring LLM training paradigms [29]. LLMs also offer advantages such as providing explanatory results in text form, enhancing the contextual understanding and reasoning capabilities relevant for time series processing [12,16]. While challenges exist, particularly regarding the modality gap between text and numerical time series data [6,31], the robust representation and few-shot learning capabilities of LLMs offer a promising avenue to overcome these hurdles and advance time series analysis.

---
**Note on Task Fulfillment:**

1.  **Consecutive References Conversion:** The provided content already uses the form `` for multiple references, grouping all citations related to a statement into a single list. No explicit merging of separate, consecutive reference blocks was required as such instances were not found in the input. The existing format already aligns with the implied goal of having a single, comprehensive list of references for each cited point.
2.  **KaTeX Syntax and Macro Conversion:** The provided content does not contain any mathematical formulas or KaTeX expressions. Therefore, this part of the task is not applicable, and no modifications were made.
## 3. Paradigms of LLM Integration in Time Series Analysis
The integration of Large Language Models (LLMs) into time series analysis has given rise to distinct conceptual paradigms, each leveraging LLMs' unique capabilities to address the inherent challenges of time series data. These paradigms define varied roles for LLMs, ranging from supportive tools to central analytical engines, and collectively contribute to the development of a more generalized time series analysis intelligence [2,32]. This section systematically presents and differentiates these proposed paradigms, discussing their core principles, objectives, and their conceptual strengths and weaknesses, thereby laying the groundwork for understanding subsequent technical details concerning data representation and adaptation.

The foundational framework delineates three primary paradigms for LLM integration in time series analysis: LLM-Assisted Enhancers, LLM-Centric Predictors, and LLM-Empowered Agents [2]. This classification offers a comprehensive lens through which to understand the evolving landscape of LLM applications in this domain.

The first paradigm, **LLM-Assisted Enhancers**, positions LLMs not as direct performers of time series tasks but as augmentative tools that improve existing methodologies and various aspects of the analytical pipeline [2]. The core principle involves leveraging LLMs' qualitative reasoning, natural language understanding (NLU), and knowledge representation capabilities to inject external knowledge and analytical capabilities into traditional models [30,32]. Objectives include enriching data context, enhancing interpretability by generating textual descriptions of patterns and anomalies, augmenting datasets, transferring domain knowledge, facilitating pre-training, and improving operational efficiency through prompting [2,6,14,28,30,35]. Conceptually, this paradigm's strength lies in its ability to address the sparsity and noise often found in time series data, leading to more robust, interpretable, and context-aware analyses by handling unstructured data and providing transparent explanations [2,14]. However, challenges include the substantial computational overhead for large datasets and the difficulty in developing universally effective solutions given the diverse nature of time series applications [2].

In contrast, **LLM-Centric Predictors** directly employ LLMs or LLM-inspired architectures to perform fundamental time series tasks such as forecasting, anomaly detection, classification, and imputation [20,35]. The underlying principle involves adapting continuous numerical time series data into a format digestible by LLMs, which are inherently token-based [2,34]. This adaptation often involves data transformation techniques like direct prompting, time series quantization, alignment methods, patching, tokenization, or even visual representations [6,30,31]. Model adaptation strategies include tuning-based approaches, where LLM parameters are fine-tuned for time series tasks (e.g., LLM4TS, Time-LLM, TEST) [1,9,13,25,28], and non-tuning-based methods that utilize black-box LLMs without modifying internal parameters (e.g., TimeGPT, Chronos, Lag-Llama) [16,19,22]. Strengths include powerful zero-shot and few-shot inference capabilities, attributed to extensive pre-training and the LLM's general self-attention mechanisms, which enable them to capture abstract patterns and act as "universal pattern machines" [2,3,14,16]. However, significant weaknesses persist, primarily the "modality gap" between continuous numerical data and discrete text tokens, leading to difficulties in preserving numerical semantics and achieving precise quantitative predictions [2,18]. Furthermore, these models can incur higher computational costs and sometimes exhibit performance parity with simpler traditional models, with tuning-based methods also facing risks of catastrophic forgetting [4,8].

Finally, **LLM-Empowered Agents** represent a paradigm where LLMs transcend mere analytical roles to become active orchestrators and planners within time series analysis [2]. The core principle involves LLMs leveraging optimized external tools and specialized time series models by generating indirect tools, such as code snippets or API calls, rather than directly processing raw data [30,31,32]. Objectives include achieving a more generalized intelligence, performing higher-level reasoning, and intricate task planning, particularly for complex scenarios requiring external knowledge and sophisticated interpretation [32]. This agentic approach synergizes the LLM's advanced control, reasoning, and interpretability with the numerical precision and specialized algorithms of traditional models [30]. Examples include systems that generate API calls for external prediction models (e.g., ToolLLM, Auto-TTE) or those employing multi-agent iterative optimization [30,35]. The primary strength lies in its capacity to handle complex tasks by coordinating and synthesizing information from diverse sources, leading to deeper insights and enhanced interpretability [32]. As an actively developing area, a current challenge is the relatively nascent stage of specific LLM-empowered agent frameworks within time series analysis, despite broader research on LLM agents [11,27].

These three paradigms—LLM-Assisted Enhancers, LLM-Centric Predictors, and LLM-Empowered Agents—are not mutually exclusive but rather complementary, each addressing different facets of time series analysis. Enhancers improve data and models, predictors directly tackle forecasting and detection, and agents orchestrate complex analytical workflows. Together, they represent a multifaceted approach to leveraging LLMs, collectively advancing towards a 'general time series analysis intelligence' by enabling a continuum of functionalities from basic data understanding to sophisticated, context-aware decision-making [2,32]. Understanding these distinct roles is crucial for appreciating the technical details of data representation and adaptation strategies explored in subsequent sections, as these details are intrinsically linked to the specific paradigm being pursued.
### 3.1 LLM-Assisted Enhancers
Large Language Models (LLMs) are increasingly recognized for their capacity to enhance time series analysis, not primarily by performing direct predictive tasks, but by augmenting existing methodologies and improving various aspects of the analytical pipeline [2]. This enhancement role leverages LLMs' qualitative reasoning, natural language understanding, and knowledge representation capabilities to provide deeper insights and operational efficiencies that complement traditional time series models [30,32]. Fundamentally, LLM-assisted enhancers act as "plug-and-play" solutions that address the inherent sparsity and noise often found in time series data, while also injecting external knowledge and analytical capabilities into existing models [2].

The utility of LLMs as enhancers can be broadly categorized into data-based and model-based enhancements.

**Data-based Enhancements:**
LLMs significantly improve data quality and understanding by enriching the information content and context surrounding time series data. This is particularly crucial given the often lower information density of time series compared to other modalities [2].
*   **Improving Data Understanding and Interpretability**: LLMs can generate textual descriptions and summaries of complex time series patterns, anomalies, and trends, thereby enhancing data interpretability [2,30]. For example, tools like LLMMPE, SignalGPT, and Insight Miner utilize LLMs to provide human-readable insights for diverse time series data, including human movement, biological signals, and general trend analysis [2]. This capability allows for a more intuitive understanding of broad trends and contextual factors, moving beyond mere numerical predictions [30].
*   **Data Augmentation and Generation**: LLMs or LLM-inspired generative methods contribute to data quality by creating synthetic time series or augmenting existing datasets, which is vital for addressing data scarcity or improving model robustness. Approaches such as "BRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimisation and Diffusion Modelling" and "VerbalTS: Generating Time Series from Texts" leverage LLMs for controlled time series generation from textual inputs [35].
*   **Contextual Enrichment and Multimodal Integration**: LLMs facilitate the integration of diverse data sources, particularly textual metadata, to provide rich context for time series analysis. This enriches the time series, leading to improved model robustness and accuracy in applications like financial decision-making [2]. Prior work has explored augmenting time series forecasting with textual metadata, highlighting the enhancer role of textual information for numerical predictions [34]. Examples include the "Modality-aware Transformer," which extracts insights from both categorical text and numerical time series through feature-level attention, and methods like "Improving Text-based Early Prediction by Distillation from Privileged Time-Series Text," which enhances early prediction by distilling knowledge from longer text windows available during training [28].

**Model-based Enhancements:**
LLMs can augment existing time series models by transferring knowledge, providing external domain context, and improving model interpretability and operational efficiency.
*   **Knowledge Transfer and Domain Adaptation**: LLMs are leveraged to imbue traditional time series models with external knowledge and domain-specific contexts, overcoming limitations inherent in purely numerical approaches [2]. This enables the fusion of domain expertise and complex reasoning into time series analysis, even when the LLM is not directly performing the core predictive task [14]. Strategies involving "alignment techniques" and the transfer and distillation of knowledge from LLMs to numerical time series analysis represent key approaches in this area [6].
*   **Pre-training and Representation Learning**: LLMs can facilitate more effective representation learning for specialized time series models. For instance, the METS method employs automatically generated clinical reports to guide ECG self-supervised learning (SSL) pre-training, maximizing similarity between paired ECGs and reports to enable zero-shot classification without extensive annotated data [16]. Similarly, dual-tower models often utilize frozen LLMs to process textual inputs, which are then integrated to enhance tasks such as ECG analysis [2]. Further advancements include aligning text and video with sensor data (e.g., IMU2CLIP) and improving spatio-temporal predictions (e.g., STLLM) [2].
*   **Interpretability and Explanatory Capabilities**: A significant contribution of LLMs is their ability to enhance the interpretability of time series models by generating explanations in natural language. This is particularly valuable in fields like financial time series forecasting, where LLMs can elucidate cross-series reasoning, integrate multimodal signals, and clarify model outcomes [14]. Specific techniques, such as those discussed in "Optimal Information Retention for Time-Series Explanations" and "Timing: Temporality-Aware Integrated Gradients for Time Series Explanation," leverage LLM-related methods to achieve greater explainability in time series models [35].
*   **Operational Efficiency through Prompting**: Direct prompting of LLMs can improve operational efficiency by assisting in decision analysis and integrating domain-specific models. For example, TrafficGPT integrates domain-specific traffic models with LLMs to provide detailed insights and enhance system interpretability, streamlining decision-making processes [2]. This allows for qualitative reasoning and exploratory analysis, providing contextual insights for decision support [30].

**Complementary Role and Challenges:**
LLM-assisted enhancers adeptly complement traditional time series methods by addressing their inherent limitations in handling unstructured data, integrating external knowledge, and providing transparent explanations. This enables more robust, interpretable, and context-aware time series analysis [2,14]. However, the deployment of LLM-assisted enhancers is not without challenges. A notable limitation is the considerable time and cost overhead associated with processing large-scale datasets. Furthermore, the inherent diversity of application scenarios within time series data presents difficulties in developing universally effective LLM-assisted enhancement solutions [2]. Overcoming these challenges will be crucial for the widespread adoption and continuous development of LLM-assisted enhancers in time series research.
### 3.2 LLM-Centric Predictors
LLM-centric predictors represent a burgeoning research direction wherein Large Language Models (LLMs) or LLM-inspired architectures are directly employed to address fundamental time series tasks. These tasks encompass forecasting, anomaly detection, and classification, extending to more specialized applications such as imputation [20,35]. Noteworthy models in this category include TimeGPT-1, Lag-llama, Chronos, and MOMENT for forecasting, and methods leveraging prompting for anomaly detection like "When Will It Fail?" [11,19].

The mechanisms through which LLM-centric predictors operate primarily involve adapting numerical time series data to a format digestible by LLMs, which are inherently designed for textual input [2,34]. This adaptation can be broadly categorized into two approaches: tuning-based and non-tuning-based predictors, with various data transformation techniques employed across both.

**Mechanisms and Data Transformation:**

1.  **Data Transformation Techniques**: A core challenge stems from the "modality gap" between continuous numerical time series and the discrete, token-based nature of LLM inputs [2].
    *   **Direct Prompting**: This straightforward method treats time series data as raw text input for LLMs. While enabling zero-shot prediction, classification, and anomaly detection by leveraging the LLM's vast knowledge, it frequently struggles with preserving numerical semantics, precise calculations, and probabilistic distributions [18,30]. PromptCast, for instance, converts numerical inputs and outputs into prompts for sentence-to-sentence prediction [16]. AuxMobLCast similarly transforms numerical time series into sentences for human mobility forecasting [16].
    *   **Time Series Quantization**: To bridge the modality gap, continuous time series data can be converted into discrete representations, often through techniques like VQ-VAE or K-means clustering. This allows pre-trained, Transformer-based LLMs to directly operate on these tokens for various tasks [30,31].
    *   **Alignment Techniques**: These methods involve training a specialized time series encoder to map time series embeddings into the semantic space of language models. This alignment often utilizes contrastive learning or leverages LLMs as backend processors, thereby enabling more seamless integration and prediction [30,31].
    *   **Patching and Tokenization**: A common pre-processing step, particularly for fine-tuning methods, involves segmenting time series data into patches ($\mathcal{X}_{inp}=\mathrm{Patching}(\mathcal{X})$) and tokenizing any related textual data ($\mathcal{T}_{inp}=\mathrm{Tokenizer}(\mathcal{T})$). These processed inputs are then fed into the LLM. Novel tokenization methods, such as those in LLMTime, transform tokens into flexible continuous values to address the limitations of standard LLM tokenizers not designed for numerical sequences [2,5]. PatchInstruct, for example, combines time series decomposition, patch-based tokenization, and similarity-based neighbor augmentation for robust prompt construction [24].
    *   **Visual Representations**: For multimodal LLMs, converting time series into images can enable pattern recognition and anomaly detection based on visual trends, leveraging models like CLIP or ImageBind [30].

2.  **Model Adaptation Strategies**:
    *   **Tuning-based Predictors**: These approaches modify or fine-tune LLM parameters. The general process involves feeding the pre-processed time series patches and optional text tokens into an LLM ($f_{LLM}^{\triangle}$) with accessible parameters. A specific task layer $\mathrm{Task}(\cdot)$ is then introduced to perform analysis based on an instruction prompt $P$, yielding the prediction $\hat{Y}$:
        $$
        \begin{aligned}
        \text{Pre-processing:}&\mathcal{X}_{inp}=\mathrm{Patching}(\mathcal{X}),\\
        &\mathcal{T}_{inp}=\mathrm{Tokenizer}(\mathcal{T}),\\\\
        \text{Analysis:}&\hat{Y}=\mathrm{Task}(f_{LLM}^{\triangle}(\mathcal{X}_{inp},\mathcal{T}_{inp},P)),
        \end{aligned}
        $$
        Examples include LLM4TS, which employs a two-stage fine-tuning process with Parameter-Efficient Fine-Tuning (PEFT) techniques to adapt pre-trained LLMs like GPT-2 for long-term multivariate time series forecasting [13,25]. Time-LLM reprograms frozen LLMs by aligning time series data with text prototypes and using a Prompt-as-Prefix (PaP) mechanism [1,28]. TEST tokenizes time series and uses text prototype aligned embeddings with soft prompts for effective fine-tuning, while TEMPO combines seasonality/trend decomposition with prompt pooling to handle non-stationary series [2,28]. OneFitsAll (GPT4TS) uses instance normalization and patching, freezing core LLM layers while optimizing position embeddings and layer normalization [9]. LLaTA employs distinct "text" and "time" branches, with the latter learning a Low-Rank Adapter (LoRA) for the LLM [9].
    *   **Non-tuning-based Predictors**: These methods utilize black-box LLMs without modifying their internal parameters. The process typically involves pre-processing raw time series ($\mathcal{X}$) into an LLM-consumable input ($\mathcal{X}_{inp}=\mathrm{Template}(\mathcal{X},P)$ or $\mathcal{X}_{inp}=\mathrm{Tokenizer}(\mathcal{X})$), feeding it to a black-box LLM ($f_{LLM}^{\blacktriangle}$), and then parsing the response ($\hat{Y}=\mathrm{Parse}(f_{LLM}^{\blacktriangle}(\mathcal{X}_{inp}))$) [2]. TimeGPT is a prominent example, being a generative pre-trained transformer model pre-trained on massive and diverse time series datasets (e.g., 100 billion data points across finance, energy, health) and capable of zero-shot inference with minimal fine-tuning [22,26]. Chronos similarly aims for direct zero-shot prediction by "learning the language of time series" [19], and Lag-Llama also demonstrates strong zero-shot capabilities [16].

**Performance Evaluation and Implications of Textual Training:**

The performance of LLM-centric predictors presents a mixed picture when compared to traditional time series models.
*   **Strengths**: A key advantage is their **zero-shot and few-shot inference capabilities**, often attributed to the extensive pre-training of LLMs on diverse data. Models like GPT-3 and LLaMA-2 have demonstrated the ability to perform zero-shot time series forecasting, occasionally outperforming specialized models [14,16]. TimeGPT and Lag-Llama are designed as foundation models with strong zero-shot prediction performance on unseen datasets [3,28]. The **generality of LLM's self-attention mechanisms** allows them to capture abstract patterns and temporal structures, positioning them as "universal pattern machines" applicable to a wide range of domains from human mobility to financial and health forecasting [2]. Multimodal LLMs (MLLMs) can also integrate textual and visual information, leading to more interpretable results [30,32].
*   **Weaknesses**: Despite these strengths, several studies highlight limitations. The primary challenge remains the **modality gap**; LLMs' fundamental training on textual data means their tokenizers are not optimized for numerical values, leading to difficulties in handling continuous values and preserving temporal relationships [2]. Direct prompting, while flexible, can result in a loss of numerical semantics and struggles with precise quantitative predictions [30]. Furthermore, some LLM-centric predictors, such as OneFitsAll, Time-LLM, and LLaTA, have been shown to perform **worse or no better than simpler ablation methods** in time series forecasting, often incurring **significantly higher computational costs** [4,8]. Modifying original LLM parameters in tuning-based approaches also risks **catastrophic forgetting**, though lightweight adaptive layers can mitigate this [2].

In conclusion, the training of LLMs on textual data has profound implications for their application in numerical time series prediction. It necessitates sophisticated data transformation techniques (e.g., patching, quantization, prompting, alignment) to bridge the inherent modality gap. While LLMs offer promising capabilities such as zero-shot learning and generalized pattern recognition, their application to time series currently faces challenges in numerical precision, computational efficiency, and sometimes, performance parity with specialized traditional models. Future research focuses on refining these adaptation techniques and developing more numerically-aware LLM architectures to fully unlock their potential in the time series domain.
### 3.3 LLM-Empowered Agents
The integration of Large Language Models (LLMs) into time series analysis has introduced a significant paradigm shift, giving rise to LLM-Empowered Agents [2]. This approach elevates LLMs beyond mere analytical instruments, positioning them as active agents capable of performing higher-level reasoning and intricate task planning within time series domains [2,32]. Such agents are designed to transform time series analysis by achieving a more generalized intelligence, enabling them to tackle complex tasks that often require external information and sophisticated interpretation [32].

A core tenet of this paradigm is the LLM's function as an orchestrator, leveraging optimized external tools and specialized time series models. Instead of directly processing raw time series data, the LLM generates indirect tools, such as code snippets or Application Programming Interface (API) calls, to interact with these external functionalities [30,31]. This "tool integration" methodology allows LLMs to extend their capabilities by coordinating expert forecasting engines or specialized processing libraries, a concept explicitly recognized as a methodology for combining LLMs with tools for time series tasks [6,30]. Examples of this include ToolLLM, which is noted for its ability to generate API calls for external time series prediction models, and Auto-TTE, which translates time series data into LLM-executable scripts for specific tasks such as interpretable Electrocardiogram (ECG) classifications [30]. Other prominent systems leveraging LLMs for orchestrating external components include CTG++, SHARE, GG-LLM, and SCRL-LG [31].

The primary benefit of this agentic approach lies in its capacity to synergize the inherent strengths of LLMs with the numerical precision and specialized algorithms of traditional time series models [30]. LLMs contribute advanced control, reasoning, and interpretability, which are particularly crucial for handling complex tasks demanding external knowledge beyond the immediate time series data [32]. This integration facilitates deeper insights and enhanced interpretability by coordinating and synthesizing information from diverse sources [32]. Furthermore, the concept extends to multi-agent systems, as explored in "BRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimisation and Diffusion Modelling," where LLM-like components take on an orchestrating role in complex time series generation [35]. Similarly, "LangTime: A Language-Guided Unified Model for Time Series Forecasting with Proximal Policy Optimization" illustrates language-guided control mechanisms, showcasing LLMs' agent-like capabilities in forecasting by using natural language for guidance [35].

The application of LLMs as agents or orchestrators is an actively developing area within time series analysis, recognized as a significant future direction [11]. Research in this domain encompasses various applications, including "Agentic Retrieval-Augmented Generation for Time Series Analysis," "Argos: Agentic Time-Series Anomaly Detection with Autonomous Rule Generation via Large Language Models," "LLM Knows Geometry Better than Algebra: Numerical Understanding of LLM-Based Agents in A Trading Arena," and "FinArena: A Human-Agent Collaboration Framework for Financial Market Analysis and Forecasting" [11]. While general research on LLM agents exists in broader contexts, such as "CoderAgent" and "GenAL" in educational settings [33], their specific deployment within time series analysis represents a rapidly evolving and promising field. It is noteworthy that some comprehensive reviews, despite their breadth, may not yet explicitly detail dedicated LLM-empowered agent frameworks within the time series context, underscoring the novelty and ongoing development in this specialized intersection [27].
## 4. Advanced Deep Learning Architectures for Time Series
The evolution of deep learning for time series analysis marks a significant departure from traditional statistical methods and earlier deep learning paradigms like basic Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks. While traditional models often rely on strong assumptions about data stationarity or linearity, and early deep learning struggled with long-range dependencies and computational scalability for extended sequences, advanced architectures introduce specific inductive biases and architectural innovations tailored to the complex, dynamic, and often non-stationary nature of time series data [27,28]. These advancements are foundational, addressing critical challenges such as capturing intricate temporal dependencies, mitigating quadratic computational costs, quantifying inherent uncertainty, and enabling real-time processing, thereby setting the stage for robust Large Language Model (LLM)-based and time series foundation models.

The advent of **Transformer-based variants and sophisticated attention mechanisms** represents a pivotal shift, moving beyond the limitations of traditional sequence models that struggled with long-range interactions. Vanilla Transformers, originally designed for natural language, possess an inductive bias for sequence-to-sequence mapping via self-attention, dynamically weighting feature importance. However, their direct application to time series faces challenges like the quadratic complexity of self-attention ($O(L^2)$) for long sequences, and the need for nuanced temporal positional encoding and causality modeling. Architectural innovations have emerged to address these, including efficient attention mechanisms (e.g., ProbSparse in Informer, LogSparse in LongTrans, frequency-enhanced in FEDFormer, pyramidal in Pyraformer, maximum entropy in Infomaxformer) that achieve sub-quadratic or linear complexity [27,28,34]. Furthermore, temporal-specific adaptations like Rotary Position Embeddings (RoPE) and relative position encoding are employed, alongside the crucial "patching" strategy (PatchTST, LLM4TS), which transforms time series segments into tokens to manage sequence length and integrate with Transformer backbones [7,29,34]. Models like iTransformer, DSformer, and TimeGPT further refine the Transformer architecture for multivariate correlation and generative forecasting, demonstrating superior performance in complex tasks [3,28]. These specialized Transformer variants often prove more effective than generic LLM applications for time series, suggesting that performance gains often stem from well-designed encoding and specialized attention rather than solely from pre-trained language knowledge [4].

Beyond Transformer-centric approaches, **novel sequence models** offer alternative computational paradigms. State Space Models (SSMs), exemplified by the Mamba architecture, feature an inductive bias towards efficient sequential processing through selective state-space mechanisms. Mamba addresses the quadratic complexity limitation of Transformers by achieving linear-time scaling, making it particularly suitable for very long time series, as seen in `FLDmamba` which integrates frequency-domain analysis [21,35]. Kolmogorov-Arnold Networks (KANs) introduce an inductive bias for learning precise non-linear functional relationships, potentially offering greater interpretability and accuracy in capturing complex dynamics. `TimeKAN` and `KAN-AD` showcase their utility in frequency decomposition for forecasting and anomaly detection, respectively [21,35]. Other innovative models like `TSMixer` (a lightweight MLP-Mixer) and `TimeMixer++` (for multi-scale pattern extraction) explore different architectures to balance efficiency and expressiveness, demonstrating a diverse landscape of non-Transformer sequence modeling solutions [7,21].

**Generative and probabilistic models** are crucial for tackling the inherent uncertainty in time series data, moving beyond deterministic point forecasts provided by many traditional and earlier deep learning models. These models possess an inductive bias towards learning and representing the underlying data-generating distribution, thereby enabling probabilistic forecasting, robust uncertainty quantification, and realistic data synthesis. TimeGPT, for instance, uses conformal prediction for robust prediction intervals [3,26]. Moirai explicitly models future values as parameters of a mixed distribution, allowing for adaptable probabilistic outputs:
$$P(y_t|x_t) = \sum_{i=1}^{k} w_i \cdot p_i(y_t|x_t; \theta_i)$$
where $w_i$ are weights and $p_i$ are component distributions [14]. Diffusion models have emerged as a powerful class for probabilistic forecasting, data generation (e.g., Diffusion-TS, TSDiff), anomaly detection, and representation learning across various tasks [21,27,33,35]. Koopman models, based on Koopman theory, offer an inductive bias towards learning dynamical systems by lifting non-linear dynamics into a linear observable space, facilitating analysis and prediction of non-stationary time series (e.g., Koopa, Koopman Neural Forecaster) [27,34].

Finally, **specialized architectures and bio-inspired models** offer solutions for niche requirements such as real-time processing, energy efficiency, and edge deployment. Echo State Networks (ESNs), a form of reservoir computing, leverage an inductive bias towards fixed-topology recurrent dynamics with trained output weights, significantly reducing training complexity and making them computationally efficient for tasks like classification and forecasting [21,35]. Spiking Neural Networks (SNNs), inspired by biological neuron communication, exhibit an inductive bias towards sparse, event-driven computation, offering substantial energy efficiency on neuromorphic hardware, critical for low-power edge applications, as demonstrated by models like `TS-LIF` for multivariate forecasting [21].

These advanced deep learning architectures collectively represent crucial advancements that LLM-based and time series foundation models must contend with and build upon. LLMs, being fundamentally Transformer-based, directly benefit from innovations in efficient attention, temporal encoding, and patching developed for time series. Foundation models can integrate the probabilistic capabilities of generative models to provide uncertainty estimates or adopt the efficiency of Mamba-like architectures for long sequence processing. Understanding their unique inductive biases and architectural solutions for specific time series challenges is paramount for developing more effective, scalable, and reliable next-generation time series AI. Future research is poised to further integrate these specialized strengths into unified, powerful foundation models while continuously refining their efficiency, robustness, and interpretability for diverse temporal data challenges.
### 4.1 Transformer-based Variants and Attention Mechanisms
The advent of Transformer models has profoundly impacted time series analysis, driven by their powerful self-attention mechanisms and ability to capture long-range dependencies. However, their direct application to time series data necessitates significant architectural adaptations to address challenges such as the quadratic complexity of self-attention for long sequences, the precise encoding of temporal positionality, and the inherent causality of time series data. The evolution of Transformer models in this domain reflects a continuous effort to optimize efficiency, enhance temporal modeling capabilities, and leverage pre-trained language model (LLM) backbones [14,27,35].

A primary challenge in applying vanilla Transformers to time series is the quadratic computational and memory complexity of self-attention with respect to sequence length, $O(L^2)$. To mitigate this, several Transformer variants have introduced sparse or efficient attention mechanisms. For instance, Informer employs ProbSparse self-attention to achieve sub-quadratic dependency, while LongTrans utilizes a LogSparse design for near-linear complexity [34]. Autoformer integrates a sub-quadratic self-attention mechanism within a trend and seasonal decomposition framework, and FEDFormer incorporates a frequency-enhanced structure to improve efficiency [27,34]. Pyraformer further reduces complexity to linear by introducing pyramidal self-attention, which also enables multi-granularity attention [27,34]. Infomaxformer redesigns self-attention based on maximum entropy to introduce sparse self-attention and prevent information loss, coupled with Keys/Values Distilling for redundancy reduction and computational complexity [28]. These innovations collectively aim to make Transformers scalable for long-term time series forecasting.

Beyond efficiency, accurately encoding temporal positionality and capturing complex temporal dependencies is crucial. Traditional positional encodings, originally designed for natural language, often fall short in capturing the nuanced temporal patterns and causal relationships inherent in time series. Models like Sundial incorporate specific adaptations such as Rotary Position Embeddings (RoPE) within their causal self-attention mechanism to better infuse positional information of patched tokens [29]. MTST addresses diverse temporal patterns by using multiple branches and relative position encoding for extracting periodic components [28]. The concept of "patching" has emerged as a significant strategy, converting contiguous segments of time series into tokens. PatchTST, for example, feeds these patches to a vanilla self-attention mechanism, resolving issues with sub-quadratic approximations and outperforming models like DLinear in long-term forecasting [7,34]. LLM4TS similarly employs channel-independence and patching to overcome context window limitations of LLM backbones, effectively reducing the time dimension and expanding the feature dimension, thereby quadratically reducing complexity [25]. This patching strategy is also central to models like OneFitsAll, Time-LLM, and LLaTA, which utilize it for time series tokenization before feeding data into Transformer-based LLM architectures [4]. Novel tokenization methods, such as wavelet-based tokenization, are also being explored to enhance foundation models for time series forecasting [35].

Architectural modifications specifically designed for time series forecasting are prevalent. iTransformer rethinks the standard Transformer by inverting the attention mechanism and feed-forward network responsibilities, embedding individual series' time points into variable tokens to capture multivariate correlations [27,28]. DSformer utilizes a double sampling block for global and local information extraction and a time-variable attention block for variable correlations in multivariate forecasting [28]. GBT introduces a two-stage Transformer framework to combat overfitting in non-stationary time series by decomposing predictions into autoregressive stages [28]. Client combines linear modules for trend learning with attention modules for cross-variable dependencies, simplifying embeddings and positional encoding for efficient multivariate long-term forecasting [28]. CARD employs a dual Transformer structure with a robust loss function to capture both temporal correlations and dynamic dependencies across variables [28]. TwinsFormer proposes a Transformer-and-decomposition-based framework with residual and interactive learning [21]. Modality-aware Transformer uses feature-level and inter-modal attention layers to combine categorical text and numerical time series, enabling cross-modal understanding [28]. PETFORMER introduces a Placeholder-enhanced Technique to improve efficiency and accuracy by addressing temporal continuity and information density [28]. TimeGPT exemplifies generative pre-trained Transformer models for forecasting, leveraging a multi-layer encoder-decoder structure with residual connections and layer normalization to handle complex temporal dependencies [3,22,26].

Empirical successes of Transformer-based variants are numerous. TimeGPT demonstrates superior performance in large-scale settings and complex tasks, largely due to its self-attention mechanisms and local positional encodings [26]. Studies show that even basic components like patching and single-layer attention can be remarkably effective, sometimes outperforming full LLM methods, particularly for smaller datasets [9,15]. For larger datasets, a combination of linear model encoding and a basic Transformer module has proven more effective [9]. This suggests that while LLMs are inherently Transformer-based and their general self-attention mechanisms allow them to perform considerably in time series tasks, the actual performance often stems from well-designed encoding techniques and specialized attention, rather than solely from the pre-trained language knowledge of the LLM itself [4,8]. For instance, ablation studies replacing the full LLM with a single randomly initialized multi-head attention layer (LLM2Attn) or a basic Transformer module (LLM2Trsf) often achieve comparable or better performance with significantly lower computational cost [4,8,15].

Despite their successes, limitations persist. The challenge of effectively integrating LLMs, which are built on Transformer architectures, into time series forecasting remains. While some approaches, such as Time-LLM and LLM4TS, keep the LLM backbone largely "intact" and rely on data preprocessing like patching and channel-independence [1,25], others, like ChatTime, conceptualize time series as a "foreign language" and use normalization, discretization, and specialized tokenization to convert data into textual representations for LLM processing without altering the core architecture [14]. This highlights a debate regarding whether LLMs' full reasoning capabilities are effectively utilized or if their strength primarily lies in their underlying Transformer architecture's capacity for sequence modeling [4,8]. Additionally, the necessity for architectural innovations such as "time attention" or "dynamic time graph networks" to infer complex lag relationships and move beyond surface-level interpretations of time series data remains an active research area [32]. The "small but beautiful" models like Informer, FEDformer, and Autoformer, which are themselves Transformer-based variants optimized for time series, have demonstrated strong forecasting performance, capable of capturing both amplitude and phase information, sometimes even surpassing more generic Transformer-based LLM applications in specific scenarios [15]. This underscores that specialized architectural refinements within the Transformer framework are often more effective than generic LLM application for time series. Overall, while Transformer-based models offer significant advancements, continued research is needed to refine their efficiency, enhance their temporal reasoning, and optimally adapt them for the diverse and complex nature of time series data.
### 4.2 Novel Sequence Models (e.g., Mamba, KANs)
The landscape of time series analysis is continually evolving, with novel sequence models emerging as alternatives or complements to the widely adopted Transformer-based architectures. Among these, State Space Models (SSMs), particularly the Mamba architecture, and Kolmogorov-Arnold Networks (KANs) represent promising directions, offering distinct theoretical advantages for handling challenges inherent in time series data, such as long-sequence dependencies and non-stationarity.

Kolmogorov-Arnold Networks (KANs), a relatively new class of neural networks, are being explored for their unique properties in modeling complex non-linear relationships. This intrinsic capability positions them as potentially effective tools for capturing intricate patterns in time series. For instance, `TimeKAN` has been proposed as a KAN-based Frequency Decomposition Learning Architecture specifically designed for long-term time series forecasting, leveraging KANs to process frequency components effectively [21]. Furthermore, `KAN-AD` applies KANs to time series anomaly detection, suggesting their utility in identifying deviations from complex normal behaviors by exploiting their strong non-linear modeling capacity [35]. The theoretical advantage of KANs lies in their ability to precisely approximate continuous functions, potentially offering more interpretability and accuracy in capturing non-linear dynamics compared to traditional Multi-Layer Perceptrons (MLPs).

Mamba architectures, rooted in State Space Models, address a critical limitation of Transformers: their quadratic computational complexity with respect to sequence length, which poses challenges for long-sequence modeling. The Mamba architecture is designed for efficient processing, particularly for extended sequences, by replacing the attention mechanism with a selective state-space model that exhibits linear-time complexity. This efficiency is underscored by research indicating efforts towards "Efficient Time Series Processing for Transformers and State-Space Models through Token Merging," implying Mamba-like architectures are considered for their efficiency gains [35]. In the context of time series, `FLDmamba` integrates Fourier and Laplace Transform Decomposition with the Mamba architecture, aiming to enhance time series prediction by combining Mamba's efficient sequence handling with frequency-domain analysis [21]. This integration could be particularly beneficial for capturing periodic and transient patterns over long horizons.

When comparing these novel models against Transformer-based architectures, several distinctions emerge. For long-sequence modeling, Mamba offers a clear theoretical advantage in computational efficiency due to its linear scaling, contrasting with Transformers' quadratic attention mechanism. This makes Mamba particularly appealing for scenarios requiring processing very long time series, where Transformer-based models might become prohibitively expensive. While specific performance comparisons for handling non-stationary data are still an active area of research, KANs' strong non-linear approximation capabilities could render them adept at modeling evolving data distributions. Transformers, while powerful, rely heavily on their attention mechanism to learn dependencies, which might be less efficient for capturing dynamic shifts in non-stationary patterns compared to specialized recurrent or state-space approaches.

Beyond Mamba and KANs, the field is exploring other novel sequence modeling paradigms. For instance, `TimeMixer++` operates as a "General Time Series Pattern Machine" using multi-scale and multi-resolution pattern extraction, aiming for universal predictive analysis across diverse tasks [21]. Similarly, `Time-MoE` introduces billion-scale time series foundation models utilizing a Mixture of Experts architecture for forecasting, indicating a move towards highly scalable and specialized models [21]. Other efficient alternatives to Transformers include `TSMixer`, a lightweight MLP-Mixer model for multivariate time series forecasting that incorporates online coordination heads and hybrid channel modeling [28]. Models like `FDNet` focus on extracting fine-grained local features, and `MPPN` employs multi-resolution periodic pattern mining, demonstrating varied approaches to deep time series prediction without necessarily relying on Transformer's global attention [28]. These diverse models underscore a collective effort to develop architectures that are either more efficient, more robust, or better tailored to specific time series characteristics than general Transformer models. It is noteworthy that even a basic Transformer component, without the vast pre-training of a full LLM, has demonstrated effectiveness as an encoder for time series data, outperforming many other encoding methods on larger datasets [8].

Practical challenges for Mamba and KANs include their relative novelty, which means less established best practices, fewer readily available pre-trained models, and potentially higher computational demands for initial training or fine-tuning in certain applications compared to the extensively optimized Transformer ecosystem. Despite these challenges, the theoretical advantages, particularly Mamba's efficiency for long sequences and KANs' non-linear modeling prowess, position them as significant contributors to the evolution of time series analysis, warranting continued research and development.
### 4.3 Generative and Probabilistic Models (e.g., Diffusion Models, Koopman)
Generative and probabilistic models offer significant advantages in addressing the inherent uncertainty and complexity characteristic of time series data, contrasting sharply with traditional deterministic predictive models that typically yield only point forecasts. These models are designed to capture the full distribution of possible future outcomes or underlying data generating processes, thereby enabling more robust analysis, realistic data generation, enhanced anomaly detection, and comprehensive probabilistic forecasting.

A key strength of these models lies in their capacity for **probabilistic forecasting and uncertainty quantification**. Unlike deterministic approaches that provide a single future value, generative models can predict a range of possibilities, quantifying the uncertainty associated with each prediction. For instance, TimeGPT, a generative pre-trained Transformer model, integrates conformal prediction to estimate prediction intervals based on historical errors [3,22]. This non-parametric method provides prediction intervals with specified coverage accuracy without requiring strict distributional assumptions, thereby enhancing risk assessment and decision-making by revealing the inherent uncertainty in forecasts [26]. Similarly, Moirai, a time series foundation model, explicitly models future values as a distribution rather than concrete points. It predicts the parameters of a mixed distribution (e.g., Student's t-distribution, Negative Binomial, Log-Normal, Normal distribution) to adapt to diverse data distributions, formulated as:
$$P(y_t|x_t) = \sum_{i=1}^{k} w_i \cdot p_i(y_t|x_t; \theta_i)$$
where $w_i$ denotes the weight of each component distribution and $p_i$ represents a predefined distribution [14]. Other probabilistic models, such as Lag-Llama, are also being developed as univariate probabilistic time series forecasting foundation models [12,16,19].

Beyond forecasting, these models excel in **realistic data generation and synthesis**. The generative nature of Large Language Models (LLMs) can be leveraged, as demonstrated by LLMTime, which samples "possible extrapolations as text completions" to treat forecasting as a generative task, producing sequences of likely future values [5]. Sundial, highlighted as a pioneering family of generative models among time series foundation models, specifically addresses the limitation of existing non-generative models by enabling probabilistic forecasting and generating "multiple probable predictions" [29]. Sundial employs a flow-matching framework, noted for its efficiency and sample quality, in contrast to denoising diffusion models, and introduces a novel "TimeFlow Loss" to learn and sample from predictive distributions autoregressively without discrete tokenization or predefined prior distributions [29]. This capability provides diverse plausible future outcomes, directly tackling the non-deterministic nature of time series. The "NuwaTS" model also implies the utility of generative approaches for time series completion or imputation [20].

**Diffusion models** have emerged as a prominent class within generative models for time series, offering robust capabilities across various tasks. They are widely applied for probabilistic forecasting, enabling models such as "Transformer-Modulated Diffusion Models for Probabilistic Multivariate Time Series Forecasting" [27], "Latent Diffusion Transformer for Probabilistic Time Series Forecasting" [27], and "Autoregressive Denoising Diffusion Models for Multivariate Probabilistic Time Series Forecasting" [27]. Recent advancements include "Diffusion-based Decoupled Deterministic and Uncertain Framework for Probabilistic Multivariate Time Series Forecasting" and models designed for "Non-stationary Diffusion For Probabilistic Time Series Forecasting" and "Conditional Diffusion Model with Nonlinear Data Transformation for Time Series Forecasting" [21,35]. For time series generation, models like "Diffusion-TS: Interpretable Diffusion for General Time Series Generation" [27] and the task-agnostic unconditional diffusion model TSDiff, which employs a self-guiding mechanism for synthetic data generation [28], demonstrate their versatility. Diffusion models are also effective for **anomaly detection**, as seen in "Imputation-based Time-Series Anomaly Detection with Conditional Weight-Incremental Diffusion Models" [27] and "Multi-Resolution Decomposable Diffusion Model for Non-Stationary Time Series Anomaly Detection" [21]. Furthermore, they contribute to imputation tasks, such as "LSCD: Lomb--Scargle Conditioned Diffusion for Irregular Time series Imputation" [35], and representation learning through models like "TimeDART: A Diffusion Autoregressive Transformer for Self-Supervised Time Series Representation" [35]. Innovations in architectural design, such as "A Temporal Correlation-Empowered Diffusion Model for Time Series Forecasting" [33] and "Transformer-based Diffusion Probabilistic Model for Heart Rate and Blood Pressure Forecasting in Intensive Care Unit (TDSTF)" which merges Transformer and diffusion models for efficient vital sign prediction [28], continually expand their utility.

**Koopman models** provide another powerful framework for handling time series complexity by learning the underlying dynamics. These models leverage Koopman theory to lift nonlinear dynamics into a linear space, facilitating analysis and prediction. Applications include learning nonstationary time series dynamics with "Koopa: Learning Nonstationary Time Series Dynamics with Koopman Predictors" [27] and forecasting with models like "Koopman Neural Operator Forecaster for Time-series with Temporal Distributional Shifts" [27] and "Koopman Neural Forecaster" [34]. For probabilistic forecasting, "KooNPro: A Variance-Aware Koopman Probabilistic Model Enhanced by Neural Processes for Time Series Forecasting" [21] and "VAE: A Koopman-Kalman Enhanced Variational AutoEncoder for Probabilistic Time Series Forecasting" [35] illustrate their ability to handle uncertainty. Furthermore, Koopman models contribute to generative modeling, as exemplified by "Generative Modeling of Regular and Irregular Time Series Data via Koopman VAEs" [27], and support advanced time series analysis through models like "SKOLR: Structured Koopman Operator Linear RNN for Time-Series Forecasting" and "KoNODE: Koopman-Driven Neural Ordinary Differential Equations with Evolving Parameters for Time Series Analysis" [35].

In summary, generative and probabilistic models significantly enhance time series analysis by moving beyond deterministic point predictions. They intrinsically account for the stochastic nature of real-world phenomena, providing richer information through probabilistic distributions and enabling comprehensive uncertainty quantification. This capability facilitates more robust decision-making, sophisticated anomaly detection by identifying deviations from learned distributions, and the creation of realistic synthetic data for various applications. While diffusion models excel in their versatility for generation and robust probabilistic forecasting across diverse tasks, Koopman models offer a structured approach to learning and forecasting based on underlying system dynamics. The convergence of these advanced generative techniques, often integrated with large language models, marks a substantial advancement towards more comprehensive and reliable time series intelligence.
### 4.4 Specialized Architectures and Bio-inspired Models (e.g., Spiking NNs, Echo State Networks)
Beyond mainstream deep learning paradigms, specialized architectures and bio-inspired models offer distinct advantages for addressing particular time series challenges, particularly those requiring real-time processing, energy efficiency, or deployment on resource-constrained edge devices. Among these, Echo State Networks (ESNs) and Spiking Neural Networks (SNNs) represent prominent alternatives, leveraging unique design principles to achieve computational efficiency and biological plausibility.

Echo State Networks (ESNs), a form of Reservoir Computing, are recognized for their efficacy in various time series tasks. Their fundamental design involves a randomly and sparsely connected recurrent neural network (the "reservoir") with fixed internal weights, where only the weights connecting the reservoir to the output layer are trained. This significantly reduces the computational cost and training time compared to traditional recurrent neural networks, making them suitable for fast and accurate time series classification [35]. Furthermore, ESNs have been successfully applied to time series forecasting, with advancements such as "Locally Connected Echo State Networks for Time Series Forecasting" proposing improved methodologies for this domain [21]. The inherent efficiency derived from their training paradigm positions ESNs as a compelling choice for applications demanding rapid adaptation and real-time processing capabilities.

Spiking Neural Networks (SNNs), inspired by the event-driven communication of biological neurons, represent another class of bio-inspired models. Unlike conventional artificial neural networks that process continuous values, SNNs operate on discrete "spikes" or events, transmitting information only when a neuron's membrane potential crosses a threshold. This event-driven computation offers significant potential for energy efficiency, especially when deployed on neuromorphic hardware, aligning perfectly with the requirements of low-power edge deployment. For time series tasks, SNNs have demonstrated their utility in multivariate time series forecasting. For instance, "TS-LIF: A Temporal Segment Spiking Neuron Network for Time Series Forecasting" introduces an SNN model specifically designed for this purpose, with its stability and frequency response characteristics thoroughly analyzed to support its robustness and applicability [21]. The low-power operation and inherent parallelism of SNNs provide a viable alternative for processing complex time series data in environments where energy consumption is a critical constraint.

While broader surveys on AI for time series or spatio-temporal data may not always explicitly feature these specialized models [7,27], their specific design principles offer clear advantages. ESNs provide computational efficiency for classification and forecasting due to their simplified training process, directly benefiting real-time applications. SNNs, with their event-driven nature, present a compelling solution for energy-efficient processing and edge deployment, addressing the computational demands of time series analysis in resource-limited settings. These models thus carve out niche applications where their unique characteristics provide superior performance or enable scenarios not feasible with mainstream deep learning.
## 5. Data Representation and Modality Bridging
The application of Large Language Models (LLMs) to time series analysis fundamentally hinges on addressing a critical "modality gap" [30,31]. This gap arises from the inherent distinctions between the discrete, token-based, and structured grammatical nature of textual data on which LLMs are predominantly trained, and the continuous, numerical, time-dependent, and often irregularly sampled or noisy characteristics of time series data [2,30]. Bridging this disparity necessitates sophisticated strategies for representing time series data in formats compatible with LLMs, or for enabling LLMs to process diverse modalities directly.

The initial and critical step in integrating LLMs with time series involves converting raw numerical time series into 'textual' or tokenized representations that LLMs can effectively process [2,6]. This transformation is essential for aligning time series features with the linguistic space of LLMs. Various approaches have emerged to tackle this challenge, which can be broadly categorized into:
1.  **Text-based Representations**: Transforming numerical series directly into text or text-like tokens.
2.  **Visual Representations**: Converting time series into images to leverage multimodal LLMs (M-LLMs) with visual processing capabilities.
3.  **Time Series Quantization**: Discretizing continuous numerical data into a finite set of tokens.
4.  **Other Multimodal Representations**: Integrating inherently structured data types such as graphs, audio, and tables for a richer context.

Each representation strategy presents distinct advantages and disadvantages, influencing LLM performance and interpretation [34,35]. Text-based methods, including direct prompting or reprogramming with text prototypes, aim to leverage LLMs' powerful reasoning by casting time series problems as language tasks [1,5]. While these approaches simplify LLM integration, they often contend with challenges such as the loss of numerical precision, difficulties in preserving subtle temporal relationships, and the potential for LLMs to generate plausible but numerically inaccurate outputs [2,30].

Visual representations, such as converting time series into line graphs, heatmaps, or spectrograms, capitalize on the "visual advantage" of M-LLMs for pattern recognition and anomaly detection, as LLMs often exhibit improved performance when presented with visual rather than raw textual data [17,30]. This method facilitates qualitative analysis but typically sacrifices fine-grained numerical accuracy and can be computationally intensive for large datasets.

Time series quantization techniques, such as Vector Quantized Variational AutoEncoders (VQ-VAE), K-Means clustering, and binning, convert continuous numerical values into discrete tokens or categorical representations [19,30]. Patching, which segments time series into fixed-size components that are then tokenized, is another prevalent strategy for LLM input [4,23]. Quantization enhances LLM compatibility and efficiency, particularly for managing long sequences. However, it introduces a trade-off, as discretization can lead to information loss or coarse-grained predictions [29,30]. Some contemporary methods endeavor to mitigate these issues by transforming tokens into more flexible continuous values, aiming to preserve numerical richness without explicit traditional quantization [2,29].

Beyond these core methods, the conceptual importance of integrating diverse modalities, including graphs for spatio-temporal data, audio signals for time-dependent sound analysis, and structured tabular data, is increasingly recognized for achieving richer time series reasoning [11,32]. This involves developing sophisticated alignment techniques and unified M-LLM architectures capable of processing and reasoning across intrinsically different data types and temporal dimensions [32]. Models like TimeGPT, which processes numerical data with minimal preprocessing, represent an alternative paradigm that directly operates on continuous values, challenging the necessity of extensive text-based conversion [3].

The optimal choice of representation technique is highly scenario-dependent. For instance, direct prompting might suit qualitative analyses or those leveraging rich textual context alongside numerical data, while visual methods excel in pattern recognition tasks like anomaly detection. Quantization is beneficial for managing model complexity and handling long sequences, especially when some loss of precision is tolerable or can be compensated by context. Integration of graphs or audio is crucial for applications where relationships between entities or specific signal characteristics are paramount.

Despite significant progress in modality alignment [1,34], several challenges persist. The scarcity of well-curated, paired time series and text datasets hampers the training and evaluation of multimodal models [34]. Moreover, ensuring that LLMs genuinely 'understand' time series patterns and numerical relationships, rather than merely performing pattern matching on textual proxies, remains an active area of research [9]. Future directions emphasize developing more robust, natively multimodal foundation models for time series, improving information preservation during conversion, and constructing unified architectures that can seamlessly integrate and reason across heterogeneous data streams to achieve comprehensive temporal intelligence.
### 5.1 A Taxonomy and Landscape of Modalities for Time Series FMs
The increasing complexity and interconnectedness of real-world phenomena necessitate a multimodal approach to time series analysis, where various forms of time-dependent data are integrated into advanced Foundation Model (FM) frameworks [32]. This emergent field requires a clear taxonomy of how time series data can be represented across diverse modalities to facilitate their interaction with FMs, particularly Large Language Models (LLMs) [11].

A primary challenge in this domain is the inherent "modality gap" that exists between continuous numerical time series data and the discrete, text-centric nature of many conventional LLMs [30]. This gap requires sophisticated strategies to enable LLMs to effectively process and interpret time series information. To bridge this divide, researchers are exploring conceptual strategies such as Direct Prompting, Time Series Quantization, Alignment techniques, Vision as Bridge, and Tool Integration [31]. These methods aim to transform numerical time series data into formats compatible with LLMs, for instance, by converting numerical sequences into textual representations [5,30] or by employing hybrid approaches that combine numerical data with textual contexts like clinical reports alongside ECG signals [16].

The landscape of multimodal FMs for time series is characterized by a dual approach: adapting existing text-centric models and developing natively multimodal architectures. A comprehensive taxonomy of time series modalities includes:
*   **Numerical Data**: The foundational data type, representing core time series observations [35].
*   **Text**: Utilized for tasks such as generating time series from textual descriptions, integrating natural language for enhanced analysis, or providing contextual information like financial reports alongside stock data [14,34,35].
*   **Images**: Time series can be visually represented to leverage the capabilities of vision-language models [12,35].
*   **Graphs**: Employed for spatio-temporal data or modeling complex relationships within multivariate time series [12,35].
*   **Audio**: Exploring the integration of audio signals with time series data [12,32].
*   **Tables**: Representing structured time series data often found in databases [11].

This breadth of modalities is reflected in the diverse range of Multimodal LLMs (M-LLMs) and other multimodal FMs currently being explored. Some M-LLMs are general-purpose, capable of handling Text & Image combinations (e.g., GPT-4, Gemini 1.5, Claude 3 Haiku, Llama 3), while others are more specialized for Graph (e.g., UrbanGPT, STD-PLM), Audio (e.g., SpeechGPT, AudioGPT), or Table modalities (e.g., TabPFN, TableLlama) [11]. For time series specifically, models such as Time-VLM and ITFormer explore vision-language integration for tasks like forecasting and multi-modal QA [35]. Dedicated multimodal time series models like ChatTime support both time series and text as input and output, integrating textual context with time series data [14]. Other examples include BloombergGPT for financial time series, GPT4TS for general time series processing, and Auto-TTE for specialized tasks like ECG analysis [30]. The field also sees the application of state-of-the-art M-LLMs to assess performance across different anomaly types and input modalities in time series analysis [17].

The landscape of research in this area exhibits several commonalities and contrasts. A common thread is the pursuit of leveraging the advanced reasoning and generative capabilities of LLMs for time series tasks, often by adapting LLMs to process various data modes [2,12]. This often involves sophisticated transformation of time series data into text or other compatible formats [30]. Contrasting approaches include directly adapting existing LLMs for time series problems versus the development of "Time Series Domain Large Models" which are foundation models natively designed for time series data [14,16]. Furthermore, a critical observation is the scarcity of well-curated, paired time series and text datasets, which are essential for advancing multimodal time series forecasting and other related tasks, as highlighted by initiatives like the TimeText Corpus (TTC) [34]. This active exploration of diverse data modalities and integration strategies underpins the rapidly evolving field of multimodal time series FMs, setting the stage for more detailed discussions on specific representation and modeling techniques.
### 5.2 Text-based Representations
The integration of Large Language Models (LLMs) into time series analysis necessitates converting numerical time series data into formats compatible with their text-centric architectures. This field primarily explores two main text-based representation strategies: reprogramming with text prototypes and direct numerical input conversion into prompts, each with distinct advantages and limitations. The overarching rationale for adopting text as a modality is to leverage LLMs' powerful language processing capabilities, generalizable reasoning patterns, and efficacy in zero-shot or few-shot learning scenarios for time series tasks [2,30,31].

One sophisticated approach involves **reprogramming time series with text prototypes**, which aims to align numerical data with the language space of LLMs. Time-LLM exemplifies this by reprogramming input time series through text prototypes before feeding them into a frozen LLM [1,14,16,28]. This method uses a "Prompt-as-Prefix" (PaP) strategy to enrich the input context and guide the transformation of reprogrammed time series patches within the LLM, thereby augmenting its ability to reason with time series data [1,28]. Similarly, TEST constructs encoders for time series data, leveraging alignment contrast and soft prompts to utilize frozen LLMs, aligning time series embeddings with text prototypes via instance, feature, and text prototype-aligned contrastive learning [2,14,16,20,27]. TEMPO combines seasonal and trend decomposition with frozen LLMs using prompt pooling to process non-stationary time series [2,27]. CALF, another method, treats each time series channel as a "word" and uses cross-attention to align it with the LLM's low-dimensional word embeddings for "text prediction" [15]. These methods implicitly or explicitly "learn the language of time series" by converting data into a language-like format, such as tokens, that LLMs can process [19].

In contrast, **direct prompting techniques** convert numerical time series into natural language descriptions or carefully formatted numerical strings. This simpler approach allows LLMs to infer patterns without architectural modifications or extensive fine-tuning [30]. For instance, a time series like "72.5, 74.1, 75.3, 76.8" could be directly presented as "The temperature has risen steadily for four consecutive days. What will happen next?" or "The sales for the past five days were 1 0 5, 1 1 0, 1 1 8, 1 2 5. Predict the next value" [30]. PromptCast and AuxMobLCast convert numerical inputs and outputs into textual prompts, framing forecasting as a "sentence-to-sentence" task to make human mobility forecasting and other time series tasks amenable to existing language models [14,16,31]. PatchInstruct refines this by decomposing raw time series into trend, seasonal, and residual components, then dividing each into numerical "patches" that are represented as textual strings. These prompts are further augmented with similar historical data points to enable in-context learning [24]. LLMTime represents time series as a string of numerical digits, effectively treating time series forecasting as a "modified language task" for next-token prediction [34].

While direct prompting offers simplicity, enabling good qualitative reasoning and exploratory analysis for classification and anomaly detection without complex numerical calculations, it faces significant limitations [30]. The primary challenge lies in aligning the semantic richness of natural language with the numerical precision of time series. Traditional LLM tokenizers are not designed for continuous numerical data, often separating continuous values and ignoring their temporal relationships, leading to a lack of numerical precision and struggles with complex relationships [2,30]. This conversion can result in information loss or distortion, as the nuanced numerical properties are flattened into discrete linguistic tokens [30,31]. For instance, LLMs struggle with precise arithmetic operations and cannot compute exact probability distributions [30].

Critically, there is an ongoing debate about the extent to which LLMs truly 'understand' time series patterns via prompting versus simply performing pattern matching on textual representations. Studies suggest that despite sophisticated text-based representations like patching and instance normalization, the full pre-trained knowledge of LLMs is often not effectively utilized for numerical precision or complex time series relationships [4,9,15]. This implies that converting time series into text-like formats does not necessarily enable LLMs to leverage their inherent reasoning for numerical tasks effectively, potentially leading to spurious correlations or 'hallucinations' where the model generates plausible but numerically inaccurate outputs [30]. Indeed, some findings indicate that LLMs perform worse when time series are presented as text compared to visual representations for tasks like anomaly detection, highlighting inherent limitations in processing linearized numerical data for pattern recognition [17].

Comparing these text-based representation methods, reprogramming with text prototypes (e.g., Time-LLM, TEST) typically involves a more intricate process of aligning time series features with the LLM's embedding space, aiming for a deeper integration of numerical and linguistic modalities [16]. This approach assumes that by mapping time series into a language-compatible space, the LLM can more effectively apply its pre-trained knowledge. Conversely, converting numerical inputs into prompts (e.g., PromptCast, AuxMobLCast, LLMTime) relies more on the LLM's ability to interpret structured natural language directly. The former aims to modify the input's *representation* to fit the LLM's internal mechanisms, while the latter focuses on crafting *external prompts* that the LLM can process. The trade-off is evident: prototype-based methods offer potentially higher precision through deeper alignment but involve more complex engineering, whereas direct prompting is simpler and immediately applicable to any pre-trained LLM, but sacrifices numerical exactitude and often struggles with long-term temporal relationships due to limited memory capacity [14,30]. Approaches like UniTime and Modality-aware Transformers explore combining domain descriptions or categorical text with numerical time series to bridge modalities, indicating a broader move towards multimodal context for enhanced time series analysis [28,32,35].
### 5.3 Visual Representations
The integration of visual representations has emerged as a significant paradigm in enabling Large Language Models (LLMs) to process and analyze time series data, leveraging the inherent visual pattern recognition capabilities of multimodal LLMs (M-LLMs). A prominent finding highlights a "visual advantage" for time series anomaly detection, where LLMs demonstrate substantially improved performance when time series data is presented as images rather than raw text [17]. This effectiveness stems from M-LLMs' ability to leverage their visual processing capabilities to discern patterns and anomalies within graphical representations, a task that often aligns with human cognitive strengths in interpreting visual information [17,30].

Various approaches have been proposed to convert time series data into visual formats suitable for M-LLM consumption. These include mapping numerical time series to simple line graphs, heatmaps, or spectrograms, with the choice of format optimized to highlight specific data aspects such as trends, correlations, or frequency components [30]. For instance, stock price charts effectively visualize trends, while spectrograms can capture patterns in audio or medical signals, and heatmaps reveal interdependencies in multivariate time series [30]. More advanced methods involve converting time series into novel binary machine vision spaces, such as in the MV-DTSA framework, which maps time series to binary images for forecasting via specialized deep machine vision models [28]. Several research initiatives, including "TimeSeriesExam," "Plots Unlock Time-Series Understanding in Multimodal Models," and "A Picture is Worth A Thousand Numbers: Enabling LLMs Reason about Time Series via Visualization," explicitly focus on this conversion to enable time series understanding in multimodal models [11]. The concept of "Time Series as Images: Vision Transformer for Irregularly Sampled Time Series" further exemplifies this trend, utilizing Vision Transformers for analysis [11,27].

This "Vision as Bridge" strategy allows for the utilization of advanced Visual Language Models (VLMs), such as GPT-4, Gemini 1.5, Claude 3, CLIP, ImageBind, and Flamingo, which are pre-trained on extensive image-text datasets and can align visual and textual features in a shared semantic space [11,30,31]. These models can then describe visual time series representations, identify broad trends, anomalies, and patterns, and answer qualitative questions like "Does this chart show an upward trend?" [30]. This approach is particularly effective for exploratory analysis, pattern recognition, and detecting salient anomalies, such as "head and shoulder" patterns in financial charts or irregular heartbeats in ECGs [30]. The advantage lies in harnessing the complementary strengths of visual models and LLMs, fostering a deeper integration of structured numerical data with unstructured linguistic reasoning [30].

Despite these advantages, employing vision as an intermediary also introduces certain limitations. A primary disadvantage is the potential lack of fine-grained numerical accuracy [30]. While visual models excel at recognizing broad trends and qualitative patterns, they are not optimized for precise numerical calculations, making them more suitable for qualitative insights than exact predictions [30]. Furthermore, the conversion process itself can present scalability challenges, as transforming large time series datasets into images and subsequently processing them demands significant computational resources and time, which may impede real-time applications [30].

Regarding anomaly detection, even with visual input, LLMs exhibit limitations, showing biases akin to human perception, particularly in identifying subtle frequency anomalies or rapidly accelerating patterns [17]. To mitigate these challenges, pre-processing steps are crucial. For instance, applying Fourier analysis to time series data before visual conversion can enhance the detectability of frequency-related anomalies, thereby overcoming some inherent limitations of direct visual interpretation by M-LLMs [17]. Therefore, while visual representations offer a compelling avenue for LLM-based time series analysis, careful consideration of the trade-offs between qualitative understanding and quantitative precision, alongside strategic pre-processing, is essential for robust application.
### 5.4 Time Series Quantization
Time series quantization serves as a crucial strategy to bridge the inherent incompatibility between continuous numerical time series data and the discrete token inputs typically processed by Large Language Models (LLMs) [6,30]. Traditional LLM tokenizers are not intrinsically designed for numerical values, frequently fragmenting continuous data and overlooking crucial temporal relationships [2]. By converting continuous values into a discrete format, quantization enables LLMs to treat numerical data as structured information, enhancing their ability to process and understand time series patterns [30].

Various methodologies have been developed for time series quantization, each with distinct approaches to discretization and preservation of data characteristics.

1.  **Vector Quantized Variational AutoEncoder (VQ-VAE)**: This advanced technique learns a discrete embedding dictionary or "codebook." Each continuous time series point is then mapped to the closest vector within this predefined codebook, effectively assigning a categorical representation. For example, a stock price of 101.37 might be assigned to "A1" from the codebook [30]. Chronos by AWS is a prominent example employing VQ-VAE to transform real-valued time series data into categorical tokens, thereby making it amenable to Transformer-based LLMs without altering their core architecture [11,19,20,30]. Similarly, VQ-TR (Vector Quantized Attention for Time Series Forecasting) further demonstrates the application of vector quantization in time series modeling, reinforcing its role in discretizing continuous data for token-based models [27]. This method aims to preserve underlying characteristics by learning an optimal discrete representation.

2.  **K-Means Clustering**: This approach groups similar continuous values into a predefined number of clusters, assigning a cluster ID to each data point. For instance, a time series sequence $\langle 0.5, 1.2, 2.8, 1.3 \rangle$ could be represented as $\langle C_1, C_1, C_2, C_1 \rangle$ for two clusters [30]. K-Means clustering is particularly effective at reducing noise in high-frequency data, such as IoT sensor readings [30]. Both VQ-VAE and K-Means clustering are highlighted as methods to generate discrete indices for LLM processing [31].

3.  **Binning**: A simpler method, binning involves mapping continuous values to predefined categories based on fixed or adaptive intervals. For example, $\langle 0.5, 1.2, 2.8 \rangle$ could be binned into $\langle \text{Low}, \text{Medium}, \text{High} \rangle$ [30]. Adaptive binning adjusts interval sizes based on data distribution to better represent significant values and prevent imbalances [30]. ChatTime applies a specific binning technique where historical data is first min-max normalized to the range $$. This reduces computational cost associated with character-level tokenization in numerical data [14].

4.  **Patching or Segmentation**: This involves breaking continuous time series data into smaller, fixed-size segments or "patches." While not always explicitly termed quantization in the sense of VQ-VAE or K-means, it constitutes a form of discretization of the temporal axis [13,23]. Methods like PatchInstruct use 'patch-based tokenization' where continuous data is segmented into fixed-length patches, which are then converted into textual representations for LLM prompts [24]. These numerical patches are often encoded into embeddings using convolutional layers before being fed to the LLM, enabling the LLM to process time series data through its token-based mechanisms [25]. Patching technology is recognized as a primary method for preparing time series data for LLM inputs, making continuous data compatible with LLM processing [4].

5.  **Wavelet-based Tokenization**: This emerging technique proposes using wavelet transforms to tokenize continuous time series data, aiming to enhance compatibility with Transformer-based models and LLMs [35].

While traditional quantization methods convert continuous numerical values into discrete categorical tokens, some approaches seek to maintain a more continuous representation. LLMTime introduces a novel tokenization method that transforms tokens into flexible continuous values, enabling untuned LLMs to achieve strong zero-shot prediction performance by creating continuous representations that LLMs can process, rather than direct discrete quantization [2,5]. Similarly, the work "Large Language Models Are Zero-Shot Time Series Forecasters" describes converting "discrete distributions into highly flexible continuous value densities" to make time series data digestible for LLMs, addressing numerical representation challenges without explicit traditional quantization [12,14,16].

**Impact on Prediction Accuracy and Capturing Subtle Patterns:**
Quantization generally offers several benefits: it reduces the number of unique tokens an LLM must process, eliminates fragmentation in numerical representations, improves prediction consistency, and enhances LLM efficiency for handling long sequences [30]. By grouping similar numbers into fixed tokens, LLMs can handle structured data without losing its inherent meaning [30].

However, discretization also introduces challenges. K-Means clustering and fixed binning methods can struggle when underlying patterns change or sudden out-of-cluster events occur (e.g., a rapid stock price surge), requiring dynamic adaptation from the model to avoid misrepresentation [30]. Fixed binning, while simple, may lead to a loss of detail and accuracy, particularly with extreme values, prioritizing simplicity over precision [30]. Furthermore, models like Sundial explicitly move away from "discrete tokenization," arguing that it leads to "out-of-vocabulary issues and coarse-grained prediction intervals" that compromise numerical precision and flexible distribution learning [29]. Sundial and TimeGPT focus on native pre-training on continuous-valued time series to avoid these issues, implying that direct use of continuous data can be advantageous for preserving precision [3,29].

**Comparison and Situational Advantages/Disadvantages:**
The choice of quantization strategy significantly influences how well the underlying time series characteristics and numerical relationships are preserved. VQ-VAE, by learning a sophisticated codebook, attempts to optimize the trade-off between discretization and information retention, making it suitable for complex patterns. K-Means clustering is advantageous for noise reduction in high-frequency data but requires robust cluster definitions that can adapt to data shifts [30]. Binning is computationally inexpensive and suitable for scenarios where high precision is not paramount or for initial data exploration. ChatTime's binning approach, combined with min-max normalization and character mapping, highlights an effort to optimize for LLM compatibility and computational efficiency [14]. Patching techniques are particularly advantageous for preserving local temporal relationships and simplifying the input length for LLMs, especially when combined with specialized encoding layers [25].

Conversely, approaches that aim to preserve more of the continuous nature, such as LLMTime's flexible continuous values or the "Zero-Shot Time Series Forecasters'" conversion to continuous value densities, address the limitations of strict discrete tokenization, potentially leading to better capture of subtle patterns and improved prediction accuracy by offering LLMs a richer numerical context [2,12]. However, these methods might introduce different computational complexities or require specific architectural designs within the LLM to effectively process such representations. The ongoing debate, exemplified by models like Sundial, suggests that while quantization is necessary for some LLM architectures, bypassing it entirely by enabling LLMs to natively handle continuous data could mitigate intrinsic limitations like out-of-vocabulary issues [29]. The optimal quantization strategy therefore depends on the specific requirements of the application, the complexity of the time series data, and the LLM's architecture.
### 5.5 Other Multimodal Representations (e.g., Graphs, Audio, Tables)
Beyond conventional numerical, textual, and visual data, the integration of less common modalities such as graphs, audio, and tabular data with Large Language Models (LLMs) offers significant potential for enhancing time series analysis. This approach aims to leverage the inherent structures and information embedded within these diverse data types to achieve a more comprehensive understanding and reasoning of temporal phenomena [6,32].

**Graph-based Representations for Time Series**
Graph-based representations are particularly advantageous for time series data that exhibit complex interdependencies or spatial-temporal relationships. These include scenarios such as urban traffic prediction, wildfire spread modeling, and financial market analysis, where entities or events are interconnected over time and space [2,11,27]. For instance, spatio-temporal data, where observations are collected from geographically distributed sensors or locations, inherently benefits from graph structures to model spatial proximity and temporal dynamics simultaneously [2,27]. Multivariate time series, especially those with irregular sampling or complex channel relationships, can also be effectively captured by graphs [35].

Innovations in Multimodal LLM (M-LLM) architectures for graph-based time series include several specialized approaches. Graph Neural Networks (GNNs) and Hypergraph Neural Networks (HNNs) are widely employed to capture intricate relationships within irregular multivariate time series, as seen in "Hi-Patch" and "HyperIMTS" [35]. Models like "TIMEGNN" learn dynamic temporal graph representations to model evolving correlations among multiple time series, while "SageFormer" utilizes graph structures to explicitly identify and model inter-series relationships within Transformer architectures [28]. For spatio-temporal forecasting, models such as "Spatio-Temporal Pivotal Graph Neural Networks," "FourierGNN," "GraphCast," and "Pre-training Enhanced Spatial-temporal Graph Neural Network" integrate graph-based reasoning with temporal components [7,27]. Specific LLM-integrated models like GATGPT and ST-LLM apply LLM insights to spatio-temporal data, and ChatGPT Informed Graph Neural Network has been used for stock movement prediction [2,11]. The concept of "dynamic time graph networks" has been proposed to infer lag relationships, further highlighting the architectural requirements for capturing complex time-dependent interdependencies [32]. Furthermore, graph-based representations are crucial for causal inference in time series, with works like "Root Cause Analysis of Anomalies in Multivariate Time Series through Granger Causal Discovery" and "DyCAST" focusing on learning dynamic causal structures [21].

**Audio-based Representations for Time Series**
Audio signals, fundamentally a form of time series data, represent another significant modality for LLM integration. Applications range from sound event detection over time to the processing of biomedical signals like Electrocardiogram (ECG) and Electroencephalography (EEG) [6,12,30,31]. For instance, `AudioGen` demonstrates the potential for quantizing audio signals for LLM processing, while `EEG-to-Text` approaches translate brain activity into text for compatibility with LLMs [31]. The "Voice2Series" framework illustrates how acoustic models can be reprogrammed for time series classification, indicating a direct application of audio processing techniques to time series problems [7,11]. Specialized audio-compatible LLMs such as SpeechGPT, AudioGPT, and MinMo represent existing models designed to process and reason with audio inputs, suggesting avenues for extending their capabilities to time series analysis [11]. The integration of audio signals in MLLMs is vital for comprehensive reasoning in time-related tasks [32]. Moreover, hybrid multimodal approaches combine audio-like signals (e.g., ECG) with text reports for tasks like zero-shot classification, maximizing similarity between modalities [12,16].

**Table-based Representations for Time Series**
Tabular data is often intrinsic to time series, particularly in domains like finance, where datasets include numerical amounts, time stamps, and categorical features such as 'Category', 'Sub-category', and 'Program' [10,30]. While the direct integration of these diverse features into LLMs might involve implicit data transformation, the explicit processing of tabular structures can offer supplementary information for advanced time series tasks, including generation and editing [32]. Architectural innovations in this area include "TableTime," which reformulates time series classification as training-free table understanding using LLMs [11]. The strong performance of models like "TabPFN" (Table-based Pre-trained Feature Network), which can outperform specialized time series forecasting models based on simple features, highlights the effectiveness of LLMs in processing tabular data for temporal predictions [11]. Other table-compatible LLMs such as TableLlama and TableGPT2 further demonstrate this growing integration [11].

**Architectural Requirements, Innovations, and Challenges**
The core challenge in integrating these diverse inputs lies in creating unified M-LLM architectures that can effectively process and reason across such varied data types and time [11]. Architectures must be designed to capture complex interdependencies across different data types and temporal dimensions [32]. This often involves sophisticated alignment techniques to fuse information from disparate modalities. For instance, alignment techniques are used to associate time series data, like ECG signals, with visual representations for anomaly detection [30]. Hybrid multimodal models are emerging, where textual information (e.g., clinical reports) guides the self-supervised learning of physiological signals (e.g., ECG) to enhance zero-shot classification capabilities [12,16]. The development of "multimodal time series and text datasets," such as `WildfireSpreadTS` and `FOCAL`, is crucial for training and evaluating these complex models [27,31]. The overarching goal is to achieve "general time series analysis intelligence" by extending LLM capabilities to adapt and process "more data modes," including graphs, audio, and tables, ultimately enabling more robust and comprehensive temporal reasoning [2]. Projects like "InstructTime: Advancing Time Series Classification with Multimodal Language Modeling" underscore this research direction [33].
## 6. LLM Adaptation Strategies and Architectures
The application of Large Language Models (LLMs) to time series analysis presents a significant challenge due to the fundamental modality gap between text-centric pre-training and the continuous, numerical nature of time series data. Addressing this requires a diverse array of adaptation strategies and architectural innovations, which can be broadly categorized into methods that minimally alter the LLM backbone, those that selectively fine-tune its parameters, and approaches that deeply integrate or orchestrate external tools and specialized models [2,31]. This section critically evaluates these integration strategies, comparing "reprogramming" approaches that adapt inputs and outputs while keeping LLM backbones frozen with strategies involving fine-tuning or adapter layers. It also analyzes the efficacy of prompt engineering techniques, discusses the implications of context lengths, and examines the architectural principles driving the shift towards native continuous-value processing in time series foundation models.

A primary direction involves **Architectural Adjustments and Innovations**, where the core LLM architecture, often based on Transformers, is modified to better suit time series data. This encompasses a crucial shift from reliance on discrete tokenization, inherent to natural language processing, towards architectures capable of native continuous-value processing [29]. Key adaptations include specialized encoding strategies such as patching, which segments time series into meaningful units to manage context length and preserve local semantics [25], and various normalization techniques like Instance Normalization and Reversible Instance Normalization (RevIN) to address non-stationarity and scaling issues [14,25]. Advanced temporal and positional encodings, such as Rotary Position Embeddings (RoPE), are also critical for capturing complex temporal dependencies and channel distinctions in multivariate series [14,29]. Furthermore, efficiency enhancements like Token Merging, FlashAttention, and KV Cache are integrated to handle long time series sequences more effectively [29,35]. This architectural specialization is epitomized by models like TimeGPT and Sundial, which are designed as native time series foundation models from the ground up, rather than adaptations of text LLMs [3,29].

Conversely, **Reprogramming and Prompt-based Approaches** focus on adapting time series data to fit the LLM's language-centric input format, generally without modifying the frozen LLM backbone [1,4]. Reprogramming frameworks, exemplified by Time-LLM, CALF, and LLaTA, transform numerical time series into a representation compatible with the LLM's embedding space, often via patching and attention mechanisms [1,15]. Prompt engineering techniques, such as direct prompting, PromptCast, TEMPO, TEST, and PatchInstruct, reframe time series tasks as natural language problems, allowing the LLM to leverage its pre-trained linguistic understanding [14,24]. A specific technique, "Prompt-as-Prefix" (PaP) [1], plays a critical role in guiding the LLM's internal mechanisms for time series processing by enriching the input context. However, critical evaluation of these methods reveals limitations; for instance, LLMs have shown limited benefit from explicit Chain-of-Thought (CoT) reasoning prompts in time series anomaly detection, suggesting that deeper reasoning mechanisms are not always effectively activated [17]. Moreover, performance degradation with increasing context lengths highlights a persistent challenge in handling extensive time series data [17].

**Fine-Tuning and Parameter-Efficient Fine-Tuning (PEFT)** represent another critical strategy, involving the selective adjustment of LLM parameters to specialize them for time series tasks. Multi-stage fine-tuning, as seen in LLM4TS, progressively aligns the LLM with time series characteristics, balancing general knowledge transfer with domain-specific adaptation [25]. Given the large parameter count of modern LLMs, PEFT techniques like LoRA and Layer Normalization Tuning are crucial for efficient adaptation, minimizing computational costs and mitigating catastrophic forgetting by updating only a small subset of parameters [4,25]. While fine-tuning is widely used, research continues to explore whether the benefits of an LLM's pre-trained linguistic knowledge truly outweigh a "random initialization + fine-tuning" approach for time series, suggesting that direct alignment to time-series patterns during fine-tuning may be more crucial [9,15]. In-context learning (ICL) offers an alternative, enabling rapid, few-shot adaptation without parameter updates, particularly useful for scenarios with limited labeled data or rapidly changing requirements [5,35].

Finally, **Tool Integration and Hybrid Models** leverage LLMs as intelligent orchestrators, allowing them to perform high-level task planning and execution while offloading precise numerical computations to specialized time series algorithms and external libraries [30]. This paradigm, exemplified by systems like ToolLLM, Auto-TTE, and TrafficGPT, utilizes LLMs to generate code or API calls, thereby enhancing interpretability and system capability by coordinating existing, optimized tools [2,30]. Hybrid models further combine LLMs' symbolic reasoning with the quantitative processing of specialized time series models, integrating diverse data types and modalities for more robust analyses. Examples include METS, ChatTime, and the Hybrid Multi-Modal Forecaster (Hybrid-MMF), which aim to bridge the semantic gap between linguistic and numerical data through shared embeddings or adaptive representations [14,34].

In summary, LLM adaptation for time series is a rapidly evolving field, balancing the preservation of LLMs' robust pre-trained knowledge with the necessity for domain-specific specialization. The effectiveness of these strategies hinges on successfully bridging the modality gap, managing computational complexity, and ensuring that the inherent reasoning capabilities of LLMs are genuinely activated for complex temporal tasks. Ongoing research continues to navigate these trade-offs, driving the development of increasingly sophisticated and efficient LLM-based solutions for time series analysis.
### 6.1 Architectural Adjustments and Innovations
LLM-based models for time series analysis necessitate specific architectural adjustments to effectively address the unique characteristics of time series data, such as continuous values, complex multi-variate correlations, and inherent non-stationarity. These modifications aim to bridge the gap between language-centric LLM architectures and the distinct nature of sequential numerical data, leading to a landscape of specialized designs and innovative data processing techniques.

While some methods primarily focus on external data preprocessing to align time series with existing LLM inputs [1,5,18], a growing body of research introduces substantial architectural innovations to the Transformer and LLM frameworks for enhanced time series processing. For instance, **LLM4TS** fundamentally replaces the original text token encoding layer with a one-dimensional convolutional layer ($\text{Conv}_{token}$) to process patched time-series data, explicitly chosen for its efficacy in preserving local semantic information [25]. It also incorporates a novel two-level temporal encoding layer that aggregates diverse temporal attributes (e.g., seconds, hours, holidays) via trainable lookup tables, effectively capturing multi-scale temporal dynamics. The final input embedding $e$ to the Transformer blocks is the sum of these three embeddings: $e = e_{token} + e_{pos} + e_{temp}$ [25]. Similarly, **Sundial** enhances the Transformer backbone with Pre-Layer Normalization (Pre-LN) for training stability and employs Rotary Position Embeddings (RoPE) within a causal self-attention mechanism to inject crucial positional information for patch tokens, facilitating the capture of temporal dependencies [29]. RoPE is also utilized in **Moirai** for distinguishing between different channels and temporal positions with both time ID and variate ID embeddings [14].

Other notable architectural transformations include **iTransformer**, which re-designs the Transformer by inverting the attention mechanism and feed-forward network, leveraging attention to capture multivariate correlations across variable tokens [27,28]. **TimeGPT** adopts a full encoder-decoder Transformer architecture, where the encoder's attention mechanism is specifically designed to learn distinct attributes from time series inputs [3]. For multi-modal scenarios, the **Hybrid Multi-Modal Forecaster (Hybrid-MMF)** integrates a multihead MLP module with an LLM (Llama 3.1 8B). Input time series ($\mathbf{X}_{time}\in\mathbb{R}^{I\times C}$) and tokenized text ($\mathbf{X}_{text}\in\mathbb{R}^{I\times N}$) are processed, with numerical inputs projected into the textual embedding space. These are then concatenated into $\mathbf{X}_{concat}\in\mathbb{R}^{I\times(C+H)}$, allowing the LLM to apply attention mechanisms across both modalities to model temporal dependencies [34]. Advanced architectures like **Time-MoE** and **TimeMixer++** adopt Mixture of Experts (MoE) principles for scalability and generalized predictive analysis across diverse tasks, reflecting a key LLM scaling strategy applied to time series [11,21,35]. Further specialized models such as **TimeKAN** (Kolmogorov-Arnold Networks with frequency decomposition) and **FLDmamba** (Fourier and Laplace Transform Decomposition within Mamba) represent architectural diversification to model non-linear relationships and enhance prediction capabilities for time series [21]. Multimodal LLMs are also exploring "time attention" mechanisms or "dynamic time graph networks" to infer complex lag relationships in time series data [32].

A critical aspect of adapting LLMs for time series involves specialized tokenization and encoding strategies, which directly address the continuous nature and sequential dependencies of time series data [9].

1.  **Patching**: This technique involves segmenting time series into contiguous segments or "patches," effectively treating them as tokens for Transformer-based models.
    *   **Rationale**: Patching is instrumental in managing the long context windows inherent in time series, significantly reducing the Transformer's quadratic time and space complexity by converting a long sequence of individual time steps into a shorter sequence of patches [25]. It also helps preserve local semantic information within each segment [25] and aligns time series data with architectures typically handling segmented inputs [35].
    *   **Effectiveness**: Studies indicate that patching is a crucial encoding technique, with basic attention or Transformer modules combined with patching often outperforming full LLMs in efficiency and sometimes performance [4,8,15]. Implementations include fixed-length patches used in **Timer**, arbitrary-length patches in **Sundial**, and multi-scale patching (e.g., patch sizes of 8, 16, 32, 64, 128) in **Moirai** to accommodate different frequencies [14,29]. Channel-independent patching further enhances multivariate time series processing [25].

2.  **Normalization**: This technique addresses the non-stationarity and varying scales common in time series.
    *   **Rationale**: Normalization mitigates distribution shifts and outlier impacts, which are pervasive in time series data, ensuring stable model training and robust predictions [25,29].
    *   **Effectiveness**: **Instance Normalization (IN)** and particularly **Reversible Instance Normalization (RevIN)** are widely adopted. RevIN is notable for its ability to perform denormalization with a trainable affine transformation, crucial for accurate forecasting and handling distribution shifts [14,25].

3.  **Temporal and Positional Encoding**: These mechanisms are designed to capture the inherent temporal order and multi-scale temporal information.
    *   **Rationale**: Unlike natural language, where word order conveys grammatical meaning, time series relies on precise temporal positioning and multi-frequency patterns.
    *   **Effectiveness**: Beyond standard positional embeddings, **LLM4TS** introduces a novel two-level aggregation temporal encoding layer [25]. **Sundial** and **Moirai** leverage **Rotary Position Embeddings (RoPE)** to inject detailed positional information for patches and distinguish between different channels and time IDs, crucial for understanding complex temporal dependencies [14,29]. The fine-tuning of positional encodings within pre-trained LLMs also contributes to better suitability for time series data [15].

4.  **Discrete Tokenization / Quantization**:
    *   **Rationale**: Directly converts continuous numerical time series into discrete tokens, making them consumable by LLMs originally trained on discrete language tokens. This allows leveraging pre-trained LLM knowledge without modifying the core LLM architecture.
    *   **Effectiveness**: **Chronos (AWS)** uses a discrete tokenization strategy to convert real-valued time series into a categorical representation [30,31]. **ChatTime** employs min-max normalization followed by discretization into 10,000 bins, adding special marker tokens to the LLM's tokenizer vocabulary [14]. **Wavelet-based Tokenization** is another specialized input processing technique for Transformer-based foundation models [35]. Conversely, **LLMTime** introduces a novel tokenization method that converts tokens into flexible continuous values to overcome limitations of traditional tokenizers for numerical data [2].

For long time series sequences, efficiency becomes a major concern. **Token Merging** strategies offer a promising solution by reducing the effective sequence length processed by attention mechanisms. Papers like "Efficient Time Series Processing for Transformers and State-Space Models through Token Merging" specifically explore this architectural innovation to accelerate time series processing in Transformer and State-State Models, directly improving efficiency for longer contexts [35]. This complements patching, which aggregates local information, by further compressing the global representation without significant loss of critical information. Additionally, the implementation of **FlashAttention** and **KV Cache** in models like **Sundial** further optimizes the computational efficiency for real-time long-context inference and long-term generation [29].

The development of LLM-based time series models inherently involves navigating a trade-off between retaining the broad generalization capabilities and pre-trained knowledge of LLMs and specializing their architectures to effectively capture time series-specific nuances [9].

*   **Retaining General LLM Capabilities**: Many approaches seek to leverage the linguistic understanding and vast knowledge base of pre-trained LLMs by keeping their core architecture largely frozen. Methods like **Time-LLM**, **LLMTime**, **Chronos**, and **ChatTime** primarily focus on adapting time series data through sophisticated external preprocessing or "reprogramming" to fit the LLM's expected input format, rather than altering the LLM's internal structure [1,5,14,30]. This strategy aims to prevent "catastrophic forgetting" and exploit the LLM's learned representations for novel tasks [2]. Similarly, techniques involving lightweight adaptive layers or Low-Rank Adapters (LoRA) like in **LLaTA** allow for fine-tuning while minimizing modifications to the frozen LLM backbone [2,4].

*   **Specializing the Architecture**: Conversely, a significant body of work suggests that deep architectural specialization is crucial for optimal time series performance. Ablation studies on various LLM-based methods have provided compelling evidence that simpler architectural components, such as combinations of patching with single-layer attention (e.g., PAttn) or basic Transformer modules (e.g., LLM2Attn, LLM2Trsf), can often achieve comparable or even superior performance to full LLMs, particularly for smaller datasets, with significantly fewer parameters [4,8,9,15]. These findings imply that the effectiveness of LLM-based time series models often stems from their specialized encoding structures (e.g., patching, attention mechanisms) and adaptations tailored for numerical sequences, rather than the intrinsic linguistic knowledge of the LLM itself [9,15]. This observation motivates the development of native time series foundation models, such as **TimeGPT-1** and **Lag-Llama**, which are architecturally innovated specifically for time series data [12]. Models like **LLM4TS** and **Sundial** exemplify this specialization by introducing dedicated convolutional layers for numerical tokens, novel temporal encoding layers, and enhanced positional embeddings directly into the Transformer architecture [25,29].

This duality highlights an ongoing research question: whether LLMs serve primarily as powerful generic backbones whose capabilities can be unlocked through careful data adaptation, or if their internal mechanisms require targeted modifications to truly excel in the domain of time series. The evidence suggests that while external data adaptations are valuable, specific architectural enhancements and simpler, specialized components often provide a more direct and efficient route to robust time series modeling.
### 6.2 Reprogramming and Prompt-based Approaches
Reprogramming and prompt-based approaches constitute a significant research direction for adapting Large Language Models (LLMs) to time series analysis, despite their inherent pre-training on natural language data [2,15]. This paradigm is centered on repurposing existing, often frozen, LLM backbones without necessitating extensive internal retraining or architectural modifications, thereby preserving the integrity of the pre-trained model while enabling its application to domain-specific time series tasks [1,2,4,8,27]. The core philosophical underpinning of prompt-based learning for time series resides in its capacity to harness the LLM's intrinsic reasoning capabilities for achieving zero-shot or few-shot learning, by reframing time series problems as sequence-to-sequence language tasks [2,14,30]. This contrasts with alternative methodologies, such as TimeGPT, which directly processes numerical time series data and exogenous variables [3], or LLM4TS, which employs structural adaptations and fine-tuning rather than relying on explicit prompt engineering or reprogramming in the typical sense [25].

**Reprogramming Frameworks.** Reprogramming frameworks primarily focus on aligning numerical time series data with the LLM's internal representation space, typically its word embeddings. **Time-LLM** is a seminal example, introducing a reprogramming framework designed to repurpose LLMs for general time series forecasting [2,19,27,28]. Time-LLM tokenizes input time series through a "patching" mechanism and subsequently aligns these low-dimensional time series embeddings with the LLM's word embeddings utilizing multi-head attention [4,15]. Furthermore, descriptive statistical features are integrated to enrich the input before its submission to a frozen LLM [4,15]. In a similar vein, **CALF** treats each time series channel as an individual "word" and aligns it with LLM word embeddings via cross-attention, facilitating "text prediction" within the frozen LLM architecture [15]. **LLaTA** also aligns time series representations with language model word embeddings and incorporates a "text branch" to generate text-based predictions [4,9]. These sophisticated input transformations serve to "reprogram" the LLM's input space, effectively rendering numerical time series data comprehensible to an LLM initially pre-trained on linguistic data [4].

**Prompt-based Approaches.** Prompt-based approaches involve converting time series problems or raw numerical data into textual prompts, enabling the LLM to process them as natural language tasks. This method is instrumental in adapting LLMs for various time series tasks, including prediction, classification, and anomaly detection, by leveraging their inherent linguistic capabilities and reasoning mechanisms [2,30].
*   **Direct Prompting**: This technique treats time series data as raw text, which is then fed directly into LLMs [6,31]. This can entail carefully formatting numerical sequences for consistent interpretation (e.g., "The sales for the past five days were 1 0 5, 1 1 0, 1 1 8, 1 2 5. Predict the next value") or articulating trends and patterns in natural language, thereby allowing the LLM to infer outcomes based on its acquired patterns and common sense [30].
*   **Specific Prompting Models**:
    *   **PromptCast** introduces a learning paradigm where numerical time series inputs and outputs are translated into textual prompts, conceptualizing forecasting as a sequence-to-sequence language generation task [14,16,31].
    *   **TEMPO** employs a prompt-based generative pre-trained Transformer framework that embeds time series-specific inductive biases directly into prompts. It leverages selection-based prompts to facilitate distribution adaptation for non-stationary time series and decomposes series into their constituent trend, seasonal, and residual components [2,14,16,27,28].
    *   **TEST** utilizes text prototype aligned embeddings to activate LLM capabilities for time series tasks by tokenizing time series and constructing explicit prompts. It further employs alignment contrast and soft prompts to effectively guide frozen LLMs [2,14,16,20,27,31].
    *   **AuxMobLCast** transforms numerical time series, specifically for human mobility forecasting, into natural language sentences using meticulously designed prompts, thereby enabling the direct application of existing language models [14,16].
    *   **PatchInstruct** constructs sophisticated prompts using a multi-pronged strategy: patch-based tokenization, time series decomposition, and similarity-based neighbor augmentation. By embedding historical examples as in-context demonstrations, it guides the LLM to execute complex temporal reasoning and prediction without requiring explicit weight updates, thereby facilitating effective in-context learning [24].
    *   Other notable approaches include **Anomaly to Prompt**, which converts detected anomalies into prompts to forecast future anomalies [35], **LangTime**, a language-guided unified model that integrates natural language instructions similar to prompt engineering [35], and **VerbalTS**, which generates time series data from textual prompts or descriptions [35].
*   **Prompt-as-Prefix (PaP)**: This technique, prominently featured in Time-LLM, plays a critical role in effectively guiding the LLM's internal mechanisms for time series processing [1]. PaP involves employing text data as a dedicated prompt prefix, which serves to enrich the input context and precisely direct the transformation of reprogrammed input patches within the LLM, consequently enhancing its reasoning capabilities for time series forecasting [1,14,16,28].

**Advantages and Trade-offs.** These low-resource adaptation strategies, encompassing both reprogramming and prompt-based methods, confer significant advantages, particularly in few-shot or zero-shot learning scenarios. They harness the extensive pre-trained knowledge and reasoning capabilities of LLMs [2,14,20,30]. For instance, GPT4TS (OFA) is recognized for its robust zero-shot performance, which implicitly relies on such adaptive techniques [10]. This approach mitigates the necessity for extensive domain-specific fine-tuning, which can be both computationally intensive and data-demanding.

However, the overall effectiveness and inherent trade-offs of these approaches remain subjects of ongoing empirical investigation. While the overarching objective is to activate the LLM's "built-in reasoning capabilities" for time series tasks [32], several studies indicate that these reprogramming efforts do not consistently yield significant performance gains that are commensurate with their associated computational costs [8]. Furthermore, specific analyses, such as those investigating Chain-of-Thought (CoT) reasoning prompts for time series anomaly detection, suggest that LLMs do not consistently exhibit enhanced performance even when provided with explicit step-by-step reasoning prompts [17]. A critical limitation observed is the degradation of LLM performance when the input time series contains a higher number of tokens, underscoring a persistent long context window bias that requires methodical addressing [17]. Crucially, some findings contend that despite elaborate input transformations, these methods may not effectively activate the LLM's deeper reasoning mechanisms specifically for time series forecasting [9].

**Synthesis.** Synthesizing these diverse reprogramming and prompt-based approaches reveals a common underlying strategy: bridging the modality gap between numerical time series data and natural language. Reprogramming frameworks, exemplified by Time-LLM, CALF, and LLaTA, achieve this primarily by transforming raw time series into a format compatible with LLM word embeddings, effectively "language-ifying" the numerical input. Prompt-based methods, as demonstrated by PromptCast, TEMPO, TEST, and PatchInstruct, advance this by explicitly structuring time series tasks or data into natural language prompts, leveraging the LLM's sophisticated text processing and generation capabilities. The technique of Prompt-as-Prefix (PaP) further refines this by providing critical contextual guidance to the LLM's internal processing. The primary trade-off inherent in these strategies lies in the delicate balance between preserving the expansive generic linguistic knowledge of a frozen LLM and achieving sufficiently high domain-specific performance for complex time series tasks. While these methods show promise for low-resource scenarios and facilitating zero-shot or few-shot learning, their ultimate ability to fully unlock and effectively utilize the LLM's deep reasoning for time series remains an active and crucial area of investigation, with some existing studies highlighting performance limitations and potential computational inefficiencies [16].
### 6.3 Fine-Tuning and Parameter-Efficient Fine-Tuning (PEFT)
Fine-tuning serves as a pivotal strategy for adapting large language models (LLMs) from their general-purpose pre-training to specific time-series tasks, encompassing forecasting, analysis, and anomaly detection [10,26]. This adaptation allows LLMs to leverage their extensive learned representations while specializing in the unique patterns and nuances of temporal data [26].

A prominent approach in this domain is multi-stage fine-tuning, designed to progressively align the LLM with time-series characteristics and task-specific requirements. A notable example is the two-stage fine-tuning process employed by LLM4TS [23,25]. The first stage, termed "Time-Series Alignment," involves supervised fine-tuning using an autoregressive objective, mirroring the LLM's original pre-training. This stage's primary objective is to orient the LLM towards time-series data, enabling it to recognize inherent temporal patterns and nuances [25]. Following this, the second stage, "Forecasting Fine-Tuning," transfers the model's weights from the initial stage and further fine-tunes them for specific time-series forecasting tasks. This stage often incorporates advanced strategies such as linear probing followed by full fine-tuning (LP-FT), which has demonstrated superior performance compared to either method alone, enhancing both out-of-distribution (OOD) efficacy and in-distribution (ID) accuracy, particularly in few-shot learning scenarios with an average MSE improvement of 2.51% [25]. This structured, multi-stage approach offers benefits in terms of improved stability and performance by gradually refining the model's focus, contrasting with single-stage fine-tuning which might struggle to balance general knowledge transfer with domain-specific adaptation [32]. Other works, such as TimeGPT, also utilize a two-stage process involving initial pre-training on diverse time series datasets followed by fine-tuning on specific, often scarce, historical data to adapt to particular load forecasting tasks [22].

Given the colossal parameter counts of modern LLMs, full fine-tuning is often computationally prohibitive and prone to "catastrophic forgetting," where the model loses its general capabilities learned during pre-training [2]. To circumvent these challenges, Parameter-Efficient Fine-Tuning (PEFT) techniques have become indispensable. PEFT methods enable the efficient adaptation of LLMs to time series data while largely preserving their robust general capabilities. LLM4TS, for instance, extensively utilizes PEFT by keeping most parameters fixed, especially within the multi-head attention and feed-forward layers of the Transformer, which are critical for data-independent representation learning [25]. Instead, it selectively updates a minimal subset of parameters, specifically applying Layer Normalization Tuning to the affine transformation parameters within layer normalization components and Low-Rank Adaptation (LoRA) to the query (Q) and key (K) matrices in the self-attention mechanism [25]. Through these targeted modifications, LLM4TS updates only 1.5% of the LLM's total parameters, achieving significant efficiency without compromising adaptability [25]. Other methods, such as LLaTA, also employ LoRA to fine-tune the LLM while freezing the base model, introducing lightweight adaptive layers to mitigate catastrophic forgetting and computational overhead [4,9]. Similarly, ChatTime leverages LoRA for both continuous pre-training and instruction fine-tuning on a 4-bit quantized Llama-2-7B model to reduce training costs while retaining text reasoning abilities [14], and multimodal prediction models use LoRA to fine-tune large models like unsloth/Meta-Llama-3.1-8B-Instruct, significantly reducing memory and computational costs [34].

However, the efficacy of fine-tuning pre-trained LLMs for time series tasks is a subject of ongoing research and debate. Several studies indicate that the benefits derived from an LLM's pre-trained language knowledge might be limited for time series prediction. Comparative experiments, for instance, have shown that a "random initialization + fine-tuning" approach can often outperform "pre-training + fine-tuning" for time series tasks [9,15]. This suggests that fine-tuning an LLM with randomly initialized weights specifically for time series data can sometimes be more effective than relying on pre-trained text knowledge, implying that direct alignment to time-series patterns during fine-tuning may be more crucial than the initial linguistic understanding [8].

An alternative to traditional fine-tuning is in-context learning (ICL), particularly relevant for rapidly adapting foundation models to novel time series problems. In-context learning in the time series domain refers to the ability of an LLM to learn new tasks from a few examples provided directly within the prompt, without any parameter updates or dedicated fine-tuning [35]. This contrasts sharply with traditional fine-tuning, which involves explicit gradient updates to the model's weights. ICL allows for "few-shot adjustments" where LLMs can connect physiological and behavioral time series data with text for meaningful inferences in health tasks with minimal adjustment [14,16]. For example, "Large Language Models are Few-Shot Health Learners" demonstrates this capability [14]. Approaches like LLMTime are explicitly designed for "zero-shot time series forecasting," operating without any training on the target dataset, relying solely on prompt engineering for task adaptation [5]. Similarly, PatchInstruct enables time series forecasting without extensive retraining or heavy fine-tuning by strategically formatting input and employing prompt engineering, reducing computational demands [24]. Other studies also evaluate LLMs in zero-shot and few-shot learning scenarios for tasks like anomaly detection, using them in their pre-trained, off-the-shelf capacity [17,18]. While traditional fine-tuning (including PEFT) updates the model's parameters to permanently adapt to new data, ICL enables rapid, on-the-fly adaptation using provided examples, making it highly flexible for scenarios with limited labeled data or rapidly changing requirements. The "In-Context Fine-Tuning for Time-Series Foundation Models" approach directly explores these principles to adapt LLMs with reduced labeled data or computational effort [35].
### 6.4 Tool Integration and Hybrid Models
The integration of Large Language Models (LLMs) with external tools marks a significant paradigm shift in time series analysis, where LLMs primarily function as orchestrators rather than direct processors of raw numerical time series data [30]. This approach capitalizes on the LLMs' advanced reasoning and contextual understanding for higher-level task planning and execution, while leveraging established, optimized time series algorithms and specialized external libraries for precise numerical computations [30]. This strategy allows the LLM to act as an intelligent control plane, generating indirect tools such as code or API calls to interact with a suite of specialized time series processing models [6,31].

The benefits of tool integration are manifold. By offloading complex numerical operations to dedicated modules, LLMs can focus on task decomposition, goal setting, and result interpretation, enhancing the overall system's capability and interpretability. For instance, `ToolLLM` generates API calls for external time series prediction models, demonstrating how LLMs can interface with existing, highly-optimized prediction tools. Similarly, `Auto-TTE` converts time series data into LLM-executable scripts, enabling interpretable ECG classification without the LLM directly processing raw signals [30]. Other notable tool-integrated systems include `CTG++`, `SHARE`, `GG-LLM`, and `SCRL-LG` which exemplify this hybrid control mechanism [31]. Beyond direct prediction, LLMs can be integrated with knowledge bases and search engines for financial decision-making, as seen in `WeaverBird`, further extending their utility as intelligent system coordinators [7]. The concept extends to agent-based systems, where LLMs serve as intelligent agents coordinating or processing multimodal data. Examples include `SocioDojo`, which builds analytical agents with real-world text and time series data, and frameworks like `Agentic Retrieval-Augmented Generation for Time Series Analysis`, `Argos` for anomaly detection, and `FinArena` for financial market analysis, all illustrating LLMs as orchestrators in complex time series problems [11,27]. `TrafficGPT` further exemplifies this by integrating traffic models with LLMs to provide user-tailored solutions and detailed insights, enhancing system interpretability through the LLM's reasoning capabilities [2].

Beyond tool orchestration, hybrid models represent another critical avenue, aiming to combine the symbolic reasoning and contextual understanding of LLMs with the quantitative processing and pattern recognition capabilities of traditional or specialized time series models [14]. These models often focus on integrating diverse data types and modalities, seeking to achieve more comprehensive and robust analyses. In financial forecasting, hybrid approaches leverage LLMs' knowledge to integrate multimodal signals, thereby enhancing interpretability and addressing challenges like cross-series inference [14]. The `METS` framework, for example, combines ECG signals with automatically generated clinical reports, utilizing a frozen language model to assist ECG self-supervised learning pre-training, effectively integrating linguistic knowledge to improve time series-specific tasks [14,16]. `ChatTime` conceptualizes time series as a "foreign language" to be processed alongside text, enabling zero-shot prediction and supporting both time series and text as input and output, thereby integrating LLM text processing with time series numerical reasoning [14].

Other notable hybrid architectures include the "Modality-aware Transformer," which integrates categorical text and numerical time series using various attention mechanisms, and `UniTime`, a language-empowered unified model for cross-domain time series forecasting that aligns modalities through domain descriptions and a language-TS transformer [28]. `Time-LLM` exemplifies a hybrid approach by clustering numerical data and reprogramming time series into textual representations, allowing for flexible switching between categorical and raw representations to optimize for both adaptability and numerical integrity within the LLM architecture [30]. A recent advancement, the `Hybrid Multi-Modal Forecaster (Hybrid-MMF)`, is designed for jointly forecasting both text and time series data. It employs a multihead MLP module for initial processing of concatenated time series and text embeddings, which are then fed into an LLM (e.g., Llama 3.1 8B) for end-to-end training. A key innovation of `Hybrid-MMF` is its focus on shared embeddings, projecting numerical inputs into the textual embedding space of the LLM to bridge modalities and leverage the LLM's capabilities for both textual and numerical prediction, in contrast to earlier models like `MM-TSFlib` that rely on frozen textual embeddings [34].

The complexities of effectively integrating diverse data types and ensuring coherent learning and inference across these modalities remain a significant challenge. Hybrid models must address issues such as varying data characteristics, differing convergence speeds across domains, and the semantic gap between symbolic linguistic representations and quantitative numerical sequences [28]. Solutions often involve sophisticated architectural designs, such as `Hybrid-MMF`'s shared embedding space, or `Time-LLM`'s adaptive representation switching, which aim to maintain numerical integrity while harnessing the contextual depth of LLMs [30,34]. These efforts underscore the ongoing research into creating cohesive frameworks that can seamlessly combine the strengths of LLMs with the precision of specialized time series models.
## 7. Time Series Foundation Models: LLM-Inspired and Native Architectures
The landscape of time series analysis is undergoing a significant transformation, driven by the emergence of foundation models that draw inspiration from or are purpose-built in the paradigm of Large Language Models (LLMs). This evolution signifies a concerted effort to move towards a "general time series analysis intelligence" [2], aiming for models with universal capabilities, including zero-shot inference and robust out-of-distribution (OOD) generalization across diverse temporal datasets [14]. This section distinguishes between two primary categories: **purpose-built time series foundation models (TSFMs)**, inherently designed for temporal data, and **LLM-inspired architectures or general-purpose LLMs adapted for time series**, which leverage principles or pre-trained weights from their linguistic counterparts.

**Purpose-built Time Series Foundation Models** like TimeGPT-1, Sundial, and Chronos represent a new paradigm, embedding time-series-specific inductive biases directly into their core design [2,14]. **TimeGPT** is frequently cited as the "first foundation model for time series" [3,16], conceived as a generative pre-trained Transformer model specifically engineered for forecasting. Its architecture features a full encoder-decoder Transformer designed to natively handle time series data and integrate exogenous variables [3,26]. **Chronos** similarly aims to "learn the language of time series" by optimizing LLM architectures for temporal data [19,30], employing a discrete tokenization strategy using VQ-VAE to convert real-valued time series into categorical representations for Transformer processing [30]. **Sundial** is introduced as a "native, flexible, and scalable time series foundation model family" [29], which directly operates on continuous-valued time series, integrating time-series-aware components such as "Re-Normalization" and "Patch Embedding" within an enhanced Transformer backbone [29]. Other notable native TSFMs include Lag-Llama for probabilistic forecasting [14,16], MOMENT, Timer, and Moirai, which further exemplify specialized architectures for diverse time series tasks [14]. Domain-specific models like ClimaX, GraphCast, and FourCastNet for weather and climate forecasting also leverage spatio-temporal inductive biases, indicating a broader trend towards specialized foundation models [7]. These models are pre-trained on vast, diverse time series datasets—TimeGPT on 100 billion data points [3], Sundial on "TimeBench" with one trillion time points [29], and Timer and Moirai on UTSD and LOTSA respectively, comprising billions of observations [14]. This extensive pre-training, often involving masked modeling or autoregressive objectives, enables them to achieve superior zero-shot and OOD generalization capabilities, often outperforming traditional methods [14,16].

In parallel, **LLM-inspired architectures and hybrid foundation models** aim to adapt the core principles of LLMs for time series analysis, particularly their scalability, generalization, and robust representation learning capabilities [2]. These approaches frequently leverage the **Transformer architecture** and its self-attention mechanisms, which are foundational to LLMs. For instance, while TimeGPT and Sundial are native TSFMs, their underlying Transformer backbones draw direct inspiration from LLMs [3,29]. To bridge the gap between continuous numerical time series and LLM-compatible formats, innovative **data transformation and tokenization strategies** are employed. Chronos's discrete tokenization [30], LLMTime's transformation into flexible continuous values [2], and Time-LLM's reprogramming of time series into text prototypes [2] are prime examples. Methods like ChatTime treat time series as a "foreign language" requiring specific preprocessing to adapt pre-trained LLMs without fundamental architectural changes [14]. The **pre-training and transfer learning paradigms** from LLMs are also extensively adopted, with models like OFA (One Fits All) and UniTime leveraging pre-trained language models or cross-domain pre-training to mitigate data scarcity and achieve transferability [12,27], [28,33]. Furthermore, **fine-tuning and parameter-efficient fine-tuning (PEFT) techniques**, such as those in LLM4TS, are used to adapt pre-trained LLMs for time series tasks, benefiting from their existing knowledge bases [23,25]. The Mixture of Experts (MoE) architecture, prevalent in large language models, is also being explored in models like Time-MoE for scalable time series forecasting [11]. While these LLM-inspired designs offer potential for scalability and generalization, critical analysis suggests that performance gains often stem from specific encoding structures rather than the direct transfer of linguistic knowledge from LLM backbones to purely numerical time series forecasting [15].

The **pre-training objectives and data scales** are paramount for both categories, mirroring their critical role in the success of LLMs. Masked modeling strategies, analogous to masked language modeling in NLP, are common, seen in Moment's masked reconstruction and Moirai's masked token reconstruction [14]. Autoregressive objectives, akin to next-token prediction, are also widely used, with Timer employing a patch-level autoregressive approach and LLM4TS integrating it for time-series alignment [14,25]. The sheer scale and diversity of pre-training data are crucial, as exemplified by TimeGPT's 100 billion data points across domains [3], Timer's 1 billion time points in UTSD, and Moirai's 27 billion observations in LOTSA [14]. However, a significant challenge remains the relative scarcity of truly large-scale, diverse, and high-quality time series data compared to text corpora, necessitating strategies like knowledge transfer from pre-trained LLMs (as in LLM4TS) or the development of curated, unified datasets like Time-series Pile [14,23].

The long-term vision aims for achieving 'general time series analysis intelligence' [2]. This ambition extends to conceptual frameworks that unify time series reasoning with Multimodal Large Language Models (MLLMs), proposing new paradigms for handling diverse data types and complex reasoning tasks, even as concrete implementations are still emerging [32]. The ongoing research in architectural innovations, such as time attention or dynamic time graph networks, further seeks to adapt LLM principles effectively for time series, especially in multimodal contexts [32]. Overall, both native and LLM-inspired approaches contribute significantly to advancing time series forecasting and analysis, each with unique advantages and design philosophies, collectively pushing the boundaries towards more generalized and efficient temporal intelligence.
### 7.1 Native Time Series Foundation Models (e.g., TimeGPT, Chronos)
The emergence of native time series foundation models (TSFMs) represents a significant paradigm shift in time series analysis, moving beyond the adaptation of general-purpose Large Language Models (LLMs) to developing architectures inherently designed for temporal data. These models address the fundamental limitations of applying LLMs, which are typically pre-trained on text, to numerical, sequential, and often probabilistic time series, by embedding time-series-specific inductive biases into their core design [2,14].

Several prominent TSFMs have been introduced, each with distinct architectural and pre-training strategies. **TimeGPT** is frequently cited as the "first foundation model for time series" [3,12,14,16], conceived as a comprehensive generative pre-trained Transformer model specifically for forecasting tasks [3]. Its architecture features a full encoder-decoder Transformer, engineered to natively handle time series data and integrate exogenous variables effectively [3]. Similarly, **Chronos** is designed to optimize LLM architectures for time series, aiming to "learn the language of time series" [19,30].

The design principles of these native TSFMs deliberately incorporate time-series-specific inductive biases. For instance, Chronos employs a discrete tokenization strategy, utilizing VQ-VAE to convert real-valued time series into categorical representations [30]. This approach allows existing Transformer-based LLMs to process time series data without fundamental architectural changes, effectively reducing the number of unique tokens and improving prediction consistency by treating time series as a sequence of learned discrete concepts [30]. **Sundial**, described as a "native, flexible, and scalable time series foundation model family" [29], implements several time-series-aware components: "Re-Normalization" to manage time distribution shifts and outlier ranges, and "Patch Embedding" to segment arbitrary-length time series into continuous patches [29]. Its enhanced Transformer backbone integrates "Pre-LN" for pre-training stability, "RoPE" for positional information in causal self-attention, "FlashAttention" for accelerated deployment, and "KV Cache" for faster inference, all contributing to efficient and stable processing of temporal sequences [29].

Other notable TSFMs include **Lag-Llama**, a general univariate probabilistic time series forecasting model [12,14,16], and **TimeMixer++**, presented as a "General Time Series Pattern Machine for Universal Predictive Analysis" capable of state-of-the-art performance across diverse analytical tasks [21]. More recent models like **MOMENT** (Transformer encoder), **Timer** (Transformer decoder), and **Moirai** (Transformer-based for probabilistic forecasting) further exemplify specialized architectures [14]. Certain models also focus on specific domains, such as **ClimaX**, **GraphCast**, and **FourCastNet** for weather and climate forecasting, leveraging spatio-temporal inductive biases [7,27]. The notion of "Enhancing Foundation Models for Time Series Forecasting via Wavelet-based Tokenization" also indicates the integration of domain-specific signal processing techniques [35].

The pre-training strategies for these TSFMs are characterized by vast datasets and time-series-centric objectives. TimeGPT, for instance, is pre-trained on an extensive collection of 100 billion data points spanning diverse domains like finance, transportation, web traffic, and healthcare, equipping it with broad generalization capabilities [22]. Sundial utilizes "TimeBench," a curated dataset of "one trillion time points" comprising both real-world and synthetic data, with a primary objective to predict the distribution of the next patch using "TimeFlow Loss" (a flow-matching framework), enabling probabilistic forecasting without explicit prior distributions [29]. MOMENT is pre-trained on "Time-series Pile," a large, diverse dataset combining various time series tasks with a masked reconstruction objective [14]. Timer employs an autoregressive pre-training on the "Unified Time Series Dataset (UTSD)," containing 1 billion time points from 7 domains, while Moirai is pre-trained on "LOTSA," a dataset with 27 billion observations from 9 domains, to predict mixed distribution parameters for future values [14].

A critical evaluation of their claims for universal applicability and out-of-distribution (OOD) generalization reveals substantial empirical support. TimeGPT, Lag-Llama, and Sundial consistently demonstrate "strong zero-shot prediction capabilities on unseen 'out-of-distribution' time series datasets," often outperforming supervised baselines [12,14,16,28,29]. TimeGPT claims "superior performance, efficiency, and simplicity" in zero-shot inference against established statistical and deep learning methods [12,14,16], and Chronos similarly shows "strong capabilities in zero-shot forecasting benchmarks" [19]. Sundial achieves "state-of-the-art zero-shot performance on point and probabilistic forecasting benchmarks," with "just-in-time inference speed" for millisecond predictions [29]. TimeMixer++ also claims "state-of-the-art performance across 8 diverse analytical tasks" including forecasting, classification, anomaly detection, and imputation, indicating broad applicability [21]. These results suggest that extensive pre-training on diverse time series data, combined with tailored architectures, enables these models to effectively generalize to new and unseen time series patterns without task-specific fine-tuning.

These native TSFMs explicitly address the limitations of adapting general-purpose LLMs for time series. General LLMs struggle with the continuous, numerical, and temporal nature of time series, often losing critical semantic and statistical properties when real values are tokenized as discrete vocabulary items. Native TSFMs overcome this by:
1.  **Specialized Tokenization/Representation**: Instead of arbitrary tokenization, models like Chronos and Sundial employ structured methods (VQ-VAE, Re-Normalization, Patch Embedding) that preserve or enhance temporal and statistical characteristics [29,30].
2.  **Architectural Adaptations**: Architectures are optimized for sequential dependencies, temporal shifts, and multi-scale patterns inherent in time series, as seen in Sundial's enhanced Transformer or TimeGPT's encoder-decoder design tailored for temporal data [3,29].
3.  **Probabilistic Forecasting**: Many TSFMs, including TimeGPT (conformal prediction), Sundial (TimeFlow Loss), Lag-Llama, and Moirai, inherently support probabilistic forecasting, providing crucial uncertainty quantification often missing in text-focused LLMs [3,14,29].
4.  **Domain-Specific Pre-training**: Large-scale pre-training on diverse time series datasets (e.g., TimeBench, Time-series Pile, UTSD, LOTSA) with time-series-specific objectives allows these models to learn universal temporal patterns and dependencies that are essential for accurate forecasting and analysis, rather than relying on inductive biases derived from natural language [14,29].

In conclusion, native time series foundation models like TimeGPT, Chronos, and Sundial offer a robust alternative to adapting general LLMs by integrating time-series-specific inductive biases into their architectures and pre-training regimes. This specialized design, combined with massive time series datasets and tailored objectives, enables them to achieve superior zero-shot and out-of-distribution generalization capabilities across diverse tasks, marking a significant advancement in the field of time series analysis.
### 7.2 LLM-Inspired Architectures and Hybrid Foundation Models (e.g., adapting LLM principles, Mixture of Experts)
The success of Large Language Models (LLMs) has catalyzed significant research into adapting their core principles and architectures for time series analysis, leading to the development of LLM-inspired architectures and hybrid foundation models. These approaches aim to harness LLM strengths such as scalability, generalization, and robust representation learning to capture complex temporal dependencies across diverse time series datasets [2,22,29].

A foundational principle adapted from LLMs is the **Transformer architecture**, particularly its encoder-decoder structure and self-attention mechanisms. Models such as TimeGPT, a dedicated time series model, explicitly draw inspiration from the Transformer's design and generative pre-training paradigm to achieve foundation model-like capabilities for time series forecasting [3,22,26]. Similarly, Sundial incorporates an "enhanced Transformer" backbone, integrating advanced components like RoPE, Pre-LN, FlashAttention, and KV Cache, commonly found in modern LLMs, and adapting them for continuous-valued time series [29]. Moment utilizes a Transformer encoder with masked language modeling principles, while Timer employs a Transformer decoder with an autoregressive pre-training strategy, mirroring LLM generation capabilities. Moirai adapts the Transformer for probabilistic forecasting with novel positional encodings, reflecting LLM-like architectural flexibility [14]. Numerous other Transformer-based variants also adapt this core architecture for time series challenges [27].

To bridge the gap between continuous numerical time series data and LLM-compatible formats, various **data transformation and tokenization strategies** have emerged. Chronos, for instance, employs discrete tokenization to convert time series data into a format suitable for Transformer-based processing, effectively "learning the language of time series" [19,30]. LLMTime introduces a novel tokenization scheme that transforms tokens into flexible continuous values to handle numerical data [2]. Time-LLM utilizes a hybrid approach, combining numerical clustering with reprogramming time series data into a text-like representation, allowing for flexible switching between categorical and numerical forms [2,30]. ChatTime treats time series as a "foreign language" and applies specific data transformations such as normalization, discretization, and tokenization to adapt pre-trained LLMs for time series processing without fundamental architectural changes [14].

**Pre-training and transfer learning** paradigms are also extensively adopted. Models like OFA (One Fits All) leverage pre-trained language or image models to perform general time series analysis, using their learned representations to mitigate data scarcity [10,12,27]. UniTime, a language-empowered unified model, aims for cross-domain pre-training to achieve transferability and adaptability across varying data characteristics, drawing inspiration from unified models in NLP and computer vision [28,33]. The concept of "zero-shot time series forecasting" by LLMs also stems from adapting these pre-training principles [5,27].

For efficient adaptation, **fine-tuning and parameter-efficient fine-tuning (PEFT) techniques** have been integrated. LLM4TS, an LLM-inspired architecture, adapts pre-trained LLMs for time series forecasting through a two-stage fine-tuning process and PEFT methods like LoRA. This allows it to benefit from knowledge transferred from the pre-trained LLM, making it a robust representation learner and effective few-shot learner [13,23,25]. Other models like Time-LLM, TEST, and TEMPO demonstrate the application of LLM principles such as prompt engineering and reprogramming into language space, creating hybrid systems that combine LLM strengths with time series data handling [2]. PatchInstruct similarly employs prompt-based learning and in-context learning through similarity-based neighbor augmentation to adapt LLMs for forecasting without requiring internal architectural modifications, leveraging specialized preprocessing techniques like decomposition and patch-based tokenization [24].

The **Mixture of Experts (MoE) architecture**, a principle gaining significant traction in large language models for handling diverse tasks and scaling efficiently, is also being applied to time series. Time-MoE explicitly leverages the MoE paradigm to build billion-scale foundation models tailored for time series forecasting, showcasing its potential to manage diverse patterns and scale effectively [11,21,35].

A notable benefit of these LLM-inspired designs is their potential for **scalability, generalization, and robust performance** across various time series datasets. Sundial aims for "unprecedented model capacity and generalization performance" and "transferability across agnostic downstream datasets," aligning with the goals of LLM-like foundation models [29]. When processing multi-modal data, the Hybrid Multi-Modal Forecaster (Hybrid-MMF) leverages a state-of-the-art pre-trained language model (Llama 3.1 8B) for processing textual inputs and projecting numerical inputs into its embedding space, enabling joint forecasting of time series and textual data through shared embeddings and cross-modal attention mechanisms [34].

However, the efficacy of directly transferring LLM principles to pure numerical time series tasks presents challenges. A critical analysis of models like OneFitsAll (GPT4TS), Time-LLM, and CALF suggests that observed performance gains are often more attributable to specific encoding structures, such as patching and single-layer attention, rather than the pre-trained linguistic knowledge embedded within the LLM backbone itself [15]. This indicates that while the architectural components (e.g., Transformers) are highly beneficial for time series, the direct semantic knowledge from natural language pre-training may not always transfer effectively to purely numerical time series forecasting. Despite this, the ambition for models like "TimeMixer++" as a "General Time Series Pattern Machine" and TSMixer as a modular building block compatible with supervised and self-supervised learning methods still aligns with the LLM philosophy of building versatile foundation models [21,28]. The research area continues to explore "architectural innovations" like "time attention or dynamic time graph networks" to better adapt LLM principles for time series reasoning, especially in multi-modal contexts [32]. Overall, LLM-inspired architectures and hybrid foundation models represent a promising direction, leveraging powerful sequence modeling capabilities while continuously refining data representation and knowledge transfer strategies for time series specificity.
### 7.3 Pre-training Objectives and Data Scales
The development of Large Language Models (LLMs) for time series analysis critically hinges on carefully designed pre-training objectives and the scale and diversity of the underlying datasets. Similar to the advancements in natural language processing (NLP), achieving foundation model capabilities in time series necessitates large-scale pre-training to enable models to learn robust and generalizable representations [21].

Various pre-training objectives have been explored to capture the inherent characteristics of time series data. Masked modeling strategies, analogous to masked language modeling in NLP, are prevalent. For instance, **Moment** employs masked reconstruction, where specific time series patches are masked and then reconstructed by the model [14]. Similarly, **Moirai** utilizes masked token reconstruction, specifically masking future windows for prediction and focusing on probabilistic forecasting by predicting parameters of a mixed distribution for future values [14]. **SimMTM** also details a simple framework for masked time-series modeling [7,27]. Another variant, **PT-Tuning**, proposes a pre-training objective where future values are masked and reconstructed based on historical values, designed to align with forecasting tasks by retaining pre-trained mask tokens during fine-tuning [28]. The modular design of **TSMixer** is also compatible with such masked self-supervised learning methods, indicating a broader adoption of this paradigm [28].

Autoregressive objectives constitute another significant class of pre-training strategies, drawing parallels to next-token prediction in LLMs. **Timer**, for example, is pre-trained using an autoregressive objective at the patch level [14]. **LLM4TS** integrates an autoregressive objective in its time-series alignment stage, predicting the next patch in a sequence to align the LLM with time-series data characteristics, mirroring the pre-training of models like GPT-2 on text [25]. **ChatTime** employs a continuous pre-training phase that utilizes an autoregressive prediction strategy with sliding windows of varying sizes and steps, adapting to arbitrary window lengths [14]. Beyond these, self-supervised learning approaches like those explored in **TimeDART** (a diffusion autoregressive transformer for self-supervised representation) and **TimePoint** (accelerated time series alignment via self-supervised keypoint and descriptor learning) aim to extract rich representations from unlabeled time series data, a common and effective strategy in general LLM pre-training [35]. Contrastive learning, such as "Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency," further enriches the set of self-supervised objectives [7].

The impact of these pre-training objectives on learned representations is substantial, aiming to foster robust generalization and zero-shot inference capabilities. Models like **TimeGPT** and **Lag-Llama** are designed to learn diverse temporal patterns and generalize to unseen data, achieving foundation model characteristics through extensive pre-training [3,12,16,22,28]. **TEMPO** further emphasizes the utilization of inherent inductive biases of time series tasks in its pre-training [12].

The importance of data scale and diversity for time series foundation models mirrors their critical role in the success of LLMs. Research indicates a focus on "Billion-Scale Time Series Foundation Models," with studies directly investigating neural scaling laws for time series to understand how training data volume and model size influence performance, akin to scaling research in LLMs [21]. Prominent examples include **TimeGPT**, which was trained on an extensive and diverse dataset of over 100 billion rows of time series data [3,22,26]. This dataset spans various domains such as finance, economics, weather, web traffic, energy, sales, transportation, banking, and healthcare, encompassing a multitude of temporal patterns, seasonalities, cycles, trends, noise, and outliers [3,22,26]. Similarly, **Timer** was pre-trained on the Unified Time Series Dataset (UTSD), integrating over 1 billion time points from seven domains [14], while **Moirai** utilized LOTSA, a comprehensive dataset comprising 27.6 billion observations from nine domains [14]. **Lag-Llama** is also noted for being trained on a large amount of time series data to achieve its zero-shot capabilities [12,16,28]. The emphasis on diversity ensures the model learns robust and transferable representations, crucial for zero-shot inference on unseen data [3,19]. This strategic use of vast and varied datasets draws a direct parallel to LLMs trained on "trillions of words" to acquire their comprehensive language understanding capabilities [30].

Despite these advances, curating and utilizing vast time series datasets for pre-training presents both challenges and opportunities. A significant challenge lies in the inherent scarcity of truly large-scale, diverse, and high-quality time series data compared to the readily available text corpora used for LLMs [23,25]. This scarcity motivates approaches like **LLM4TS**, which addresses the limitation by transferring knowledge from pre-trained LLMs, thus benefiting from their original pre-training on vast text corpora [23]. However, research indicates that the benefits of language model pre-training for time series forecasting are often limited, with randomly initialized models achieving superior performance after fine-tuning compared to those leveraging text-based pre-training, suggesting that text-specific pre-training objectives may not effectively transfer to numerical time series data [15]. This highlights a critical challenge in direct knowledge transfer and the necessity for time series-specific pre-training.

Opportunities arise in several areas. The development of curated, unified datasets, such as Moment's Time-series Pile, Timer's UTSD, and Moirai's LOTSA, represents a concerted effort to aggregate diverse time series data for effective pre-training [14]. Strategic data preprocessing and sampling also play a vital role. For instance, **TimeGPT** maintains data integrity through minimal preprocessing, primarily imputing missing values [3,26]. **ChatTime** employs K-means clustering to select high-quality samples, balancing computational costs with data representativeness [14], and **Moirai** utilizes varied patch sizes to accommodate different frequencies in the pre-training data, enhancing its ability to capture diverse temporal structures [14]. Furthermore, ongoing research focuses on improving synthetic data quality, which is crucial for augmenting real-world datasets and ensuring comprehensive, representative training for models like **Chronos** [19]. These efforts underscore the continuous evolution of strategies to overcome data limitations and harness the power of large-scale pre-training for time series foundation models.
## 8. Applications of LLMs in Time Series
Large Language Models (LLMs) are rapidly extending their capabilities into the domain of time series analysis, catalyzing advancements across a diverse array of real-world applications. These include critical sectors such as climate science, the Internet of Things (IoT), healthcare, traffic management, audio processing, and finance [6,30,31]. The integration of LLMs offers a novel paradigm for understanding and interacting with sequential data, often leveraging their inherent natural language processing (NLP) and generative capacities to address challenges traditionally handled by specialized statistical or machine learning models.

In **time series forecasting**, LLM-based approaches have demonstrated notable strengths, particularly in generalizing to new datasets and performing effectively in data-scarce scenarios. A significant advantage is their ability to perform zero-shot and few-shot forecasting, where models like TimeGPT-1, Chronos, LLMTime, Time-LLM, PatchInstruct, Sundial, and Lag-Llama have achieved promising or state-of-the-art results without extensive task-specific training [1,5,14,19,24,26,29]. This success is often attributed to strategies such as reprogramming or textualization, which convert numerical time series data into text-like formats to harness the LLM's language understanding, as seen in Time-LLM and LLMTime [2,11,14]. Specialized time series foundation models, including TimeGPT-1 and Sundial, are designed for universal forecasting with strong out-of-distribution capabilities [14,29]. LLMs also show promise in specific forecasting challenges like long-term forecasting, exemplified by LLM4TS, and probabilistic forecasting, where models like Sundial and Moirai generate multiple probable future distributions [14,23,29].

For **classification and anomaly detection**, LLMs leverage their pattern recognition and contextual understanding. A distinct "visual advantage" has been observed, where LLMs perform significantly better when time series data are presented as images, suggesting the efficacy of multimodal models (e.g., Vision-Language Models) in discerning irregularities [17,30]. This enables tasks such as detecting abnormal heartbeats or classifying stock market trends from charts [30]. Mechanisms include direct prompting for "common sense" reasoning to classify patterns, using learned embeddings from aligned data (e.g., METS for ECG classification), and instruction tuning for specialized applications like financial sentiment analysis (Instruct-fingpt) [12,14,30]. A significant contribution of LLMs in these tasks is the interpretability provided by natural language explanations for identified anomalies or classifications, offering qualitative insights valuable for exploratory analysis [2,30].

Beyond these core applications, LLMs are being explored for a diverse array of **other time series tasks**, indicating a shift towards more comprehensive and intelligent analytical systems. These include:
*   **Imputation**: Filling missing values using LLMs' ability to learn rich contextual representations, exemplified by models like Moment, Timer, NuwaTS, and diffusion-based methods [5,14,20,21].
*   **Generation**: Producing synthetic time series data or probabilistic future distributions, leveraging the generative nature of LLMs, often via diffusion models or specialized generative architectures like Sundial and Moirai [14,28,29]. This is crucial for addressing data scarcity and privacy concerns.
*   **Causal Inference and Explanation**: Facilitating the discovery of causal structures (e.g., Granger-causality), inferring causal factors, and generating interpretable insights, particularly in AIOps for root cause analysis and financial time series explanations [7,21,28]. LLMs can process complex dependencies and provide actionable explanations.
*   **Time Series Reasoning and Semantic Understanding**: Leveraging LLMs' NLP capabilities for complex inferences, multimodal question answering (ITFormer), and generating textual descriptions and summaries of time series data, which is particularly beneficial in domains like health and finance [2,9,16,35].

Despite these promising advancements, critical evaluation reveals several limitations. In forecasting, some studies suggest that LLM-based methods may sometimes perform comparably to or even worse than simpler ablation models, implying that the benefits might stem more from effective encoding and attention mechanisms than from the complex pre-trained LLM's reasoning capabilities [4,9]. General LLMs also face issues with numerical precision, hallucination, inconsistent output formats, and unreliable uncertainty quantification, and are sensitive to prompt wording and context window limitations in macroeconomic forecasting [18]. For anomaly detection, LLMs struggle with discerning subtle, real-world anomalies and do not consistently benefit from Chain-of-Thought prompting, while visual methods, though effective for broad trends, may lack fine-grained accuracy [17,30]. Furthermore, direct prompting often lacks the statistical probability computations inherent in traditional anomaly detection algorithms [30]. Joint multimodal forecasting, while promising, does not universally outperform established numerical prediction baselines [34].

In synthesis, LLMs are most suited for tasks requiring strong pattern recognition, contextual understanding, and the ability to operate in data-scarce or zero-shot/few-shot settings [1,25]. Their generative capabilities are invaluable for data augmentation and probabilistic forecasting, while their NLP foundation provides distinct advantages in interpretability, semantic understanding, and multimodal integration, allowing for tasks like causal explanation and time series reasoning [14,30]. However, current limitations include challenges with numerical precision, the detection of highly subtle anomalies, and the effective utilization of their complex reasoning abilities beyond basic pattern matching [9,17]. Overcoming these requires further research into designing truly multimodal and multitemporal foundation models, rigorously validating LLM benefits across a wider range of tasks, and developing methods that genuinely leverage their inherent reasoning for time series complexities [2,6,26].
### 8.1 Time Series Forecasting
Large Language Models (LLMs) are increasingly being adapted for time series forecasting, showcasing notable strengths, particularly in generalizing to new datasets and performing effectively in data-scarce scenarios, such as few-shot and zero-shot learning [1,25].

A significant advantage of LLM-based approaches lies in their ability to perform **zero-shot and few-shot forecasting**. Models like TimeGPT-1 [14,26], Chronos [19], LLMTime [5], Time-LLM [1], PatchInstruct [24], Sundial [29], and Lag-Llama [14] have demonstrated promising or state-of-the-art results in zero-shot settings, where predictions are made on unseen data without specific prior training. For instance, TimeGPT-1 can generate accurate zero-shot forecasts using only historical values, significantly enhancing efficiency and reducing computational overhead compared to traditional methods [3,26]. Similarly, Chronos exhibits "promising results in zero-shot forecasting benchmarks," offering advantages over statistical models [19]. In few-shot learning, where only limited training data is available, models like Time-LLM and LLM4TS have shown strong generalization capabilities [1,23]. LLM4TS, for example, achieved an average improvement of 6.84% in Mean Squared Error (MSE) in few-shot settings, with a variant using only 5% of training data outperforming baselines trained on 10% of data [25]. This highlights the value of pre-trained LLMs' robust representation learning capacity in data-constrained environments [25].

The competitive or superior performance of LLMs in time series forecasting can be attributed to several mechanisms. A common strategy involves **reprogramming or textualization**, where numerical time series data is converted into text-like formats or prompts to leverage the LLM's language processing capabilities [2,11,14,31,34]. Examples include Time-LLM, PromptCast, LLMTime, TEMPO, and UniTime [2,11,14]. LLMTime, for instance, introduced a tokenization method that enables un-tuned LLMs to match or exceed zero-shot prediction performance by leveraging their in-context learning capabilities to represent multimodal distributions [2]. PatchInstruct employs strategic prompt construction and in-context learning through similarity-based neighbor augmentation, integrating time series decomposition and patch-based tokenization to enhance forecasting quality [24]. Furthermore, specialized time series foundation models such as TimeGPT-1, Lag-Llama, MOMENT, and Sundial are designed for universal forecasting, demonstrating strong zero-shot and out-of-distribution capabilities often surpassing specialized models [14,29]. LLM4TS utilizes a two-stage fine-tuning strategy and a two-level aggregation method, alongside channel-independence and patching, to effectively adapt pre-trained LLMs for time series data, leading to state-of-the-art results in multivariate time series forecasting [25].

Despite these successes, a critical evaluation reveals limitations. Several studies indicate that, for time series forecasting, current LLM-based methods often perform comparably to or even worse than simpler ablation methods that remove or simplify the LLM component [4,8,9,15]. For example, ablation methods reportedly outperformed Time-LLM in 26 out of 26 cases and LLaTA in 22 out of 26 cases across various datasets and metrics [9]. These findings suggest that the perceived benefits of LLMs may sometimes stem from effective encoding techniques and basic attention mechanisms rather than the complex pre-trained LLM itself, and that the inherent reasoning capabilities of LLMs are often not effectively utilized in these forecasting applications [4,9]. Moreover, general LLMs used in macroeconomic forecasting exhibit limitations such as issues with numerical precision, hallucination, inconsistent output formats, and unreliable uncertainty quantification, highlighting their sensitivity to prompt wording and context window limitations [18]. It is also noted that traditional forecasting metrics like MSE can be misleading, as models might achieve acceptable scores without truly understanding dynamic patterns, merely by producing nearly constant outputs [17].

In the context of **joint multimodal forecasting**, integrating textual and numerical event data shows promise, yet models might not always outperform established baselines for numerical prediction, underscoring the inherent complexity of simultaneous prediction [34]. The Hybrid Multi-Modal Forecaster (Hybrid-MMF), designed to jointly forecast text and numerical data using shared embeddings, did not surpass existing baselines for numerical prediction [34]. However, the incorporation of text embeddings did enhance numerical predictions for certain models (e.g., NLinear and fine-tuned models), indicating that textual context can improve numerical pattern recognition, even if a direct, end-to-end multimodal LLM does not universally outperform numerical-only models [34]. Furthermore, some attempts at multimodal forecasting, such as ChatGPT's performance in stock movement prediction, have shown to lag behind traditional methods [7,14].

Despite these challenges, LLMs and LLM-inspired architectures show significant promise and excel in several types of forecasting problems. Notably, **long-term forecasting** is an area where LLMs demonstrate substantial capabilities. LLM4TS, for instance, has yielded state-of-the-art results in long-term time series forecasting, with experiments evaluating prediction lengths up to 720 time steps across various real-world datasets [14,23,25]. Other models also specifically target long-term forecasting, including those employing frequency domain learning or novel architectures [21,27,28]. **Probabilistic forecasting** is another emerging strength, with models like Lag-Llama, Moirai, and Sundial focusing on predicting future value distributions and generating multiple probable predictions [14,28,29]. Sundial, using an enhanced Transformer and TimeFlow Loss, achieves state-of-the-art results on probabilistic forecasting benchmarks, crucial for decision-making in intrinsically non-deterministic scenarios [29]. LLMs also show promise in specific application domains, including load forecasting (TimeGPT in data-scarce environments) [22], financial forecasting (e.g., for explainable financial time series forecasting) [2,10,14], health forecasting [2], and human mobility forecasting (AuxMobLCast) [11,14].
### 8.2 Classification and Anomaly Detection
Large Language Models (LLMs) are increasingly explored for time series classification and anomaly detection, leveraging their pattern recognition capabilities and contextual understanding. A notable finding in this domain is the "visual advantage" exhibited by LLMs in anomaly detection, where their performance significantly improves when time series data are presented as images rather than textual representations [17,30]. This suggests that multimodal LLMs, particularly Vision-Language Models (VLMs), can effectively process the visual patterns inherent in time series graphs to identify irregularities, such as detecting abnormal heartbeats from ECG signals or classifying stock market trends from charts [30].

Despite this visual strength, LLMs demonstrate specific limitations in their application to anomaly detection. They often struggle to discern subtle, real-world anomalies, and their reasoning capabilities do not benefit from explicit Chain-of-Thought (CoT) prompting for these tasks [17]. Furthermore, research indicates that LLMs' ability to identify periodic structures is not intrinsically linked to their repetitive bias, nor is their understanding directly related to their arithmetic capabilities, challenging prior assumptions about their internal mechanisms [17]. For visual methods, while effective for broad trends, fine-grained accuracy remains a challenge, rendering them less suitable for precise numerical classification or the detection of highly subtle anomalies [30]. Direct application of general-purpose LLMs without specific adaptation or contextual understanding may also yield poor performance in complex numerical tasks like stock movement prediction, highlighting the need for specialized approaches [14].

The mechanisms through which LLMs perform classification and anomaly detection vary. One approach involves leveraging "common sense" reasoning derived from natural language descriptions. Through direct prompting, LLMs can classify time series patterns, such as identifying human activities from fitness tracker data or flagging potential financial fraud by comparing current transactions to historical cases, primarily focusing on pattern recognition rather than statistical probabilities [30]. Another mechanism involves utilizing learned embeddings from aligned data. This is exemplified by the METS method, which employs a frozen language model guided by clinical reports to enable zero-shot ECG classification, thereby recognizing patterns in medical time series without extensive labeled training data [12,14]. Similarly, InstructTime advances time series classification through multimodal language modeling [11,33], and Instruct-fingpt improves financial sentiment analysis via instruction tuning of general-purpose LLMs [12]. Foundation models like Moment and Timer also demonstrate versatility in anomaly detection and classification tasks [14]. For anomaly detection specifically, methods like TimeGPT's `detect_anomalies` employ conformal prediction to establish prediction intervals, flagging observations falling outside these intervals as anomalies, allowing for adjustable sensitivity through confidence levels [3].

When comparing LLM-based approaches with traditional methods, several unique contributions emerge. A significant advantage of LLMs is the interpretability of their natural language explanations for identified anomalies and classifications [2,30]. This qualitative insight is particularly valuable for exploratory analysis, providing a deeper understanding of unusual patterns [30]. While conventional techniques offer robust statistical guarantees and fine-grained numerical precision [27,35], LLMs excel in providing contextual understanding and leveraging zero-shot or few-shot learning capabilities, especially when visual data representations are utilized [17]. However, it is crucial to note that direct prompting methods typically do not compute statistical probabilities for anomalies, a feature commonly found in traditional statistical and machine learning anomaly detection algorithms [30]. The integration of LLMs with time series analysis is an active area of research, with frameworks like LLM4TS explicitly noting classification and anomaly detection as future directions for broader applicability [25].
### 8.3 Other Time Series Tasks (Imputation, Generation, Causal Inference, etc.)
Beyond the primary applications of forecasting, classification, and anomaly detection, Large Language Models (LLMs) are increasingly being explored for a diverse array of other time series tasks, leveraging their robust representation learning and natural language processing (NLP) capabilities. This expansion signifies a novel and impactful direction in time series analysis, moving towards more comprehensive and intelligent systems [2,31]. The novelty lies in the integration of semantic understanding and generative capacities, which often go beyond the scope of traditional, purely statistical or machine learning methods.

**Imputation**, the process of filling in missing values in time series data, is a critical preliminary step for many analytical tasks. LLMs and time series foundation models demonstrate significant potential in this area. Models like Moment and Timer explicitly include imputation as a core task [14]. Similarly, NuwaTS is a dedicated time series imputation foundation model [20]. Approaches such as TimeMixer++ and methods based on optimal transport theory are also advancing time series imputation [21]. Notably, diffusion models are being adapted for imputation, as seen in LSCD for irregular time series [35]. Even models primarily focused on forecasting, like TimeGPT, incorporate imputation during data preprocessing [3], and LLMs like LLMTime can handle missing values within a zero-shot framework by treating numerical segments as text [5]. The general approach often involves leveraging LLMs' ability to learn rich contextual representations of time series, enabling more informed and coherent imputation compared to simpler statistical methods or traditional deep learning models that might lack the same level of sequence understanding.

**Generation** of synthetic time series data or probabilistic future distributions is another burgeoning area. LLMs' inherent generative nature, often manifested through transformer architectures, is a natural fit for this task. Diffusion models, such as TSDiff and a "Temporal Correlation-Empowered Diffusion Model," are prominent for synthetic data generation and refinement [28,33]. Sundial is designed as a generative model, providing multiple probable predictions and learning on continuous-valued time series [29]. Moirai, focusing on probabilistic forecasting, exemplifies generation of future distributions that account for uncertainty [14]. More directly leveraging NLP, studies explore generating time series from textual input (e.g., VerbalTS) or controlling generation via multi-agent iterative optimization and diffusion modeling (e.g., BRIDGE) [35]. The ability of LLMs to generate text from structured data implies a natural extension to generating structured time series, potentially allowing for the creation of diverse and coherent data augmentations to address issues like the "cold-start" problem [28]. This capability is particularly beneficial for data scarcity and privacy-preserving data sharing.

**Causal Inference and Explanation** are critical for understanding the underlying mechanisms of time series and for building trust in model predictions, especially in sensitive domains. LLMs contribute by facilitating the discovery of causal structures and generating interpretable insights. Research in causal discovery includes identifying Granger-causal structures across domains, as addressed by "Transferable Time-Series Forecasting under Causal Conditional Shift," and inferring causal factors with STICM to improve prediction robustness [28]. More advanced methods like "Root Cause Analysis of Anomalies in Multivariate Time Series through Granger Causal Discovery" and DyCAST focus on learning dynamic causal structures [21]. For AIOps, LLMs are applied in "Empowering Practical Root Cause Analysis by Large Language Models for Cloud Incidents" and "Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models" [7]. The distinctive benefit of LLMs here is their capacity to process and reason about complex dependencies, often expressed in natural language or requiring semantic understanding, to provide actionable explanations. For instance, "Self-Interpretable Time Series Prediction with Counterfactual Explanations" and "Temporal Data Meets LLM" focus on generating counterfactual and actionable explanations, and providing "explanation and illustration of model results" for financial time series [12,28]. LLMs can also act as orchestrators, assisting in causal inference through external libraries via a 'Tool' integration paradigm [31].

Beyond these, LLMs open avenues for **Time Series Reasoning and Semantic Understanding**. Several papers highlight the "interactive potential" between language and time series for tasks like "time series reasoning and social understanding," where the semantic capabilities of LLMs are better leveraged than in pure forecasting [9,15]. This extends to **Multimodal Question Answering (QA)**, where models like ITFormer bridge time series and natural language to answer queries [35]. LLMs can provide "text descriptions and summaries" for time series data and patterns, facilitating higher-level interpretation [2]. This capability allows for complex inferences from physiological and behavioral time series data in health domains [12,16].

The application areas are broad, spanning **Traffic and Mobility Prediction**, **Financial Market Analysis**, and **Medical Time Series Analysis** [11]. In finance, LLMs are used for sentiment analysis and stock movement prediction [11,16]. In healthcare, LLMs perform "meaningful inference on many health tasks" by connecting physiological and behavioral time series data with text [12,16]. Other specific tasks include **Event Analysis** (drafting event schemas, predicting events) [7,34], **Irregular Time Series Analysis** [21], **Action Recognition** [11], and **Time Series Alignment** [35].

The distinct contribution of LLMs in these tasks stems from their NLP capabilities, enabling them to understand diverse prompts, generate contextually relevant text (e.g., explanations, summaries, textual predictions), and integrate multimodal information where time series are combined with text, images, or structured data [32,34]. This is a significant leap beyond traditional methods, which typically operate solely on numerical data without inherent semantic understanding.

Despite the promising advancements, research gaps and opportunities remain in these nascent application areas. The full potential of LLMs for complex time series reasoning is still largely unexplored, with many experimental scopes remaining focused on prediction rather than these more intricate tasks [4,9]. Developing "general time series analysis intelligence" that encompasses a broader spectrum of tasks is an overarching goal [2]. Future research needs to focus on designing truly multimodal and multitemporal foundation models that can robustly handle the unique challenges of different time series domains [6,26], and to empirically validate the benefits of LLMs' NLP and reasoning over traditional methods for each specific task. This will require more detailed methodologies and experimental results for tasks beyond forecasting, classification, and anomaly detection.
## 9. Evaluation Landscape: Performance, Challenges, and Gaps
The evaluation of Large Language Models (LLMs) for time series analysis presents a complex and evolving landscape, characterized by both promising advancements and significant empirical limitations. Initial expectations regarding the direct transferability of linguistic knowledge have frequently met with 'startling findings' that challenge the perceived effectiveness of LLMs for standard time series forecasting [9]. This section synthesizes the actual effectiveness of LLMs, critically comparing their performance, cost, and generalization capabilities against simpler ablation counterparts and traditional methods, while also highlighting critical deficiencies in current evaluation practices and future research directions.

Many studies report instances where LLM-based models achieve state-of-the-art (SOTA) results or demonstrate competitive advantages. For example, LLM4TS has been recognized for its SOTA performance in long-term forecasting and its robust capabilities as a representation learner and few-shot learner [13,16]. Similarly, TimeGPT, Sundial, and Chronos exhibit strong zero-shot performance, often outperforming supervised baselines and traditional statistical or deep learning methods [3,16,19,26,29]. Time-LLM, through its reprogramming of time series into the language space, also claims superior performance in both few-shot and zero-shot scenarios [1,2]. PatchInstruct similarly aims to enhance LLM forecasting quality by addressing limitations of prior LLM approaches [24].

However, a substantial body of evidence reveals significant limitations when LLMs are applied to time series tasks, particularly in numerical forecasting, without specialized adaptations. Critical analyses show that simpler ablation methods, often consisting of basic architectural components without the full LLM, can significantly outperform or match full LLM-based approaches in numerical forecasting. For instance, in comparative studies, ablation counterparts have been shown to surpass models like Time-LLM, LLaTA, and OneFitsAll across multiple datasets and metrics [4,9,15]. This strongly suggests that pre-trained LLMs, in their direct application paradigms, are often ineffective for precise time series forecasting. The Hybrid-MMF model, for example, failed to consistently outperform existing baselines for numerical forecasting, underscoring the inherent challenges in multimodal time series prediction [34]. Generic LLMs, such as ChatGPT, have also demonstrated poor performance in highly precise numerical tasks like stock movement prediction, often lagging behind both SOTA methods and traditional linear regression models [14,16]. In macroeconomic forecasting, traditional models, especially Bayesian Vector Autoregression (BVAR), frequently outperform even advanced LLMs like GPT-4 across various horizons [18]. Furthermore, LLMs' reasoning capabilities in time series contexts are often weak, failing to improve anomaly detection even with explicit chain-of-thought prompts and showing degradation with increasing input sequence length [17].

A critical concern is the unfavorable performance-to-cost ratio for many LLM-based time series models. These models frequently demand substantially more computational resources—both in training time and inference speed—without delivering proportionally superior or even competitive forecasting performance. For instance, an LLM-based model with billions of parameters might require thousands of minutes to train on a dataset, whereas its ablated counterpart with significantly fewer parameters can train in mere minutes, yet achieve better performance [4,9,15]. This substantial computational overhead renders many current LLM-based approaches impractical for real-world applications where efficiency is paramount.

The empirical evidence regarding the effective transferability of pre-trained linguistic knowledge to numerical time series tasks remains largely contradictory. Numerous studies indicate that pre-trained language knowledge offers limited, if any, benefit for time series forecasting. Experiments comparing "random initialization + fine-tuning" with "pre-training + fine-tuning" often show the former performing better, suggesting that knowledge acquired from text data provides negligible assistance for time series tasks [4,9,15]. This challenge stems from the fundamental modality gap and the inherent differences between linguistic data and time series data. LLMs often struggle to represent sequential dependencies in numerical time series, as demonstrated by input shuffling experiments that similarly affect LLM-based methods and their simpler counterparts [4,9,15]. Any observed performance gains in LLM-based time series models are frequently attributed to simpler encoding techniques, such as patching or basic Transformer modules, rather than the complex capabilities of the large pre-trained language model itself [4,9,15]. Conversely, some models, like LLM4TS and Sundial, attribute their success in few-shot and zero-shot learning to effective knowledge transfer from pre-trained models, with larger models consistently achieving better performance [13,29]. This highlights that the utility of pre-trained linguistic knowledge is highly dependent on specific adaptation strategies, such as novel tokenization methods, effective reprogramming of time series into the language space, and parameter-efficient fine-tuning (PEFT) [2,25].

Evaluating foundation models for time series presents unique challenges, as 'traditional forecasting performance evaluation methods... are insufficient' [26]. The primary attribute of foundation models is their ability to 'predict completely novel sequences' [26], necessitating rigorous zero-shot and few-shot learning protocols [10,28]. A significant challenge in benchmarking models like TimeGPT is that their extensive pre-training on billions of data points from publicly available sources may include widely recognized academic datasets, making a truly "unseen" evaluation problematic for assessing true zero-shot capabilities [3]. Current evaluation practices are further hampered by the scarcity of diverse, high-quality, and time-aligned multimodal time series datasets, which are essential for adequately training and evaluating LLMs in this domain [6,32,34].

To address these deficiencies, a critical analysis emphasizes the need for more robust comparison methodologies that account for the unique characteristics of LLMs and multimodal time series [32]. The role of 'uncertainty quantification' through methods like 'conformal prediction' is crucial for assessing model reliability and understanding forecast confidence, especially in the presence of distribution shifts [21,26]. Moreover, dedicated evaluation metrics are required that can assess both the accuracy of results and the underlying reasoning processes, particularly for multimodal LLMs, moving beyond surface-level interpretations [32]. The "black box" nature of LLMs also poses challenges to understanding the data influence behind predictions and decisions, underscoring the need for enhanced interpretability [20].

Qualitative insights further reveal LLM reliability limitations, including struggles with understanding complex patterns, biases towards their training language distributions, and the issue of 'hallucinations' when generating explanations or augmented data [2]. While LLMs may offer qualitative insights or support tasks requiring general knowledge and reasoning, their direct application "lacks precision" for complex numerical relationships and exact predictions, often failing to compute probability distributions or generate precise numerical forecasts [30]. This highlights the nuanced efficacy of LLMs, where they show promise in areas requiring generalized understanding or multimodal integration, but often struggle or under-deliver in tasks demanding high numerical precision and faithful capture of intrinsic time series dynamics. The field therefore requires continued research into effective modality bridging strategies and more rigorous, holistic evaluation frameworks to accurately gauge the true potential and limitations of LLMs in time series analysis.
### 9.1 Datasets and Evaluation Protocols
The robust evaluation of Large Language Models (LLMs) for time series analysis necessitates a diverse array of benchmark datasets and rigorous evaluation protocols. Current research employs a wide spectrum of datasets, reflecting the complexity and real-world applicability of LLMs across various domains [10].

Benchmark datasets exhibit considerable diversity in terms of domain, scale, and characteristics. Widely adopted univariate and multivariate time series benchmarks for forecasting tasks include the Electricity Consumption dataset, the Traffic dataset, and the Weather dataset, each providing hourly or sub-hourly data from real-world sensors [4,8,9,15,25]. The ETT (Electricity Transformer Temperature) dataset, encompassing ETTh1, ETTh2, ETTm1, and ETTm2 sub-datasets, is frequently utilized to assess models on power transformer data at different granularities [4,8,9,15,25]. Other common real-world datasets include the Illness dataset (weekly influenza cases), the Exchange Rate dataset (daily currency rates), Covid Deaths, and Taxi trip data, showcasing governmental, financial, and urban time series, respectively [4,8,9,10,15]. Competitive benchmarks such as the M5 competition, which focuses on hierarchical time series forecasting, are also frequently used [28]. Additionally, specialized archives like the Monash Time Series Forecasting Archive provide standardized platforms for comparative studies [5,27].

Several studies highlight the use of domain-specific datasets to validate LLM performance. In the financial sector, datasets like Financial Aid by US States (yearly data with categorical features and text notes), Currency Exchange Rate, daily Stock Market prices (e.g., S&P 500, Microsoft, Apple), and Commodity prices (Natural Gas, Crude oil, Gold) are employed to test models on financial and macroeconomic time series [10]. Healthcare applications leverage datasets such as MIMIC-III, which provides ICU vital signs and clinical notes, and other public datasets like WE-SAD and MHEALTH [28,34]. For anomaly detection tasks, specific datasets are designed to test various anomaly types, including point, range, frequency, and trend anomalies [17], alongside comprehensive benchmark suites like TSB-UAD for univariate time-series anomaly detection [27].

A significant trend in dataset selection involves the development of large-scale, diverse datasets specifically for training time series foundation models. Examples include the Time-series Pile, which aggregates data from various tasks, and the Unified Time Series Dataset (UTSD), comprising over 1 billion time points from seven domains [14]. LOTSA further expands on this, combining open-source time series from nine domains, totaling 27.6 billion observations, addressing challenges like varying frequencies and distributions [14]. ChatTime also constructed high-quality datasets for continuous pre-training and instruction fine-tuning to cover diverse scenarios [14]. PromptCast introduces the large PISA dataset for its evaluations [12,16].

Despite these advancements, a critical bottleneck is the scarcity of diverse, high-quality, and time-aligned multimodal time series datasets [34]. This limitation is explicitly acknowledged across multiple works, which call for more realistic and multimodal benchmarks that extend beyond synthetic samples and can support diverse reasoning structures [6,23,31,32,34]. The TimeText Corpus (TTC) represents a recent effort to address this gap, offering a curated, time-aligned text and time dataset for multimodal forecasting in domains such as climate science (National Weather Service data) and healthcare (MIMIC-III with clinical notes) [34]. Similarly, WildfireSpreadTS provides a multi-modal dataset for wildfire prediction [27].

Evaluation metrics commonly employed in time series tasks primarily focus on forecasting accuracy. The Mean Absolute Error (MAE) and Mean Squared Error (MSE) are the most ubiquitous metrics, quantifying the difference between predicted and actual values [4,8,9,15,24,25,28]. The Root Mean Squared Error (RMSE) is also utilized, particularly in multimodal contexts [34]. For probabilistic forecasting, the Normalized Average Continuous Ranked Probability Score (NACRPS) is used [28]. In anomaly detection, the F1-score and its variations are favored due to their ability to balance precision and recall, especially when dealing with discrete anomaly intervals generated by LLMs [17]. For multimodal tasks involving text generation, metrics such as Cosine Similarity, METEOR, and ROUGE are applied, complemented by qualitative LLM-based metrics like GPT Semantic Score and GPT F1 Score to assess semantic alignment [34]. Beyond mere accuracy, research emphasizes the importance of rigorous uncertainty quantification, particularly in the presence of distribution shifts [21], and the need for dedicated metrics that examine the dual accuracy of results and underlying reasoning processes for multimodal LLMs [32].

Evaluation protocols are meticulously designed to assess model generalization and transferability, especially in resource-constrained scenarios. Few-shot learning protocols typically involve training models with a limited fraction of the available data, often 10% or 5%, to evaluate performance under data scarcity [4,8,9,10,15,25,35]. Zero-shot learning is a crucial protocol for evaluating the out-of-distribution generalization capabilities of LLM-based models on unseen time series datasets without prior training on specific target data [5,10,12,16,19,28]. This setting is particularly relevant for foundation models, which are expected to demonstrate strong transferability [14].

Additional experimental protocols include assessing the impact of input shuffling to determine an LLM's ability to capture sequential dependencies [4,9,15]. Studies also compare different initialization and fine-tuning strategies to understand the contribution of pre-trained language knowledge versus random initialization [9]. For long-term forecasting, evaluations often standardize prediction lengths and align configurations with established models like PatchTST for consistent comparison [25]. Furthermore, self-supervised learning evaluations often utilize a linear evaluation protocol where a pre-trained backbone's weights are frozen, and a linear layer is trained on the downstream task to assess representation learning [25]. These varied protocols provide a comprehensive framework for understanding the strengths and limitations of LLMs in diverse time series applications.
### 9.2 Performance Comparison and Critical Analysis
The efficacy of Large Language Models (LLMs) in time series forecasting presents a complex landscape, characterized by conflicting claims of state-of-the-art (SOTA) performance alongside evidence of significant limitations and inefficiencies. A critical comparison reveals that while some LLM-based approaches demonstrate competitive or superior performance in specific contexts, others fall short when benchmarked against established time series models and LLM-free baselines [4].

Several studies highlight instances where LLM-based models achieve SOTA results. For example, LLM4TS has been reported to achieve SOTA in long-term forecasting and exhibit strong representation and few-shot learning capabilities [13,16,23,25]. Similarly, TimeGPT, Lag-Llama, and Sundial are noted for their strong zero-shot performance, often outperforming supervised baselines and traditional statistical or deep learning methods [3,14,16,26,29]. TimeMixer++ and Chronos also claim SOTA performance or advantages over statistical models in forecasting benchmarks [19,21]. Time-LLM, through reprogramming time series into the language space, is recognized for enhancing LLM performance in various prediction scenarios, excelling in both few-shot and zero-shot settings [1,2]. PatchInstruct also claims to enhance LLM forecasting quality, especially by addressing limitations of prior LLM approaches like heavy fine-tuning [24]. Furthermore, OFA has shown that even frozen LLMs can perform considerably well due to their self-attention mechanisms [2].

However, a substantial body of evidence underscores the limitations of LLMs, particularly when directly applied to time series tasks without specialized adaptation. Critical analyses consistently reveal that LLMs often show limited or no advantage, especially in numerical forecasting scenarios. For instance, in a comprehensive study across 8 datasets and 2 metrics, simpler ablation methods (without LLMs or with basic architectural components) significantly outperformed full LLM-based methods like Time-LLM (in 26 out of 26 cases), LLaTA (in 22 out of 26 cases), and OneFitsAll (in 19 out of 26 cases) [4,9,15]. This strongly indicates that pre-trained LLMs are largely ineffective for time series forecasting in these paradigms. The Hybrid-MMF model also did not consistently outperform existing baselines for numerical forecasting, highlighting challenges in multimodal forecasting [34].

LLMs demonstrate limitations in specific scenarios and task types. Direct application of out-of-the-box LLMs to raw numerical signals is often "counter-intuitive" due to the modality gap [2]. In macroeconomic forecasting, traditional models, especially BVAR, generally outperform LLMs across various horizons, with even GPT-4 struggling to consistently surpass simple baselines [18]. General LLMs like ChatGPT have been shown to perform poorly in precise numerical tasks such as stock movement prediction, lagging behind both SOTA methods and traditional linear regression [7,12,14,16]. Moreover, their reasoning capabilities are often weak, failing to improve anomaly detection even with explicit chain-of-thought prompts, and their performance degrades with increasing input sequence length [17]. Qualitative observations further suggest that purely textual methods are inaccurate for numerical temperature prediction compared to pure time models [34].

Common patterns and conflicts in performance results can be attributed to several factors. Divergences arise from differences in model adaptation, dataset properties, and evaluation methodologies. For instance, the superior performance of models like LLMTime and Time-LLM is attributed to novel tokenization methods and reprogramming time series into the language space, which specifically address the modality gap [2]. Conversely, general LLMs often struggle because their direct application "lacks precision" for complex numerical relationships and exact predictions, excelling more in qualitative reasoning [30]. The nature of the task also plays a crucial role; for example, multimodal forecasting involving dynamic and unpredictable textual events (like weather) poses inherent difficulties, where models may fail to adapt well to time-series tokens in the embedding space [34]. Data scarcity can also limit a hybrid model's learning effectiveness [34]. Additionally, the alignment processes (e.g., RLHF) optimized for general conversational quality can inadvertently impair LLMs' ability for precise numerical extrapolation [5]. A critical challenge in benchmarking foundation models like TimeGPT against standard academic datasets is the possibility that their vast training data might include these datasets, making a truly "unseen" evaluation problematic [3].

A significant concern is the performance-to-cost ratio for LLM-based time series models. These methods frequently demand substantially more computational resources without delivering proportional or superior forecasting performance [9]. For example, Time-LLM, with 6642 million parameters, required 3003 minutes to train on the Weather dataset, whereas its ablation counterpart, with only 0.245 million parameters, trained in just 2.17 minutes [4,9,15]. Inference times for LLM-based models (Time-LLM, OneFitsAll, LLaTA) were also orders of magnitude slower, being 28.2, 2.3, and 1.2 times longer, respectively, compared to their ablated versions [4,9,15]. This substantial computational overhead without commensurate performance gains renders many LLM-based approaches impractical for real-world applications where efficiency is critical.

The empirical evidence regarding the transferability of pre-trained linguistic knowledge to time series tasks is largely contradictory, challenging the intuitive assumption that general LLM capabilities would directly translate to time series proficiency. Several studies indicate that pre-trained language knowledge offers limited benefit for time series forecasting. Experiments comparing "random initialization + fine-tuning" with "pre-training + fine-tuning" frequently show that the former performs better, achieving the best results in 8 cases compared to only 3 cases for pre-trained models [4,9,15]. This suggests that the knowledge acquired during pre-training on text data provides limited assistance for time series tasks. The flaw in the intuitive assumption lies in the fundamental differences between linguistic data and time series data. LLMs struggle to represent sequential dependencies in time series data, as evidenced by input shuffling experiments that similarly affect LLM-based methods and their ablation counterparts [4,9,15]. Instead, any observed performance in LLM-based time series models is often attributed to simpler encoding techniques, such as patching combined with single-layer attention or basic Transformer modules, rather than the complex capabilities of the large pre-trained language model itself [4,9,15].

Conversely, other research argues that knowledge transfer from pre-trained LLMs is crucial for the success of their models. LLM4TS attributes its SOTA long-term forecasting, robust representation learning, and few-shot learning capabilities to knowledge transfer [13,23]. Sundial also highlights that "knowledge transfer from pre-trained models" is a crucial factor in its success, with larger models consistently achieving better performance [29]. These conflicting findings emphasize that the utility of pre-trained linguistic knowledge is highly dependent on the specific adaptation strategies and the architectural choices made for integrating LLMs with time series data. Effective strategies, such as time-series alignment stages and PEFT, are shown to enhance forecasting accuracy and data efficiency, especially in few-shot learning scenarios [25]. However, without such careful adaptation, the direct transfer of linguistic knowledge appears to be largely ineffective for numerical precision and capturing inherent time series patterns.
## 10. Challenges, Limitations, and Ethical Considerations
Despite the promising advancements in applying Large Language Models (LLMs) to time series analysis, the field is confronted by substantial challenges that impede their widespread and effective deployment. These obstacles span fundamental architectural mismatches, inherent performance inconsistencies, significant computational demands, and critical ethical considerations, demanding a rigorous theoretical and practical re-evaluation of current methodologies.

A primary barrier stems from the **modality gap** [2,6,12,14,25,31,34]. LLMs are predominantly trained on discrete linguistic data, which fundamentally mismatches the continuous, numerical nature of time series data [2,30]. This discrepancy leads to significant **numerical reasoning deficiencies**, where standard LLM tokenizers, designed for text, struggle to handle continuous values, resulting in inconsistent tokenization, loss of numerical precision, and a diminished capacity for robust statistical reasoning [2,14,18,30]. Consequently, LLMs exhibit a "shortfall in recognizing key time-series patterns and nuances" [25], often failing to effectively utilize their textual reasoning capabilities for numerical tasks [4,8,9,15]. This can manifest as "hallucinated values" or forecasts in "inconsistent formats," undermining quantitative reliability [18]. Even alignment mechanisms (e.g., RLHF) intended to improve LLM general coherence have been shown to degrade performance in numerical extrapolation tasks, prioritizing linguistic fluency over numerical precision [5].

The inherent **black-box nature** of large deep learning models, including LLMs, presents formidable challenges for **interpretability, trustworthiness, and ethical accountability** [20]. In sensitive time series applications such as healthcare, finance, or autonomous systems, understanding the rationale behind a model's prediction is critical for decision-making and risk assessment [7,12,28,32]. The lack of transparency in LLMs makes it difficult to discern the data's influence on predictions, leading to issues like "hallucinated values" and "inconsistent output formats" that severely compromise trustworthiness [18]. Furthermore, LLMs demonstrate a "non-human-like" processing of time series data, struggling with nuanced understanding of subtle real-world anomalies [11,17]. This limitation, combined with a lack of robust uncertainty quantification, impacts reliability in high-stakes domains [18]. Ethical concerns extend to **algorithmic bias, fairness, transparency, and accountability**, particularly the crucial aspect of **privacy protection** when LLMs process sensitive data like medical records or financial information [31,32]. The need for "responsible and transparent AI" is paramount for the ethical deployment of LLM-assisted systems [2,6].

**Data irregularities and the dynamic nature of time series environments** pose significant obstacles. Real-world time series often exhibit non-stationarity, where statistical properties evolve over time, alongside unpredictable fluctuations and **concept drift** [2,25,30,31]. This inherent dynamism, coupled with irregularities such as sparsity, noise, outliers, and irregular sampling rates [2,30,31], challenges LLMs, which are not inherently designed to handle such complexities [30]. A critical **architectural limitation** for LLMs is their **context window constraint**, leading to a "short memory" where they "forget early data points" and "miss temporal relationships" in long sequences [30]. This "long context window bias" or information loss hinders their ability to capture long-range temporal dependencies, crucial for accurate long-term forecasting [17,35]. Furthermore, the **scarcity of large-scale, well-curated time series datasets**, especially multimodal ones, limits the development of robust foundation models capable of generalizing across diverse applications [23,32].

The **computational costs and resource demands** associated with LLMs are often prohibitive for time series applications, especially in real-time or resource-constrained environments [2,4]. Transformer-based architectures, central to LLMs, suffer from "quadratic time complexity and high memory usage" for long input sequences, leading to a "computational explosion" [28]. Empirical studies reveal that LLM-based methods often require significantly longer training and inference times than simpler baselines, with some LLMs demanding several days of training on substantial computational resources [3,4,8,9,15,22]. This necessitates "powerful hardware" [30] and makes their deployment "less efficient and more expensive than traditional methods" for many organizations [18]. Such high energy consumption also raises concerns about environmental sustainability [14]. While techniques like Parameter-Efficient Fine-Tuning (PEFT) and architectural optimizations (e.g., FlashAttention, KV Cache) are being explored to mitigate these costs [23,25,29], computational efficiency remains a significant barrier for large-scale adoption [31,32].

Finally, the field is plagued by **inconsistent performance and significant benchmarking shortcomings**. Empirical evidence frequently demonstrates that LLM-based methods often underperform simpler baselines or ablated models in time series tasks, challenging the assumption of their inherent superiority [4,8,9,15]. General-purpose LLMs, like ChatGPT, often struggle in specialized numerical domains such as financial stock prediction [7,12,14,16]. This variability is compounded by an absence of robust and standardized benchmarking. Current evaluation metrics are often described as "immature," with a critical need for "dedicated evaluation metrics" and "more realistic and multimodal benchmark datasets" [32]. The "lack of large-scale standardized datasets" and the issue of proprietary models potentially having "seen" benchmarks during training further complicate objective comparison and hinder transparent academic evaluation [3,14,26]. These issues collectively underscore the necessity for rigorous evaluation frameworks to foster genuine progress and ensure the reliability of LLMs in time series analysis.
### 10.1 Modality Gap and Numerical Reasoning Deficiencies
The application of Large Language Models (LLMs) to time series data is significantly hampered by an inherent "modality gap," which refers to the fundamental mismatch between the text-centric nature of LLMs, primarily trained on discrete linguistic corpora, and the continuous, numerical characteristics of time series data [2,6,12,14,25,31,34]. This dissimilarity in data composition poses multifaceted challenges for effectively leveraging LLMs in time series analysis [25]. The pursuit of "transferable representations" and "multimodal language modeling" implicitly acknowledges this gap as a core challenge to be bridged [33].

This modality gap directly leads to significant challenges in numerical precision and robust statistical reasoning. Standard LLM tokenizers, designed for linguistic data, are ill-equipped to handle continuous numerical values. They tend to separate continuous values and overlook their temporal relationships, leading to potential issues with inconsistent tokenization of floating-point numbers and a loss of numerical precision and contextual information [2,14,18,30]. The conversion of continuous numerical data into discrete textual representations inherently sacrifices some of this precision, further exacerbating the problem [18]. For instance, Sundial highlights that discrepancies between continuous-valued time series and discrete language tokens can lead to out-of-vocabulary issues and coarse-grained prediction intervals [29]. Consequently, LLMs struggle to represent precise numerical patterns and perform fine-grained statistical calculations, such as computing probability distributions or generating accurate numerical predictions [30].

Furthermore, the pre-training on linguistic corpora results in a "shortfall in recognizing key time-series patterns and nuances" [25]. Studies reveal that LLMs' inherent reasoning capabilities are often "not effectively utilized" for time series tasks, indicating a fundamental deficiency in applying text-based reasoning directly to continuous numerical data [4,8,9,15]. The observed performance gains in some LLM-based approaches are sometimes attributed to simpler architectural components like patching and attention layers, rather than the complex language processing backbone of the LLM itself, suggesting that the LLM's capacity for complex numerical patterns remains largely untapped or ineffective [4,15]. This deficiency extends to LLMs' ability to perform complex numerical relationships and arithmetic operations, often resulting in "hallucinated values" or forecasts in "inconsistent formats," undermining robust quantitative reasoning [18]. Even advanced LLMs, like GPT-4, when aligned for general language coherence, can exhibit degraded performance in numerical extrapolation tasks, suggesting that current alignment methodologies may prioritize linguistic fluency over numerical precision [5]. Research also indicates that LLMs' understanding of time series anomalies is not linked to their arithmetic reasoning capabilities, demonstrating a fundamental struggle with raw numerical processing and nuanced statistical reasoning [17].

The limitations of text-centric models when confronting inherently numerical domains are starkly illustrated by their performance in specific financial tasks. Evidence shows that general LLMs, such as ChatGPT, perform poorly in tasks like stock movement prediction, even when compared to simple linear regression models [14,16]. This highlights their limitations in complex numerical and financial reasoning, especially when integrating multimodal signals in financial time series forecasting [16]. The need for specific procedures to "effectively tokenize time series data and convert discrete distributions into highly flexible continuous value densities" underscores the inherent difficulties LLMs face with raw numerical time series data in such critical applications [16]. While some models, like TimeGPT, aim to address these issues by directly handling continuous numerical data as native time series models [3], even they can be affected by distribution differences, indicating a nuanced deficiency in adapting to out-of-distribution numerical data [22]. Efforts to mitigate this gap include methods like time series patching with temporal encoding [23,25], time series decomposition and patch-based tokenization [24], and converting time series into "text prototypes" [1], but these often circumvent rather than directly solve the core numerical reasoning limitations.
### 10.2 Inconsistent Performance and Benchmarking Shortcomings
Despite the considerable potential of Large Language Models (LLMs) in time series analysis, empirical evidence consistently reveals significant variability and often inconsistent performance, challenging the assumption of their universal superiority. This section critically examines scenarios where LLMs demonstrate strengths and weaknesses, analyzes the underlying reasons for these discrepancies, and discusses how the absence of robust benchmarking impedes objective comparison and progress in the field.

Empirical studies frequently demonstrate instances where LLM-based methods underperform, particularly when compared against simpler baselines or ablated models. A recurring "disturbing trend" highlights that the efficacy of LLMs for time series tasks is often overstated without rigorous validation [8]. For instance, extensive ablation studies reveal that simpler, non-LLM baselines or ablated models frequently outperform full LLM integrations. Specifically, ablation methods achieved superior results compared to Time-LLM in all 26 cases, LLaTA in 22 out of 26 cases, and OneFitsAll in 19 out of 26 cases across various datasets and metrics [4,9,15]. This directly challenges the notion that LLMs inherently offer superior capabilities for time series forecasting [15]. Furthermore, general-purpose LLMs, such as ChatGPT, have been shown to perform poorly in highly specialized domains like financial stock prediction, often failing to outperform even traditional baselines such as linear regression [7,12,14,16]. This suggests that LLMs may lack an intrinsic understanding of complex numerical patterns or statistical relationships without specific adaptation [12].

The inconsistent performance extends to model stability and precision. LLM performance can be "highly sensitive to prompt wording and the number of historical values provided," leading to unreliable deployment [18]. GPT-4 occasionally shows marginal improvements over simple baselines but often underperforms traditional models, while Llama2 models rarely surpass them, indicating a lack of consistent advantage [18]. Moreover, LLMs with alignment mechanisms (e.g., RLHF) have surprisingly shown worse performance than less capable or non-aligned models (e.g., GPT-4 performing worse than GPT-3) for numerical time series tasks, highlighting a challenge in optimizing LLMs for numerical fidelity [5]. Research also indicates significant variability in the behavior and performance of different LLM models when applied to time series anomaly detection, suggesting an inherent lack of consistent reliability across models [17]. Specific issues include "low numerical precision" for direct prompting and visual representations, rendering them more suitable for qualitative insights rather than exact predictions or complex numerical computations [30]. Critiques of models like Chronos further suggest performance inconsistencies or limitations within existing benchmarks [19].

Conversely, some specialized LLM-based approaches demonstrate promising capabilities. Time-LLM claims to "outperform state-of-the-art, specialized forecasting models" and excels in few-shot and zero-shot learning scenarios [1]. Similarly, LLM4TS exhibits consistent superiority across various datasets in both full-shot and few-shot learning, highlighting its data-efficient characteristics [25]. The ability of LLMs to perform zero-shot learning, a limitation for traditional models lacking pre-training, underscores their potential generalizability [10]. Sundial, a family of time series foundation models, aims to address inconsistencies arising from non-generative or non-probabilistic models and issues with discrete tokenization, demonstrating "state-of-the-art zero-shot performance" across established benchmarks [29]. However, even for models like TimeGPT, consistent superiority is not guaranteed, as performance can vary significantly depending on distribution differences between load data and training data, necessitating careful validation [22].

Several reasons contribute to these discrepancies. A primary factor is the "scarcity of datasets" and the "limited large-scale time-series data for building robust foundation models" [23,32]. This limitation is particularly pronounced for "large-scale, well-curated, paired time series and text datasets for forecasting," which is crucial for multimodal approaches [34]. The inherent diversity and wide scope of application scenarios in time series data make it challenging to develop universally effective LLM-assisted solutions [2]. Furthermore, "understanding Model Limitations" reveals that even powerful models like Transformers may struggle and perform inconsistently in time series contexts [35]. The "inherent difficulty of textual event forecasting" also contributes to the limitations of multimodal models [34]. Other challenges include the struggle to combine channel independence and dependence in time series models, and the observation that contrastive learning and data augmentation methods designed for classification can degrade prediction accuracy by disrupting fine-grained temporal relationships in time series data [28]. Additionally, the "black box" nature of LLMs hinders understanding the data influence behind predictions, making consistent assessment difficult [20]. Discrete tokenization in prior works can lead to "out-of-vocabulary issues and coarse-grained prediction intervals," directly impacting prediction quality and consistency [29].

The absence of robust benchmarking significantly hinders objective comparison and progress. Current evaluation metrics are often described as "immature," with a pressing need for "dedicated evaluation metrics" that assess both results and underlying reasoning processes [32]. The lack of "more realistic and multimodal benchmark datasets" is a critical bottleneck [32]. The nascent stage of LLM-time series integration means that "evaluation settings are not being aligned or clearly defined," and there is an overarching "lack of large-scale standardized datasets" [14,26]. This contributes to misleading reported performances, as current benchmarking practices often lack the necessary rigor, especially in conducting thorough ablation studies [4]. The focus on single modalities and single tasks in current research implies a lack of comprehensive, multi-modal, and multi-task evaluation frameworks, highlighting a need for more robust assessment [31]. A significant challenge also arises in fairly benchmarking models like TimeGPT, where its extensive training on public datasets might mean it has already "seen" known benchmarks, making independent evaluation difficult [3].

The observed "negative results," such as the Hybrid-MMF model not outperforming existing baselines despite its multimodal design, underscore the complexity and inherent difficulty in achieving breakthroughs in multimodal forecasting [34]. These instances are crucial for revealing fundamental limitations and guiding future research towards more effective evaluation frameworks. The implicit calls for "more robust and comprehensive benchmarking" [8], "thorough ablation studies and critical evaluations" [4], and the development of "more robust evaluation frameworks and future research into multimodal and multi-task analysis" [31] all point to a consensus within the research community regarding the urgent need for a standardized and rigorous evaluation paradigm to foster genuine progress.
### 10.3 Interpretability, Trustworthiness, and Ethical Concerns
The deployment of Large Language Models (LLMs) in time series analysis, particularly for sensitive applications, introduces critical challenges related to interpretability, trustworthiness, and a range of ethical considerations. The inherent "black box" nature of complex LLMs makes the data influence behind their predictions and decisions difficult to understand, necessitating a deeper theoretical analysis [20]. This lack of transparency is especially problematic in high-stakes domains such as healthcare, finance, and autonomous driving, where understanding model behavior is paramount for decision-making and risk assessment [7,12,28,32].

Efforts to enhance interpretability in LLM-based time series models are underway. Some approaches focus on providing natural language explanations of trends or allowing for human-like pattern recognition through direct prompting and visual methods [30]. The integration of LLMs with domain-specific models, such as TrafficGPT, has been shown to offer detailed insights that enhance system interpretability [2,6]. Furthermore, models like Auto-TTE can generate interpretable ECG classifications using LLM-executable scripts [30]. Broader research emphasizes the importance of interpretable predictions in safety-critical fields, proposing methods like generating actionable counterfactual explanations [28] and developing visual analytics frameworks such as TimeTuner to help diagnose model behavior [28]. Specific studies also address the black-box nature through techniques like "Optimal Information Retention for Time-Series Explanations" and "Timing: Temporality-Aware Integrated Gradients" [35], while others investigate "Pattern Neurons in Urban Time Series Forecasting" to understand model decisions [21]. The ability of LLMs to provide explanatory time series forecasting results in textual form is also highlighted as a key advantage, addressing a common limitation of traditional models [12,16].

The trustworthiness of LLMs in time series is significantly compromised by issues such as hallucinations and biases. LLMs frequently "hallucinate values" and produce "inconsistent output formats," which severely undermines their reliability in critical domains like macroeconomic forecasting where accuracy is paramount [18]. This problem is recognized as an active research area and challenge in the field [11]. Moreover, LLMs exhibit a "non-human-like" processing of time series data, struggling with the nuanced understanding of subtle, real-world anomalies [11,17]. This limitation, coupled with a lack of robust reasoning, can lead to misinterpretation of patterns, resulting in false positives or missed critical events, thereby undermining their overall reliability [17]. Another facet of trustworthiness is the LLMs' "limited ability to adapt their responses to reflect uncertainty," often providing unreliable confidence intervals or failing to generate them consistently [18]. This lack of robust uncertainty quantification impedes high-stakes decision-making. In contrast, models like TimeGPT implement conformal prediction to estimate prediction intervals, contributing to trustworthiness by providing quantifiable uncertainty estimates and enabling anomaly detection based on these intervals [3,26]. Implicit biases can also arise, as suggested by research into "Label Correlation Biases" that directly influence time series forecasts [21]. Furthermore, the finding that aligned LLMs (e.g., GPT-4) can perform worse on numerical tasks than their unaligned predecessors (e.g., GPT-3) raises concerns about their reliability and predictability for critical quantitative applications [5].

Ethical challenges extend beyond interpretability and trustworthiness, encompassing algorithmic bias, fairness, privacy, transparency, and accountability. Privacy protection is a particularly significant challenge, especially when customizing LLMs for users involving sensitive data such as medical records or financial information [31,32]. Differential privacy has been explored as a solution in this context, particularly for deep differentially private time series forecasting [35]. The call for "responsible and transparent AI" in LLM-assisted enhancers underscores the awareness of these ethical concerns, advocating for the development of "efficient, responsible, and universally applicable plug-and-play solutions" [2,6]. While not always explicitly detailed, the implications of LLMs' high computational costs and sometimes poor performance in time series forecasting also raise questions about their responsible deployment, especially if they do not offer clear advantages over simpler, more efficient models [4]. These profound ethical considerations are crucial for the acceptance and effective deployment of LLMs in real-world time series systems, necessitating a focus on trustworthy, interpretable, and robust reasoning within these models [32].
### 10.4 Data Irregularities and Dynamic Environments
The dynamic and inherently irregular nature of real-world time series data presents fundamental obstacles for modeling, particularly for Large Language Models (LLMs) adapted to this domain. These challenges manifest in several key areas, leading to potential degradation in model performance and reliability.

A primary concern is **non-stationarity and evolving data distributions**. Real-world time series frequently exhibit non-stationary properties, where statistical characteristics change over time, alongside unpredictable fluctuations, such as the dynamic nature of weather systems [34]. This includes phenomena like **concept drift**, where the underlying data generation process shifts, and **distributional shifts** between training and testing data, which are common due to seasonal changes or evolving trends [2,25,30,31]. The complex, non-stationary nature of macroeconomic time series data, for instance, significantly challenges LLMs' ability to capture dynamic relationships effectively [18]. Traditional Transformer-based models can even suffer from severe overfitting when processing non-stationary time series, stemming from improper initialization of unknown decoder inputs [28]. Static quantization methods, like K-Means clustering, become ineffective in the face of concept drift, necessitating models that can adapt dynamically [30]. Addressing non-stationarity is a significant research focus, as evidenced by dedicated works like "Multi-Resolution Decomposable Diffusion Model for Non-Stationary Time Series Anomaly Detection" and "TimeBridge: Non-Stationarity Matters for Long-term Time Series Forecasting" [21,35].

Another significant challenge arises from **data irregularities** such as sparsity, noise, outliers, and irregular sampling rates [2,30,31]. Time series data typically possesses a lower information density compared to other modalities like video, and often contains unpredictable noise, necessitating robust processing mechanisms [2,28]. The prevalence of "不规则时间序列" (irregular time series) in real-world scenarios, often due to uneven sampling or incompleteness, makes it a recognized challenge tackled by works such as "Amortized Control of Continuous State Space Feynman-Kac Model for Irregular Time Series" and "Vision Transformer for Irregularly Sampled Time Series" [11,21]. Moreover, the problem of scarce historical data is a common irregularity, with traditional machine learning models exhibiting limited accuracy in such low-data regimes [22]. The heterogeneity of time series data—varying frequencies, numbers of variables, and statistical distributions—further complicates the development of unified foundation models capable of generalizing across all types [14].

A critical limitation for LLMs in time series contexts is their ability to handle **long-term dependencies and context window constraints**. LLMs often suffer from a "short memory," causing them to "forget early data points" and "miss temporal relationships" in long sequences [30]. This "context window limitation" restricts the amount of historical data that can be provided, potentially hindering the model's ability to learn intricate long-term dependencies and adapt to dynamic shifts [14,18]. Evidence suggests a "long context window bias" or information loss, where LLMs struggle to maintain focus or adequately process extended temporal dependencies, leading to reduced performance with longer sequences [17]. This difficulty in capturing long-range temporal relationships and preventing information loss over extended context windows is a persistent challenge [35].

The challenges in handling these dynamic and irregular properties often translate into **difficulty in robustly capturing sequential dependencies**. Experiments involving input shuffling have revealed that LLM-based methods do not consistently demonstrate outstanding capabilities in capturing complex temporal relationships when compared to their ablation counterparts [4,9,15]. This implies a potential weakness in modeling the inherent order and relationships within time series, which is crucial for addressing non-stationarity and concept drift.

To mitigate these challenges, various approaches have been proposed. Some models explicitly address non-stationarity and distribution shifts through techniques like **Re-Normalization**, designed to solve time distribution shift and outlier range issues [29]. Similarly, the adoption of **Reversible Instance Normalization (RevIN)** during fine-tuning enhances forecasting accuracy by addressing distribution shifts between training and testing data [25]. Time series decomposition methods, such as those utilized by PatchInstruct, break down series into trend, seasonality, and residual components, inherently managing properties like non-stationarity and seasonal variations by providing clearer understanding of underlying dynamics to the LLM [24].

For managing long-term dependencies and context window limitations, **patch-based tokenization** and similar strategies assist in handling long context windows by segmenting series into digestible blocks [24,25]. Architectural adaptations, such as **FlashAttention and KV Cache** in Sundial, are introduced to facilitate real-time, long-context inference and long-term generation [29]. Integrating **multi-scale temporal information** through methods like a two-level aggregation strategy further enhances an LLM's ability to interpret time-specific information and adapt to complex temporal dynamics [25].

The emphasis on training LLMs on **vast and diverse time series datasets** from multiple domains (e.g., finance, weather, energy, web, sales) aims to equip them with the robustness and generalization ability to handle complex and potentially irregular real-world scenarios, implicitly addressing challenges like non-stationarity and concept drift [3,26]. This broad training helps in learning different temporal patterns and improving generalization, even with minimal preprocessing like imputing missing values [3,5]. Overall, the goal is to enhance "robust reasoning" and develop models with "robustness and generalization ability" when facing noise, outliers, and changes in data distribution, moving towards more efficient algorithms for large-scale time series data with long historical information [31,32].
### 10.5 Computational Costs and Resource Demands
The integration of Large Language Models (LLMs) into time series analysis introduces significant computational overhead, posing critical challenges to accessibility, sustainability, and deployment feasibility, particularly for real-time applications, edge computing, or organizations with limited resources. This computational intensity stems primarily from the architectural complexities of Transformer-based models and their extensive parameter counts, leading to substantial demands during both training and inference [2,28].

Quantitatively, the computational burden is stark. Transformer models inherently suffer from performance degradation and a "computational explosion" when handling larger lookback windows, alongside "quadratic time complexity and high memory usage" for long input sequences [28]. For instance, Time-LLM, a prominent LLM-based method for time series forecasting, was reported to have 6642 million parameters. In contrast, a much smaller ablation counterpart utilized only 0.245 million parameters. This substantial difference in model size translates directly into disproportionate resource consumption: Time-LLM required approximately 3003 minutes for training on the Weather dataset, whereas the ablation method completed training in a mere 2.17 minutes [4,8,9,15]. Furthermore, inference times for LLM-based methods (e.g., Time-LLM, OneFitsAll, LLaTA) were observed to be significantly longer, ranging from 1.2 to 28.2 times slower than their more efficient ablation counterparts [4,8,9,15]. The training of large foundation models like TimeGPT implicitly indicates substantial resource demands, with one instance stating it was "trained over multiple days" [3,22].

These high computational costs severely impact the practical applicability of LLMs in time series. For real-time applications and edge computing environments, the "significant time and cost overhead when dealing with large-scale datasets" makes LLMs prohibitive [2]. The necessity for "powerful hardware" to process and convert large datasets, especially when using visual representations or managing context windows for high-frequency data, further restricts deployment [30]. For organizations with limited resources, the expense of running open-source LLMs locally, which requires substantial computational resources, or the "substantial" API costs associated with commercial LLMs like GPT-4, renders LLM-based forecasting "less efficient and more expensive than traditional methods" [18]. The argument is frequently made that the computational intensity of LLMs is not justified by their performance improvements in time series forecasting, making them impractical for many real-world scenarios [4,8,9,15]. The overall resource consumption also raises concerns about sustainability, particularly given the energy demands for training and continuous adaptation [14].

To mitigate these challenges, researchers are exploring various strategies. Architectural improvements aim to enhance efficiency, such as the incorporation of "FlashAttention" and "KV Cache" in models like Sundial, which facilitate "just-in-time inference speed" and accelerate deployment by achieving zero-shot predictions within milliseconds [29]. Other models like TSMixer and Mlinear have demonstrated significantly improved efficiency, with TSMixer reducing memory and runtime by 2-3 times and Mlinear achieving a 10x efficiency advantage over state-of-the-art models [28]. Similarly, a Transformer-based Diffusion Probabilistic Model boasts being "more computationally efficient" and "17 times faster" in inference compared to baselines [28]. TimeGPT also highlights remarkable *inference efficiency*, reporting GPU inference speeds of 0.6 milliseconds per series in zero-shot scenarios, which significantly enhances accessibility for users [26].

A prominent approach to managing high costs is Parameter-Efficient Fine-Tuning (PEFT) [23,25]. Techniques such as Low-Rank Adaptation (LoRA), Layer Normalization Tuning, and 4-bit quantization are employed to reduce memory and computational costs during fine-tuning, allowing adaptation of pre-trained LLMs with minimal parameter adjustments [7,13,14,16,23,25,34]. For instance, LLM4TS freezes most parameters and trains only about 1.5% of the total LLM parameters [25]. Additionally, input transformation strategies like patching and channel-independence can quadratically reduce the time and space complexity of Transformer architectures for processing long sequences [25]. The development of "Lightweight" models, such as LightCTS and "Lightweight General Time Series Forecasting Model," directly addresses the need for efficient, accurate models deployable on resource-constrained devices, acknowledging that increasing model complexity does not always translate to proportional accuracy gains [28,35]. Despite these efforts, "computational efficiency" remains a key challenge, particularly for MLLMs in high-stakes domains, emphasizing the continued need for efficient algorithm development to reduce complexity and improve scalability and user experience for large-scale time series data [31,32].
## 11. Future Directions and Open Research Questions
The rapidly evolving field of Large Language Models (LLMs) for time series analysis presents a multitude of future opportunities and pressing research questions, primarily centered on overcoming current limitations and striving towards a holistic "general time series analysis intelligence" (AGI) [2,6,30,32]. This aspirational goal envisions a unified system capable of adeptly handling diverse time series problems with robustness, efficiency, and generalizability, necessitating a strategic research trajectory that synergizes the strengths of Foundation Models with specialized time series techniques.

A paramount challenge lies in **bridging the inherent modality and numerical reasoning gap** between LLMs' linguistic pre-training and the continuous, numerical nature of time series data. Future research must focus on designing domain-native foundation models and integrating specialized numerical processing modules to provide robust numerical grounding for complex time series dynamics. This involves advancing beyond mere adaptation of text-centric models to time series, exploring novel architectural modifications, continuous tokenization, and sophisticated projection and alignment techniques that seamlessly integrate numerical data into an LLM's semantic space [6,30,34]. Concurrently, ongoing research into improving synthetic data quality, as exemplified by efforts for Chronos, will be crucial to enhance models' ability to learn and represent diverse numerical time series patterns, thereby addressing the modality gap at the data level [19]. Improving LLM reasoning by exploring novel prompt engineering or architectural modifications is essential to unlock their potential for tasks requiring complex time series reasoning and social understanding, rather than merely sequence prediction [4,9,17,34].

To ensure meaningful progress, the field critically requires **robust and standardized benchmarking**. The current landscape is marked by inconsistent performance evaluations and a notable absence of reliable comparison metrics. Future efforts must establish comprehensive evaluation frameworks that extend beyond simple accuracy, assessing adaptability to new data, robustness to non-stationarity and concept drift, uncertainty quantification, and genuine reasoning abilities [12]. This includes developing standardized benchmarking protocols for multimodal time series and conducting rigorous ablation studies to identify true sources of performance in LLM-based models. A cornerstone of this initiative is the creation of public, large-scale, high-quality multimodal datasets with diverse annotations, directly addressing the identified lack of such resources and providing the necessary infrastructure to mitigate issues like the "negative results" observed in multimodal forecasting [6,11,30,34].

Furthermore, **enhancing interpretability and fostering responsible AI development** are paramount. Given the black-box nature of LLMs, future research must focus on advanced Explainable AI (XAI) techniques tailored for time series, including generating trustworthy textual explanations, designing inherently interpretable models, and providing transparent insights into decision processes. Alongside interpretability, responsible AI principles must guide development, emphasizing robust privacy protection (especially for sensitive data), bias mitigation, and accountability frameworks. The integration of conformal prediction methods can enhance trustworthiness by providing transparent risk assessment and reliable confidence intervals [26,32]. Research should also focus on the interpretability of cross-modal fusion mechanisms, ensuring clarity in how different data modalities contribute to LLM decisions [11,34].

Addressing the inherent dynamism of real-world time series necessitates robust mechanisms for **adapting to dynamic time series environments**. This involves enabling continuous learning, rapid online adaptation, and meta-learning strategies to handle non-stationarity, concept drift, and unpredictable fluctuations without extensive retraining [2,34]. Innovations are needed for efficient long context window handling, effective capture of long-range temporal dependencies, and enhanced model robustness against noise, outliers, and irregular data. The potential for integrating well-performing models like Chronos into production systems highlights the importance of research into deployment, efficiency, and reliability for real-world dynamic applications [19].

Finally, the realization of "general time series AGI" requires forging profound **cross-disciplinary synergies and pushing beyond traditional boundaries**. This vision entails leveraging existing and future Foundation Models more effectively, fostering deep integration with domain-specific knowledge across fields like finance, healthcare, and IoT, and processing truly multimodal and multitemporal data including text, images, and structured data [6,26,30]. The trajectory points towards higher-level contextual understanding and symbolic reasoning, including causal discovery and the development of multi-agent systems where LLMs orchestrate specialized tools and knowledge bases. This holistic research path, emphasizing architectural innovations and a sustained commitment to interdisciplinary exploration, is critical for achieving universal predictive analysis and seamless knowledge transfer across diverse time series domains [13,23].
### 11.1 Bridging the Modality and Numerical Reasoning Gap
The inherent disjunction between Large Language Models' (LLMs) linguistic pre-training and the continuous, numerical nature of time series data presents a significant modality gap that impedes effective numerical reasoning [20,34]. Overcoming this challenge necessitates a multi-faceted approach, encompassing the design of domain-native foundation models, the integration of specialized numerical processing modules, and sophisticated strategies for enhancing LLMs' contextual understanding to provide robust numerical grounding for complex time series dynamics.

A primary strategy involves designing foundation models specifically pre-trained on diverse time series data with native continuous-value processing capabilities. This moves beyond merely adapting text-centric models to time series. For instance, Sundial introduces "TimeFlow Loss" to enable native pre-training on continuous-valued time series, thereby circumventing the limitations of discrete tokenization [29]. Similarly, proposals for "building foundation models from scratch" for time series inherently advocate for architectures native to numerical and temporal data [2]. Continuous tokenization, such as patch tokens, is considered more effective for time series, offering a promising avenue for future research [14,29,35]. Techniques like LLMTime, which transform tokens into flexible continuous values, represent a step towards overcoming traditional tokenizer limitations [2,5]. Improving the quality of synthetic data, as explored for Chronos, also implicitly enhances models' ability to learn and represent underlying patterns in diverse numerical time series, thereby addressing the modality gap at the data level [19].

Further enhancing numerical reasoning requires integrating specialized numerical modules and developing hybrid architectures. Current research indicates that simple input transformations often fail to leverage LLMs' intrinsic reasoning capabilities for time series data [4,9]. LLM4TS, for example, employs architectural innovations such as a convolutional token encoding layer and a novel two-level temporal aggregation method to bridge this gap [13,23,25]. Future directions include refining these numerical representations, integrating more sophisticated numerical processing modules directly into LLM architectures, or exploring advanced hybrid numerical-symbolic designs [14,18,25,35]. The work of Professor Qi Liu's group, focusing on cross-domain pre-training and multimodal language modeling for time series, also points towards the development of such hybrid architectures and advanced integration techniques [33].

To provide "numerical grounding" for complex time series dynamics, leveraging LLM-like contextual understanding is paramount. This entails enabling LLMs to genuinely perform complex numerical and statistical reasoning, extending beyond mere sequence processing. Solutions include developing sophisticated projection and alignment techniques that seamlessly integrate numerical data into an LLM's semantic space, rather than simple concatenation [34]. Methodologies such as time series quantization, alignment techniques, and even leveraging the vision modality are being explored as bridging mechanisms [6]. PatchInstruct, for instance, transforms continuous time series data into a structured textual format suitable for LLM prompts, with future research focusing on more advanced numerical-to-text encodings and explicit embedding of statistical properties within prompts [24]. Other efforts, including PromptCast, AuxMobLCast, Time-LLM, and TEST, convert numerical time series into textual prompts or align them with text prototypes [12,16,28]. The objective is to cultivate better "digital representations" within LLMs through enhanced prompt engineering [30]. Moreover, the development of "aligned models" capable of integrating text, numbers, and images into a unified reasoning system is envisioned to lead to more robust numerical processing [30]. Critically, a deeper theoretical understanding of how LLMs interpret and process numerical time series data, and the potential pattern similarities between language and time series, is essential for enabling genuine time series reasoning [20,31]. This includes addressing challenges like the negative impact of LLM alignment (e.g., RLHF) on numerical precision and extrapolation, possibly through multi-objective alignment processes [5]. Furthermore, adapting to distribution shifts, as observed with TimeGPT's performance, requires adaptive fine-tuning strategies or architectural enhancements that allow models to adjust to changes in numerical time series data [22]. Future multimodal integration efforts aim for deeper fusion mechanisms where time series features are intrinsically aligned with language model representations, facilitating more profound reasoning across diverse modalities, including potentially incorporating video data [11,14,26,32,35]. This holistic approach is crucial for moving beyond mere sequence prediction towards genuine time series reasoning and social understanding tasks where LLMs' unique linguistic strengths can be effectively integrated [8,11,15].
### 11.2 Towards Robust and Standardized Benchmarking
The current landscape of Large Language Models (LLMs) applied to time series analysis is characterized by inconsistent performance and a notable absence of reliable comparison metrics, underscoring an urgent need for robust and standardized benchmarking [12,16]. Instances such as ChatGPT's suboptimal performance in stock prediction, juxtaposed with LLM4TS achieving state-of-the-art results in other contexts, highlight these discrepancies and the limitations of existing evaluation practices [12,16]. Furthermore, critical findings indicating that simpler models can often outperform LLM-based methods necessitate a re-evaluation of current metrics to ensure that reported performance gains are genuinely attributable to the LLM's unique capabilities rather than basic data processing or attention mechanisms [8,9,15]. This situation implicitly calls for more rigorous and transparent benchmarking practices to empirically justify the value proposition of complex LLM-based models [4].

To address these challenges, a comprehensive roadmap for developing robust and standardized benchmarking must extend beyond mere accuracy metrics, encompassing a multifaceted evaluation of model performance. Crucially, future evaluations should assess adaptability to new, unseen time series or with limited data, particularly in few-shot and zero-shot learning scenarios [16,35]. Beyond prediction accuracy, critical aspects include robustness to non-stationarity, concept drift, and out-of-distribution scenarios, as well as the capacity for uncertainty quantification [14,21]. Deeper analysis is required to understand why models succeed or fail, probing into LLMs' reasoning abilities, their handling of subtle anomalies, and cross-model consistency [17,35]. This involves evaluating quantitative reasoning, computational efficiency, and the ability to generate reliable uncertainty estimates across diverse time series domains [9,18]. Evaluating how models perform as they scale, exploring "neural scaling laws," also represents a vital future direction [21]. The commitment to improving general LLM evaluation practices, including personalized evaluation and role-guided self-reflection, further supports the development of robust frameworks for LLM-based time series models [33].

A cornerstone of this roadmap is the creation of diverse, high-quality multimodal datasets. The current "lack of large-scale, well-curated, paired time series and text dataset for forecasting" represents a significant hurdle [23,34]. Building upon efforts like Time-series Pile, UTSD, and LOTSA, there is a clear need for even larger, more diverse, and higher-quality multimodal time series datasets that accurately represent real-world complexities, including varying frequencies, variable counts, and distributions [14]. These datasets should go beyond synthetic samples, supporting diverse reasoning structures and enabling comprehensive evaluation of multimodal forecasting models [32]. While existing surveys provide an overview of current multimodal datasets, the emphasis remains on the need for continued development and their utilization in robust benchmarking [6].

Finally, establishing standardized protocols is paramount for fostering transparent and comparable research outcomes. This includes conducting comprehensive evaluations against diverse baselines, across various time series tasks, and with varied data modalities and zero-shot/few-shot scenarios [12]. Rigorous ablation studies are essential to identify the true sources of performance in LLM-based time series models, comparing them not only to traditional methods but also to simpler architectural components [4,9,15]. Meticulously constructed validation sets are crucial for model tuning and assessing generalization capabilities, especially considering the "inherent diversity and scope of application scenarios" in time series [2,28]. Standardized protocols should incorporate practical validation for specific application contexts, accounting for data distribution differences, and could involve dynamic benchmarking frameworks that assess model performance under varying degrees of data scarcity and distribution shifts [22]. The rigorous evaluation methodology demonstrated by models like TimeGPT, which includes testing on numerous unseen time series and using normalized, scale-independent metrics against a seasonal naive baseline, sets an important precedent for addressing prior criticisms of inconsistent evaluation [26]. Moreover, evaluation protocols must specifically test the resilience of LLMs to different training and alignment procedures, ensuring that benchmarks accurately assess numerical fidelity and extrapolation capabilities rather than solely focusing on general linguistic prowess or model size [5]. This will require designing new metrics and test cases to uncover subtle performance discrepancies and establish clear guidelines for LLMs' effective contribution to time series analysis [5,18]. Dedicated evaluation metrics should examine both the accuracy of results and the underlying reasoning processes, moving beyond simple metrics and contexts to provide comprehensive multi-task analysis frameworks [17,31,32].
### 11.3 Enhancing Interpretability and Responsible AI
The integration of Large Language Models (LLMs) into time series analysis necessitates a strong emphasis on enhancing interpretability and fostering responsible AI development, particularly given the inherent "black box" nature of these complex models [20]. Moving beyond mere predictions, the goal is to provide quantifiable insights for domain experts and ensure trustworthiness in critical applications.

A primary focus for future research involves the development of strategies to improve the interpretability of LLM-based time series systems. The challenge lies in understanding how LLMs process information and arrive at their predictions, especially when dealing with subtle anomalies or complex numerical sequences [5,17]. Researchers are calling for a deeper theoretical understanding of LLM operations on numerical data to improve their interpretability [31]. While some LLM applications, such as direct prompting and visual methods, already offer good interpretability, and models like Auto-TTE can generate interpretable ECG classifications [30], there is a critical need for advanced Explainable AI (XAI) techniques tailored specifically for LLM-time series models [2].

Several approaches are being explored to achieve this enhanced interpretability. One promising avenue is the generation of explainable time series prediction results in textual form by LLMs, with projects like "Temporal Data Meets LLM" explicitly aiming to address model result explanation [7,12,16]. However, these explanations must be robust, accurate, and trustworthy, particularly in sensitive contexts [16]. Beyond textual outputs, research is advancing in creating inherently interpretable models or developing sophisticated tools to illuminate their decision processes. Examples include "Self-Interpretable Time Series Prediction with Counterfactual Explanations," which aims to develop models that inherently generate actionable explanations, crucial for high-stakes domains such as healthcare and autonomous driving [28]. Visualization frameworks like "TimeTuner" also provide essential tools for analyzing model behavior and understanding underlying mechanisms [28]. Furthermore, studies like "Optimal Information Retention for Time-Series Explanations" and "Timing: Temporality-Aware Integrated Gradients for Time Series Explanation" are defining a path towards more robust and human-centric XAI, offering transparent insights into complex model decisions [35]. Efforts are also directed at "Shedding Light on Time Series Classification using Interpretability Gated Networks" and "Investigating Pattern Neurons in Urban Time Series Forecasting," focusing on designing models that are intrinsically more understandable or provide clear insights into their decision-making processes [21].

In parallel with interpretability, fostering responsible AI development is paramount. This involves proactively addressing ethical implications, particularly in sensitive fields where LLMs are deployed. Future research should prioritize "responsible" LLM-assisted enhancers that consider both efficiency and ethical implications [2]. A critical component of responsible AI is robust privacy protection. Strategies include exploring model customization to tailor LLMs for different users while implementing strong privacy mechanisms, especially for sensitive data like medical records [31,32]. Research into "Privacy Amplification by Structured Subsampling for Deep Differentially Private Time Series Forecasting" signifies ongoing efforts to build privacy-preserving time series models for sensitive data domains [35].

Beyond privacy, responsible AI development also encompasses bias mitigation and robust accountability frameworks. Ensuring the trustworthiness of LLM forecasts requires enhancing their ability to adapt to uncertainty, provide reliable confidence intervals, and mitigate issues such as "hallucinations" and inconsistent outputs [11,18]. The use of conformal prediction, as seen in TimeGPT, offers transparent risk assessment and helps users understand the confidence level of predictions, which is essential for high-stakes decision-making [26]. Overall, the aim is to develop multi-modal LLMs (MLLMs) for time series that ensure results are "trustworthy and actionable" by championing trustworthy, interpretable, and robust reasoning [32]. This holistic approach to interpretability and responsible AI is crucial for the successful and ethical deployment of LLMs in diverse time series applications.
### 11.4 Adapting to Dynamic Time Series Environments
The inherent dynamism of real-world time series, characterized by non-stationarity, concept drift, and unpredictable fluctuations, presents a significant challenge for existing models, necessitating mechanisms for continuous learning and rapid adaptation without extensive retraining [2,14,34]. Future research is crucial for enabling large language models (LLMs) to intrinsically adjust to evolving patterns and contexts, ultimately fostering a "general time series analysis intelligence" [2].

A primary research avenue focuses on enhancing model robustness against **non-stationarity and concept drift**. Current efforts include leveraging decomposition techniques, such as TEMPO's combination of seasonal and trend decomposition with frozen LLMs to manage distributional shifts [2]. Similarly, PatchInstruct utilizes time series decomposition to separate stable components from residuals, although future work could explore dynamic decomposition methods that adapt to evolving seasonal patterns or trend shifts [24]. Other advancements include RevIN for distribution shifts within the LLM4TS framework [25], GBT's two-stage framework for non-stationary series, and "Transferable Time-Series Forecasting under Causal Conditional Shift" for domain adaptation [28]. Sundial's "Re-Normalization" mechanism also addresses time distribution shifts and outlier ranges [29]. Despite these foundational steps, the field requires further exploration into more sophisticated adaptive mechanisms within foundation models [29].

To achieve rapid adaptation, a central theme is the development of **continuous learning, online adaptation, and meta-learning strategies**. These approaches aim to update model parameters efficiently in dynamic environments without requiring full retraining [14,28]. Specific suggestions include integrating online learning or prompt updates based on recent performance to manage concept drift [24], and exploring continuous learning within frameworks like LLM4TS to handle severe concept drift and real-time data streams [25]. Papers such as "Lightweight Online Adaption for Time Series Foundation Model Forecasts" and "Fast and Slow Streams for Online Time Series Forecasting Without Information Leakage" explicitly advocate for efficient, lightweight online adaptation in dynamic, real-time settings [21,35]. The implicit sensitivity of models like TimeGPT to "distribution differences" further underscores the necessity for such flexible adaptation mechanisms [22]. Additionally, the development of "self-correction mechanisms" is deemed essential for improving the robustness of time series reasoning with multimodal LLMs [32].

Another critical challenge is **effective long context window handling and the capture of long-range temporal dependencies**. LLMs often face performance degradation with longer time series, struggling with information loss and subtle anomalies over extended periods [17,30]. Research must focus on improving mechanisms within Transformer architectures or exploring alternative sequence models to retain information from very long time series without significant loss [14]. Innovations such as Moirai's variable-length input strategy and varied patch sizes [14], and Sundial's use of FlashAttention and KV Cache for efficient "real-time long-context inference and long-term generation" [29], represent initial steps. While "state-of-the-art results in long-term forecasting" demonstrate progress [23], further investigation into memory mechanisms or more efficient encoding strategies is needed to overcome context window limitations and allow LLMs to incorporate longer historical sequences for better adaptation to non-stationarity in dynamic environments like macroeconomics [18].

Furthermore, enhancing **model robustness and generalization ability against noise, outliers, and irregular data** is paramount [31]. This includes adapting to varying data granularities and irregular sampling rates, as well as handling "不规则时间序列" (irregular time series) [21,25,35]. For instance, "Amortized Control of Continuous State Space Feynman-Kac Model for Irregular Time Series" highlights progress in this area [21]. The diverse pre-training of models like TimeGPT on various patterns, seasonalities, cycles, trends, noise, and outliers serves as a foundational approach to bolstering adaptability [26]. Finally, developing efficient algorithms for large-scale time series data and enabling real-time processing and interactive capabilities for LLMs will be essential for practical applications in dynamic settings [31]. The overarching goal is to achieve architectural and methodological innovations that genuinely enable LLMs to robustly model the ordered and dynamic nature of time series data, addressing current limitations in capturing sequential dependencies [15].
### 11.5 Cross-Disciplinary Synergies and Beyond
The long-term vision for Large Language Models (LLMs) in time series analysis transcends traditional forecasting, aiming towards a "general time series analysis intelligence" [2,14]. This ambitious goal, analogous to Artificial General Intelligence (AGI) in broader AI contexts, necessitates profound cross-disciplinary synergies and advanced integration with other AI paradigms to push the boundaries of time series analysis.

LLMs have already demonstrated substantial potential across a diverse array of domains, including finance, healthcare, transportation, AIOps, human mobility, IoT, climate, and audio analysis [7,12]. This broad applicability highlights a future direction where LLMs' capabilities are extended through deep integration with domain-specific knowledge. A critical aspect of achieving general intelligence is the fusion of diverse data types and modalities. Future models are envisioned to integrate images, text, structured data, and even video, enabling richer multimodal analysis [11,30]. This includes leveraging domain-specific textual knowledge alongside numerical data, as exemplified by financial sentiment analysis tools like Instruct-fingpt and health inference models like Few-Shot Health Learners and METS [12,16]. Moreover, the integration of statistical domain knowledge, such as seasonal decomposition and autocorrelation analysis, is proposed to enhance LLM performance in specialized fields [31]. The ability for models to transfer knowledge effectively between different domains is a promising avenue for broad applicability, leveraging both similarities and differences across diverse time series contexts [30,31].

Moving beyond conventional numerical forecasting, the research trajectory emphasizes LLMs' potential for higher-level contextual understanding and symbolic reasoning. Tasks such as time series reasoning and social understanding, which inherently involve complex interactions between language and temporal data, are identified as areas where LLMs can genuinely excel [4,8]. This involves inferring causal relationships, dynamic interdependencies, and latent structures within time series data [14]. Causal discovery and reasoning are emerging as active research areas, exemplified by studies on identifying causal relationships in multivariate time series and generating hypotheses of dynamic causal graphs [21,35]. This suggests a future where LLMs' advanced reasoning capabilities could be leveraged to uncover complex temporal relationships, moving beyond mere correlation to understanding underlying mechanisms.

To realize this ambitious vision, a significant research trajectory involves the development of multi-agent systems. In this paradigm, LLMs serve as orchestrators, coordinating specialized time series models, external tools, and knowledge bases to address complex problems [30,31]. This approach facilitates a more holistic and adaptable solution for complex time series analysis, integrating diverse functionalities under a unified LLM control. Furthermore, hybrid systems are being explored that combine the strengths of multimodal LLMs (e.g., visual processing) with specialized time series analysis tools to compensate for reasoning weaknesses in tasks like anomaly detection [17]. The integration of Graph Neural Networks (GNNs) with LLMs, as demonstrated by models like TIMEGNN, SageFormer, and MAGNN, further exemplifies such synergy, enabling robust modeling of spatial and temporal relationships in multivariate time series [28].

The path toward "general time series AGI" requires a sustained commitment to interdisciplinary exploration [2]. This includes the creation of truly multimodal and multitemporal foundation models, encompassing time series embeddings and classification foundation models [26]. Architectural innovations that move beyond surface-level interpretations to infer deeper causal insights are also crucial, potentially leveraging advancements in neuro-symbolic AI [14]. The ultimate aim is to move beyond academic benchmarks towards broader applicability and seamless integration into real-world production systems, as highlighted by Chronos's potential [19]. This trajectory points towards achieving "universal predictive analysis" and knowledge transfer across diverse domains, striving for models analogous to unified models in NLP and Computer Vision for long-term time-series forecasting, by leveraging cross-disciplinary insights and architectural innovations [13,23].
## 12. Conclusion
The integration of Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) into time series analysis marks a significant paradigm shift, moving the field towards more flexible, scalable, and intelligent systems [2,32]. This interdisciplinary convergence has generated substantial progress, leveraging LLMs' inherent capabilities in processing diverse data types, adapting to dynamic changes, and generating interpretable textual explanations, thereby addressing long-standing limitations of traditional, task-specific time series models [2,12].

Significant advancements have been made in adapting LLMs for time series tasks. Novel strategies such as reprogramming frameworks like Time-LLM, which repurposes frozen LLMs for general time series forecasting by aligning data with text prototypes [1], and innovative prompt-based learning approaches like PatchInstruct, which uses patch-based prompting and decomposition to bridge the numerical-text modality gap with minimal preprocessing [24], have demonstrated enhanced forecasting quality. Furthermore, advanced fine-tuning methodologies, exemplified by LLM4TS's two-stage fine-tuning with time-series patching and temporal encoding, have achieved state-of-the-art results and robust few-shot learning capabilities by effectively transferring knowledge from pre-trained LLMs [23,25]. These methods enable LLMs to serve as robust representation learners, especially valuable in scenarios with limited time series data [23]. The burgeoning field has also seen the classification of integration strategies into categories such as Direct Prompting, Time Series Quantization, Alignment, Vision as Bridge, and Tool integration, indicating a systematic effort to bridge the fundamental text-numerical modality gap [6,31].

A pivotal development has been the emergence of native time series foundation models (TSFMs) such as TimeGPT, Sundial, Chronos, and Lag-Llama [12,14,19,26,29]. These models, often Transformer-based and pre-trained on massive, diverse time series datasets (e.g., TimeBench, 100 billion data points for TimeGPT), exhibit impressive zero-shot and few-shot forecasting capabilities, democratizing and enhancing time series analysis by reducing the need for extensive task-specific training [3,10,22,29]. Sundial, for instance, introduces the TimeFlow Loss for native pre-training on continuous-valued time series, facilitating generative probabilistic forecasting [29]. This shift enables advanced applications like few-shot anomaly detection, multi-task scalable time series analysis, and imputation [20]. Furthermore, the conceptualization of LLMs within time series analysis ranges from **LLM-Assisted Enhancers** (improving data interpretability and model performance) and **LLM-Centric Predictors** (directly performing tasks) to **LLM-Empowered Agents** (orchestrating complex analysis), outlining a comprehensive framework for their application [2].

Despite this progress, significant challenges persist. A prominent concern is the inherent modality gap between text-centric LLMs and numerical time series data, which often leads to inconsistent performance and necessitates specialized adaptation techniques [2,12,30,31]. Several studies critically evaluate the effectiveness of current LLM-based methods for direct numerical forecasting, concluding that they frequently underperform or merely match simpler baselines while incurring disproportionately high computational costs in terms of parameters, training, and inference time [4,8,9,15,18]. This suggests that the perceived performance often stems from basic encoding structures like patching and attention mechanisms rather than the LLM's inherent pre-trained language knowledge or advanced reasoning capacities [4,8,15]. For instance, a joint multimodal forecaster (Hybrid-MMF) incorporating a Llama 3.1 LLM, while showing that textual embeddings can enhance numerical predictions, did not consistently outperform unimodal baselines for numerical forecasting, highlighting the complexities of truly effective multimodal fusion [34]. Additionally, LLMs exhibit limitations in numerical precision, struggle with quantifying uncertainty, and can be sensitive to prompt wording, as observed in macroeconomic forecasting [18]. Their reasoning capabilities for tasks like anomaly detection are also limited, often showing a "visual advantage" when data is presented as images rather than raw numerical sequences, and struggling with subtle anomalies or longer input sequences [17]. Moreover, the impact of LLM alignment processes (e.g., RLHF) on precise numerical tasks can be detrimental, with newer models sometimes performing worse than older versions [5].

Looking ahead, the future trajectory of this interdisciplinary field demands concerted research efforts to address these challenges and fully unlock the potential of LLMs for time series analysis. Future work must focus on developing larger and more diverse multimodal datasets, improving multimodal fusion techniques, and gaining a deeper theoretical understanding of the interplay between different data modalities [20,34]. Research should pivot towards leveraging LLMs for higher-level time series reasoning and understanding tasks, where their unique capabilities can be more effectively utilized, rather than merely adapting them for direct numerical prediction [4,8,15]. Key directions include enhancing numerical representation, improving multimodal integration, and developing more robust context handling mechanisms to overcome current limitations with long input sequences [17,30]. Furthermore, the field needs to establish standardized evaluation protocols for foundation models, investigate the integration of domain knowledge, ensure model customization and privacy, and enhance robustness and generalization for dynamic time series environments [12,31,35]. By systematically addressing these challenges and pursuing these identified future directions, the community can pave the way for a more robust and versatile "general time series analysis intelligence" [2].

## References

[1] Time-LLM: 利用LLM进行时间序列预测 [https://research.ibm.com/publications/time-llm-time-series-forecasting-by-reprogramming-large-language-models](https://research.ibm.com/publications/time-llm-time-series-forecasting-by-reprogramming-large-language-models) 

[2] LLM在时间序列分析中的潜力与应用 [https://www.cnblogs.com/zhangdoudou/p/18277709](https://www.cnblogs.com/zhangdoudou/p/18277709) 

[3] TimeGPT：驱动时序分析的生成式预训练模型 [https://www.ewbang.com/community/article/details/1000232865.html](https://www.ewbang.com/community/article/details/1000232865.html) 

[4] LLM在时序预测中表现不佳：研究揭示其局限性 [https://36kr.com/p/2849256434354821](https://36kr.com/p/2849256434354821) 

[5] LLMTime: LLMs for Zero-Shot Time Series Forecasting [https://github.com/naveen-mysore/llmtime](https://github.com/naveen-mysore/llmtime) 

[6] LLM赋能时间序列分析：现状与未来 [http://www.paperreading.club/page?id=207265](http://www.paperreading.club/page?id=207265) 

[7] 时空序列与 AIOps 的 LLM/LM/FM 资源大全 [https://github.com/shuowang-ai/Awesome-TimeSeries-SpatioTemporal-LM-LLM](https://github.com/shuowang-ai/Awesome-TimeSeries-SpatioTemporal-LM-LLM) 

[8] LLM时序预测表现不佳，推理能力未被有效利用 [https://mp.weixin.qq.com/s?__biz=MzI4MDYzNzg4Mw==&mid=2247563947&idx=2&sn=8db5b06e467d81dc6b2e54c65736ff75&chksm=ea8eae2341423ea6bb9bb5ab9a74cb62af1772fa9d8c821299636e0de386f0a700252693e185&scene=27](https://mp.weixin.qq.com/s?__biz=MzI4MDYzNzg4Mw==&mid=2247563947&idx=2&sn=8db5b06e467d81dc6b2e54c65736ff75&chksm=ea8eae2341423ea6bb9bb5ab9a74cb62af1772fa9d8c821299636e0de386f0a700252693e185&scene=27) 

[9] LLM用于时序预测：研究揭示其局限性与有效性 [https://roll.sohu.com/a/791020903_129720](https://roll.sohu.com/a/791020903_129720) 

[10] 基于Transformer和LLM的金融时间序列预测 [https://github.com/UVA-MLSys/Financial-Time-Series](https://github.com/UVA-MLSys/Financial-Time-Series) 

[11] 时序分析的多模态大模型概览 [https://github.com/mllm-ts/Awesome-Multimodal-LLMs-Time-Series](https://github.com/mllm-ts/Awesome-Multimodal-LLMs-Time-Series) 

[12] 大模型+时间序列：15篇高分论文必看！ [https://www.bilibili.com/read/cv27602026](https://www.bilibili.com/read/cv27602026) 

[13] LLM4TS：利用预训练LLM进行两阶段时间序列预测 [https://readpaper.com/paper/1919773528159168768](https://readpaper.com/paper/1919773528159168768) 

[14] 大模型处理时间序列：进展与基础模型展望 [https://www.zhihu.com/question/649649951/answer/1939298967692227876](https://www.zhihu.com/question/649649951/answer/1939298967692227876) 

[15] 大语言模型在时序建模中是否“鸡肋”？ [https://imgtec.eetrend.com/blog/2025/100590159.html](https://imgtec.eetrend.com/blog/2025/100590159.html) 

[16] 大模型+时间序列：15篇高分论文速览 [https://www.bilibili.com/read/mobile/27602026](https://www.bilibili.com/read/mobile/27602026) 

[17] ICLR 2025：LLMs理解时间序列异常能力研究——视觉优势与推理局限 [https://baijiahao.baidu.com/s?id=1827624616561349104&wfr=spider&for=pc](https://baijiahao.baidu.com/s?id=1827624616561349104&wfr=spider&for=pc) 

[18] LLMs vs. Traditional Methods: Macroeconomic Forecasting Accuracy [http://www.paperreading.club/page?id=277003](http://www.paperreading.club/page?id=277003) 

[19] Chronos：用 Fatir Ansari 学习时间序列语言 [https://twimlai.com/go/685/](https://twimlai.com/go/685/) 

[20] LLM赋能时序数据分析：直播研讨会 [https://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&mid=2247691579&idx=3&sn=bfee7a287ca8cb192a700549370b19a0&chksm=e898b7b6dfef3ea01bdd8912b2401a382eaa7b7b5dc939a92071b04c5659c0199683f619a9e3&scene=27](https://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&mid=2247691579&idx=3&sn=bfee7a287ca8cb192a700549370b19a0&chksm=e898b7b6dfef3ea01bdd8912b2401a382eaa7b7b5dc939a92071b04c5659c0199683f619a9e3&scene=27) 

[21] ICLR 2025 时间序列高分论文精选 (32篇) [https://cloud.tencent.com/developer/article/2479221](https://cloud.tencent.com/developer/article/2479221) 

[22] TimeGPT在稀疏历史数据负荷预测中的应用 [https://www.sciencedirect.com/science/article/pii/S0306261924023572](https://www.sciencedirect.com/science/article/pii/S0306261924023572) 

[23] LLM4TS: LLMs Two-Stage Fine-Tuning for Time-Series Forecasting [https://zhuanzhi.ai/paper/aa8cc5af54acbd7c0b2337ee1fb6b8e9](https://zhuanzhi.ai/paper/aa8cc5af54acbd7c0b2337ee1fb6b8e9) 

[24] PatchInstruct: LLMs进行时间序列预测的块状提示法 [http://www.paperreading.club/page?id=316721](http://www.paperreading.club/page?id=316721) 

[25] LLM4TS: 利用预训练LLM进行数据高效时间序列预测 [https://arxiv.org/html/2308.08469v4](https://arxiv.org/html/2308.08469v4) 

[26] TimeGPT：首个时间序列基础大模型 [https://cloud.tencent.com/developer/article/2379848](https://cloud.tencent.com/developer/article/2379848) 

[27] AI for Time Series (AI4TS) 论文、教程与综述 [https://github.com/qingsongedu/awesome-AI-for-time-series-papers](https://github.com/qingsongedu/awesome-AI-for-time-series-papers) 

[28] 时间序列预测最新研究进展 [https://www.zhihu.com/question/31833683/answer/3287697903](https://www.zhihu.com/question/31833683/answer/3287697903) 

[29] Sundial：原生、灵活、可扩展的时间序列基础模型家族 [https://blog.csdn.net/qq_41185868/article/details/148965119](https://blog.csdn.net/qq_41185868/article/details/148965119) 

[30] LLMs 在时间序列分析中的应用：方法与案例 [https://blog.csdn.net/sinat_26917383/article/details/151331357](https://blog.csdn.net/sinat_26917383/article/details/151331357) 

[31] AI论文速读 | LLM4TS：大语言模型用于时间序列分析综述 [https://cloud.tencent.com/developer/article/2466763](https://cloud.tencent.com/developer/article/2466763) 

[32] 多模态大模型赋能时间序列推理：新范式与研究方向 [https://cloud.tencent.com.cn/developer/article/2497402](https://cloud.tencent.com.cn/developer/article/2497402) 

[33] 刘淇教授：数据科学与认知智能领域的领军者 [http://staff.ustc.edu.cn/~qiliuql](http://staff.ustc.edu.cn/~qiliuql) 

[34] 多模态预测：联合时间序列与文本数据 [https://arxiv.org/html/2411.06735v2](https://arxiv.org/html/2411.06735v2) 

[35] ICML 2025 时间序列论文总结 [https://blog.csdn.net/sinat_37574187/article/details/148057984](https://blog.csdn.net/sinat_37574187/article/details/148057984) 

