# A Survey on LLM-based Multi-Agent

# 0. A Survey on LLM-based Multi-Agent

## 1. Introduction
Large Language Models (LLMs) represent a significant advancement in artificial intelligence, demonstrating exceptional capabilities in understanding, generating, and reasoning with natural language [18]. Originating from the Transformer architecture, LLMs have transformed tasks from text generation and summarization to complex reasoning, embodying a potential pathway toward Artificial General Intelligence (AGI) through their ability to perceive environments, plan solutions, and execute actions [18,21,22]. Concurrently, Multi-Agent Systems (MAS) involve the collaborative work of multiple autonomous agents to solve complex problems that are beyond the scope of a single agent [14,28]. Agents, defined as entities capable of perceiving their environment and taking actions, have long been a focus in intelligent systems research, traditionally dominated by reinforcement learning (RL)-based approaches for simpler, well-defined tasks [16].

The convergence of LLMs and MAS marks a new paradigm for addressing intricate challenges, highlighting revolutionary changes brought about by their integration [25]. This synergy is driven by the unique capabilities LLMs offer, particularly their potential in reasoning and planning, which aligns with human expectations for intelligent agents operating in interactive environments [16,19]. LLM-based agents have shown significant strides in interacting with complex environments and solving intricate tasks across diverse applications, akin to human societal engagement [16].

Despite their individual strengths, both single LLM agents and traditional multi-agent systems exhibit inherent limitations. Single LLM agents, while powerful, can struggle with issues such as hallucination, difficulty with complex or abstract concepts, and limitations in context retention, often operating within isolated environments with fixed decision paths [4,18,21]. Traditional multi-agent systems, conversely, have faced limitations in natural language understanding and generation, adaptability, and managing complexity, often being restricted to performing simple, well-defined actions [9,16,28].



![Synergy of LLMs and Multi-Agent Systems](https://modelbest-prod.oss-cn-beijing.aliyuncs.com/SurveyGo/picture/-WWv2bfyw30P8hsq-FO3t_/home/surveygo/data/requests/13542/survey/imgs/Synergy%20of%20LLMs%20and%20Multi-Agent%20Systems.png)

The multi-agent paradigm powered by LLMs effectively overcomes these limitations by leveraging the collective intelligence of multiple specialized agents [3,19]. This approach emphasizes key benefits such as enhanced collaboration, specialization, and superior problem-solving capabilities [2,10]. LLM-based multi-agent systems enable agents with distinct identities to engage in sophisticated communication and collaboration to achieve complex task objectives, mirroring human teamwork and allowing for a more effective simulation of real-world environments [3,16,19]. The ability of these systems to engage in debate and reflection among agents leads to improved decision-making, particularly for tasks requiring deeper reasoning or specialized skills, thus enhancing professional knowledge, robustness, reliability, and adaptability [2,13,18,26]. By orchestrating multiple agents, LLM-MAS can address complex problems where single LLMs fall short, offering a distributed computing mode that facilitates accurate conclusions through discussion, inspection, reasoning, and evaluation [10,13].

Given the rapid advancements and increasing interest in this dynamic field, this survey aims to provide a comprehensive overview of LLM-based multi-agent systems, identifying current challenges, and exploring future research directions [2,3,19]. We will delineate the fundamental concepts, analyze the latest research trends, and discuss various applications of LLM-based multi-agent systems, thereby establishing a comprehensive understanding and guiding future explorations in this promising domain.
## 2. Foundations of LLM-based Multi-Agent Systems
Large Language Models (LLMs) represent a significant advancement in artificial intelligence, primarily characterized by their ability to process and understand natural language [17,27]. These models, such as GPT-4.1, Llama3.3-70B, Qwen3-32B, Gemma3-27B, and Qwen2.5-32B, are trained on vast datasets, enabling them to exhibit capabilities in natural language understanding, generation, and complex reasoning [4,5,15,25]. Their architecture, typically based on the Transformer model, enables effective capture of long-range dependencies in sequential data, which is crucial for sophisticated language tasks.

Core capabilities of LLMs that are highly relevant to intelligent agents include:
* **Decision-Making and Reasoning**: LLMs can break down intricate tasks into manageable sub-goals, systematically reason through each component, and learn from prior experiences to optimize decision-making processes [3,7,19]. This capability is often enhanced through prompting techniques and allows for sophisticated planning and problem-solving [14,17,23].
* **Tool Use**: LLM-based agents can extend their functionalities by integrating and utilizing external tools and resources, thereby expanding their operational scope and effectiveness in diverse environments [3,4,14,19,23].
* **Memory**: LLMs incorporate memory mechanisms essential for maintaining context and learning from interactions. This includes both short-term memory (context learning) and long-term memory, which can be facilitated by external vector databases and Retrieval-Augmented Generation (RAG) techniques to preserve and retrieve information over extended periods [3,4,14,19,22,23].

These capabilities collectively enable LLMs to serve as the foundation for intelligent agents, providing environmental awareness, perception, planning, and continuous learning to enhance performance and decision-making [14,23].

Multi-Agent Systems (MAS) represent a paradigm where multiple intelligent agents interact to solve problems that are difficult or impossible for a single agent to solve [16]. In computer science, an agent is defined as a computational entity that perceives its environment through sensors and acts upon it through effectors [27]. Agents are characterized by fundamental properties:
* **Autonomy**: Agents can operate independently, making decisions and executing actions based on their internal state and perceptions without direct human intervention [16,21,25,27].
* **Reactivity**: Agents respond to changes in their environment in a timely manner [21,27].
* **Proactiveness**: Agents exhibit goal-directed behavior, taking initiative to achieve their objectives rather than merely reacting to environmental stimuli [21,27].
* **Social Ability**: Agents can interact, communicate, and engage in cooperation or competition with other agents to achieve collective goals [16,21,25,27].

Traditional MAS are designed around principles of distributed problem-solving, aiming for enhanced adaptability and the emergence of complex behaviors [25]. They comprise individual entities with specific characteristics and states that adaptively behave according to their context and environment, making decisions and taking actions [17]. Agent architectures vary significantly, encompassing both homogeneous agents that perform similar tasks and heterogeneous agents that collaborate based on their specialized abilities and expertise, enabling flexible adaptation to diverse task requirements [16].

Communication is a cornerstone of MAS, dictating how agents exchange information and coordinate their actions. Communication protocols can range from simple message-based systems to more complex blackboard systems [16]. Furthermore, communication structures are categorized into types such as decentralized, centralized, layered, or nested, specifically designed to suit various task requirements and environmental conditions [16]. Coordination mechanisms are crucial for managing these interactions, with approaches often drawing from control theory and reinforcement learning (RL), where agents learn optimal strategies through environmental interaction [16]. Multi-agent reinforcement learning (MARL) further distinguishes algorithms based on dimensions such as task patterns, agent types, learning styles, and knowledge sharing [16]. Despite their strengths in simulating complex social interactions and teamwork, traditional MAS often face challenges such as non-stationary environments, the complexities of multi-objective training, and increased difficulty in training and evaluation compared to single-agent systems [26].



**Core Elements of LLM-based Multi-Agent Systems**

| LLM Core Capabilities for Agents    | Multi-Agent System (MAS) Properties |
| :---------------------------------- | :---------------------------------- |
| **Decision-Making & Reasoning**: Break down tasks, reason through components, learn from experience, planning. | **Autonomy**: Operate independently, make decisions without human intervention. |
| **Tool Use**: Integrate and utilize external tools and resources. | **Reactivity**: Respond to environmental changes in a timely manner. |
| **Memory**: Maintain context, learn from interactions (short-term, long-term, RAG). | **Proactiveness**: Exhibit goal-directed behavior, take initiative. |
| **Natural Language Processing**: Understanding, Generation, Reasoning. | **Social Ability**: Interact, communicate, cooperate/compete with others. |

The emergence of LLM-based multi-agent systems signifies a profound synergy, integrating the advanced linguistic and reasoning capabilities of LLMs with the distributed, collaborative framework of traditional MAS [16,19]. LLMs serve as the core component of autonomous AI agents, significantly expanding their perception and action spaces through multi-modal capabilities and sophisticated tool utilization [14,21]. This integration directly addresses several limitations inherent in both traditional MAS and standalone LLMs:

* **Enhanced Communication and Interaction**: LLMs' powerful natural language understanding and generation capabilities enable more complex, flexible, and human-like interactions among agents. This facilitates improved communication, richer information exchange, and more sophisticated coordination mechanisms compared to conventional rule-based or symbolic methods [10,16,25]. Agents can now communicate high-level concepts and even generate structured outputs such as documentation and diagrams [5].
* **Improved Decision-Making and Problem-Solving**: By leveraging LLMs for reasoning, planning, and knowledge application, LLM-based agents can achieve deeper task understanding, dynamic role assignment, and more effective problem-solving in complex, dynamic environments [10,16,25]. This enables the system to decompose, allocate, and execute complex tasks more efficiently through agent collaboration [10].
* **Overcoming LLM Limitations**: While powerful, single LLMs have limitations such as knowledge confined to their training data, restricted context windows, and difficulty handling multiple roles simultaneously [14]. Multi-agent architectures built upon LLMs overcome these by distributing cognitive loads, facilitating knowledge sharing, and enabling specialized roles for different LLM agents, effectively mimicking cognitive synergy [14]. For instance, graph representations, such as $G(V, E)$ where $V$ is the node set representing LLM-based agents $V_i$ and $E$ is the edge set representing message transmission $E_{ij}$ between agents $V_i$ and $V_j$, can model intricate relationships among multiple LLM-based agents [16].
* **Flexible and Adaptive Systems**: LLM-based MAS can adapt more flexibly to different task requirements and environmental changes, promoting complementarity and synergy among agents [16]. This is evident in applications like the intelligent verification of planning templates, where open-source LLMs form the foundation of the multi-agent architecture to enhance processing and analysis efficiency [13]. The ability to simulate social interactions and teamwork through LLMs, moving beyond predefined rules, enhances the understanding of complex social dynamics and emergent coordination, even under constraints like limited local perception [8,9].

This powerful combination enables LLM-MA systems to address more dynamic and complex tasks, emphasizing diverse agent configurations, inter-agent interactions, and collective decision-making processes [16,19].
## 3. Architectures and Frameworks for LLM-based Multi-Agent Systems

**Key Frameworks for LLM-based Multi-Agent Systems**

| Framework      | Type/Focus          | Key Strengths                                  | Key Limitations/Considerations               |
| :------------- | :------------------ | :--------------------------------------------- | :-------------------------------------------- |
| **LangChain**  | General LLM Dev     | Data processing, tool integration, CoT, large community. | Primarily single-agent, steep learning curve. |
| **LangGraph**  | Workflow Orchestration | Complex task state transition diagrams.        | Steep learning curve.                         |
| **Dify**       | Open-source Platform | User-friendly, strong community support.       | Less flexibility.                             |
| **AutoGen**    | Multi-Agent Dialogue | Flexible interaction, customizability, easy debugging, research-friendly. | Inconvenient deployment, tool limitations.     |
| **CrewAI**     | Multi-role Collab   | "Task collaboration" model, organizational structures. |                                               |
| **MetaGPT**    | Workflow Automation | Embeds human workflows/SOPs, role specialization, covers SDLC. |                                               |
| **CAMEL**      | Agent Collaboration | "Initial prompt" technique, guides dialogue.   |                                               |
| **ReDel**      | Recursive MAS       | Supports recursive systems, custom tools, visualization. | Specific niche.                               |
| **Auto-GPT**   | Autonomous Agent    | Planning, memory, tool usage, "plan-execute-self-check-retry". | Stability issues, lacks robust process management. |
| **BabyAGI**    | Task Management     | Automates task creation, prioritization, execution. |                                               |


![LLM-based Agent Architecture and Profile Generation](https://modelbest-prod.oss-cn-beijing.aliyuncs.com/SurveyGo/picture/twJVAAwie-Pcn3wEHXO58_/home/surveygo/data/requests/13542/survey/imgs/LLM-based%20Agent%20Architecture%20and%20Profile%20Generation.png)

The rapidly evolving field of LLM-based Multi-Agent Systems (MAS) necessitates a robust understanding of their foundational architectures and the frameworks that facilitate their construction and deployment. This section provides a comprehensive overview of these critical aspects, dissecting the design principles of individual agents, the intricate mechanisms governing their interactions, and the diverse set of software tools available for their development.

At a high level, the structural organization of LLM-based MAS can be broadly categorized into several paradigms, each presenting distinct trade-offs in terms of scalability, robustness, and coordination complexity [2]. These include **equal-level (flat)** structures, where agents operate on the same hierarchical plane, collaborating or negotiating towards shared or opposing objectives [2]. **Hierarchical** structures, conversely, involve a clear leader-follower dynamic, common in scenarios demanding coordinated efforts under central authority, such as Stackelberg games where decisions are sequential [2]. **Nested (hybrid)** structures combine elements of both equal-level and hierarchical substructures within a single system, allowing for flexible complexity [2]. Furthermore, **dynamic structures** enable roles, relationships, and agent numbers to adapt over time, modifying interaction patterns based on internal states or external context [2]. Understanding these architectural types is crucial for designing systems that balance efficiency with resilience [3].

The efficacy of these multi-agent architectures hinges upon the sophisticated capabilities of their constituent agents. Large Language Models (LLMs) serve as the cognitive core, endowing individual agents with advanced natural language understanding and generation, sophisticated reasoning, strategic planning, effective tool utilization, and robust memory management [11,14,22]. An agent's typical architecture encompasses perception, processing (brain/analysis), and action modules, with memory mechanisms supporting continuous learning and contextual awareness [11,14,21]. Agent design, including meticulous profile generation through contextualized, pre-defined, or learning-based methods, is paramount for customizing traits, actions, and skills to meet specific objectives [16,19].

Beyond individual capabilities, the true power of multi-agent systems lies in their inter-agent mechanisms. These involve diverse communication paradigms such as cooperation, debate, and, in specialized cases, competition [2,26]. Communication predominantly leverages textual messages, but the rise of multi-modal LLMs is enabling richer information perception and exchange [16]. Protocols often include message-passing mechanisms and shared message pools, which significantly enhance communication efficiency by allowing agents to access relevant information without explicit requests [5,31]. The structure of communication, whether hierarchical, decentralized, or centralized, impacts coordination and efficiency, especially in complex tasks requiring dynamic interactions and synchronized actions [8,19]. Effective task decomposition, role assignment, and goal alignment are also critical for achieving collective intelligence and successful collaborative problem-solving [16,19].

The practical realization of these architectural and interaction principles is facilitated by a growing ecosystem of frameworks and toolkits. These range from general-purpose LLM development platforms like LangChain and Dify, which offer foundational capabilities for LLM integration, to specialized multi-agent frameworks such as AutoGen, CrewAI, and MetaGPT [3,6]. Each framework offers unique strengths, whether it's AutoGen's flexible dialogue-based collaboration, CrewAI's emphasis on multi-role task organization, or MetaGPT's approach to embedding human workflow processes directly into agent operations [5,6]. Emerging tools also address specific challenges, such as ReDel for recursive systems or SwarmBench for benchmarking decentralized multi-agent coordination [1,8]. Despite significant progress, a notable challenge remains in developing frameworks that can effectively orchestrate multiple agents to solve complex reasoning tasks, indicating a crucial area for future research and development [18]. This continuous evolution of architectures, inter-agent mechanisms, and supporting frameworks collectively pushes the boundaries of what LLM-based multi-agent systems can achieve [24].
### 3.1 Agent Design and Internal Capabilities
Large Language Models (LLMs) fundamentally serve as the cognitive core for intelligent agents, significantly enhancing their intrinsic capabilities across multiple domains. This integration empowers agents with advanced natural language understanding and generation, sophisticated reasoning abilities, strategic planning, effective tool utilization, and robust memory management [14,22]. For instance, LLMs process messages to generate coherent responses, thereby facilitating natural language understanding and generation within individual agents [25]. In frameworks such as MetaGPT, LLMs are central to enabling agents to perform role-specific tasks, including web searching for product managers and code execution for engineers [5]. Furthermore, LLMs function as the “brain” for agents in contexts requiring decentralized decision-making and action coordination based on limited information [8].

The architecture of an LLM-based agent typically comprises three integral components: the “brain,” perception, and action modules [11]. The “brain” module acts as the agent’s central processing unit, responsible for storing and retrieving information and knowledge, as well as executing complex cognitive functions such as information processing, decision-making, reasoning, and planning [11]. The perception module enables the agent to gather information from its external environment, with capabilities extending beyond conventional text-only inputs to encompass multi-modal data streams, including visual and auditory information [11]. The action module facilitates the agent’s interaction with its environment, allowing it to provide feedback and adapt to dynamic changes through various means, such as generating text output, initiating physical actions, and utilizing external tools [11].

These core components contribute to essential agent characteristics, including reactivity, pro-activeness, social ability, and autonomy [17,26,27]. Reactivity ensures agents can respond swiftly to environmental shifts, often enhanced by multi-modal fusion techniques. Pro-activeness denotes an agent’s capacity for goal-directed actions, directly supported by LLMs’ reasoning and planning prowess. Social ability allows agents to engage in communication with other agents and human users through natural language [26]. Autonomy underscores an agent’s ability to operate and manage its internal state without constant external intervention [17,27].

LLMs significantly enhance the reasoning and planning capabilities of agents. Techniques such as Chain-of-Thought (CoT) prompting allow LLMs to decompose complex tasks into manageable sub-problems [14]. Building upon CoT, Tree of Thoughts (ToT) enables the exploration of multiple reasoning pathways at each step, forming a tree-like decision structure [14]. For more extended and intricate planning, LLM+P integrates an external classical planner, typically leveraging Planning Domain Definition Language (PDDL) [14]. Across various frameworks, LLMs are instrumental in facilitating agents’ reasoning, planning, and decision-making processes [4]. The integration of knowledge graphs further supports these advanced reasoning and planning functions [24].

Memory mechanisms are critical for storing, retrieving, and managing knowledge within agents, enabling continuous learning and context awareness [22]. While specific memory technologies like vector databases or Retrieval-Augmented Generation (RAG) are not explicitly detailed in all provided digests, the functional role of memory is consistently highlighted. For instance, in social network simulations, agents incorporate attention-based memory systems to maintain stable interactions over extended periods [9]. Similarly, agents in certain simulations retain a memory of past interactions to inform future decisions, such as remembering the last 30 interactions to guide resource management and behavioral choices [7]. The broader concept of memory management is also recognized as a key capability for LLM-based agents, supporting reflection and adaptivity [23,24].

The acquisition and improvement of agent capabilities are primarily driven by meticulous agent design and configuration, often involving techniques akin to prompt engineering and fostering adaptivity [17,19]. Agents are defined by their unique traits, actions, and skills, which are customized to meet specific objectives [3,19]. A fundamental aspect of agent design is the meticulous crafting of agent profiles, which define their roles and personal styles, analogous to human personas [16]. These profiles can encompass basic information (e.g., name, age, career), psychological attributes (e.g., emotions, personality, life goals), social relationships, environmental contexts, and behavioral constraints [16].

Different strategies are employed for agent profile generation:
1.  Contextualized Generation Method: This approach involves analyzing and decomposing complex scenarios to define concrete agent roles for specific sub-tasks. For example, in a corporate workflow, distinct agents might be defined for managerial, secretarial, execution, and consulting roles [16]. This method is labor-intensive as it necessitates regenerating profiles for each new scenario, but it ensures optimal alignment with task requirements. Exemplar systems include Generative Agents, MetaGPT, and ChatDev, where identities, occupations, relationships, goals, and constraints are explicitly defined through natural language descriptions [16,21].
2.  Pre-defined Method: Here, LLMs are used to create a broad pool of agents with pre-defined characteristics. Suitable agents are then selected from this pool for specific scenarios. This typically involves crafting prompt rules for profile composition, which LLMs use to generate diverse agents. While this method significantly reduces time for a large number of agents, it may offer less precise control over customization [16,21]. SpeechAgents, for instance, generates seed profiles with background details like age and preferences, and roles can be assigned based on demographic data as seen with GPT-3 [16,21].
3.  Learning-based Method: This dynamic approach starts with broadly defined agents, and new agents are generated by LLMs during task execution, combining existing profiles with specific generation rules. This method offers increased flexibility and efficiency but carries risks of hallucination or profile-task mismatches [16,21]. For example, RecAgent uses ChatGPT to generate additional agent profiles based on an initial set of manually detailed attributes, facilitating a comprehensive and adaptable agent pool [16,21].

Within various frameworks, agents are configured by their assigned roles, the tools they can access, and their specific goals [6]. This customization enables agents to specialize in tasks such as text processing or handling multi-modal data like images and videos [10]. The continuous refinement of these configurations, alongside methods for generating and adapting agent profiles, underpins the evolution of agent capabilities and their effective performance in complex multi-agent systems.
### 3.2 Inter-Agent Mechanisms
Inter-agent mechanisms are fundamental to the operation and effectiveness of multi-agent systems (MAS) built upon Large Language Models (LLMs). These systems hinge on diverse communication paradigms, intricate language protocols, and sophisticated task coordination strategies.

Different communication paradigms significantly influence the performance and behavior of LLM-based multi-agent systems. Cooperation is a primary paradigm where agents with shared objectives collaborate without centralized leadership, emphasizing collective decision-making and shared responsibility [2]. This collaboration greatly enhances the efficiency and accuracy of task processing [10]. Cooperative interactions can be unordered—allowing agents to freely express opinions—or ordered, where agents adhere to specific rules to boost efficiency [11].

Debate is another crucial paradigm, emerging when agents have opposing goals or need to negotiate to reach a solution [2]. Debate and reflection among agents have been shown to improve overall system performance [26]. Frameworks like AgentVerse, AutoAgents, and Dynamic LLM-Agent Network (DyLAN) explore mechanisms that include debate, replaying, and searching strategies for coordination [24]. For instance, in educational scenarios, teaching agents utilize debate—alongside division of labor and collaborative work—to meet specific teaching needs [23]. Similarly, agents engaged in moral dilemmas can discuss their reasoning over discrete rounds to work towards a shared judgment, re-evaluating their positions as the conversation progresses [15].

Competition, though less common in general LLM-based MAS, is vital in specific environments such as predator–prey simulators [29,31] or in scenarios where agents must dynamically adjust strategies based on others’ actions, often incorporating game theory principles to optimize decision-making [11]. Balancing the number of agents with their chosen strategies is crucial for effective collaboration [26], and MAS inherently offers advantages such as fault tolerance, flexibility, and scalability compared to single-agent systems [27].

The types of communication languages and protocols employed are critical for efficiency and reliability. Most LLM-based agent systems predominantly utilize textual messages, capitalizing on LLMs’ exceptional text processing capabilities for information perception and dissemination [16]. This reliance on text enables agents to generate and understand language, forming the basis for interpretable communication both among agents and between humans and agents [17].

For example, the SPADE framework facilitates inter-agent communication by enabling agents to send and process messages using LLMs, which in turn fosters complex natural language interactions through inquiries and responses [25]. Although traditional systems typically used unimodal text, the advent of multi-modal Large Language Models (MLLMs) is ushering in a transition toward multi-modal information perception—similar to the diversity of human sensory acquisition from multiple sources and modalities [16].

Information acquisition by agents encompasses three main message types:
1. Entire Environment Message: Conveys basic environmental information (e.g., scene, layout, atmosphere) that influences agent behavior and can be user-defined, automatically generated, or supplementary background information [16].
2. Interaction Message: Involves information exchanged directly between agents and is determined by task requirements (e.g., dialogue content). These messages are typically autonomous but can be managed by additional LLMs, acting as primary drivers for agent decision-making [16].
3. Self-Reflection Message: Consists of internal messages containing historical, interaction, and environmental data, guiding agent introspection and self-updating to align with task needs [16].

Communication protocols frequently involve message-passing mechanisms, where agents transmit restricted-length messages to one another—a method employed in both predator–prey simulators and collaborative communication platforms [29,31]. Frameworks like AutoGen are designed specifically for multi-agent conversational collaboration, enabling agents to interact and exchange instructions through dialogue [6]. Another critical protocol is the shared message pool, as pioneered by MetaGPT; this publish–subscribe mechanism allows agents to access relevant messages from a common pool without making explicit requests, thereby significantly enhancing communication efficiency by using structured outputs like documents and charts for clarity [5,19,22].

Communication structures can vary:
• Hierarchical communication structures agents in layers, with interactions mostly occurring within or between adjacent levels, as exemplified by the DyLAN framework which promotes dynamic interactions to improve cooperation efficiency [19,22].
• Decentralized communication operates on a peer-to-peer basis, common in world-simulation applications, where agents communicate directly. In these decentralized MAS, local communication is especially critical for coordination and achieving common objectives, as demonstrated in SwarmBench [8].
• Centralized communication involves a central agent coordinating the system’s communications, with other agents interacting exclusively through this node [19,22].

The decomposition of complex tasks into smaller subtasks and the assignment of roles to agents are essential for efficient multi-agent operations. Although specific techniques such as hierarchical task network planning are mentioned indirectly through strategies like division of labor, these approaches are evident when teaching agents assume different educational roles to meet specific needs [23]. Frameworks like CrewAI further support both linear and parallel task collaboration flows, organizing agents into company-like structures for effective task distribution and role allocation [6].

Finally, aligning individual agent goals with overall system objectives and coordinating agent actions is paramount for achieving collective intelligence [19]. Although the literature does not detail specific goal-alignment techniques, the inherent nature of cooperative paradigms—where agents share goals and make joint decisions—implicitly fosters this alignment [2]. Coordination is further enhanced through collaborative frameworks like AgentVerse, AutoAgents, and DyLAN, which focus on dynamic interaction and synchronized actions [24]. Ultimately, the ability of agents to communicate, coordinate, and collectively execute tasks remains a central theme across these inter-agent mechanisms [10,16].
### 3.3 Frameworks and Toolkits
The burgeoning field of LLM-based multi-agent systems necessitates robust frameworks and toolkits to facilitate their development, deployment, and research. These platforms offer varying levels of abstraction, capabilities, and design philosophies, catering to diverse development needs and research objectives [3,6].

Among the foundational frameworks, LangChain serves as a general-purpose toolkit for developing LLM-based applications, supporting functionalities such as data processing, tool integration, and chain-of-thought reasoning [6,23]. While its LangChain Agents primarily follow a single-agent paradigm, they can be extended for more custom behavior, and the framework benefits from a large community and extensive documentation, albeit with a recognized steep learning curve [6,27]. Complementing this, LangGraph, also from the LangChain team, offers powerful process orchestration capabilities, enabling the creation of complex task state transition diagrams for intricate workflows, though it shares a similar steep learning curve [6]. Dify, another open-source platform, integrates model services, knowledge bases, and workflow orchestration through a user-friendly interface, excelling in ease of use and strong community support, yet offering less flexibility compared to more programmatic frameworks [6]. The Qianfan platform extends beyond framework capabilities by providing a comprehensive environment for model building, optimization, and deployment, supporting large-scale model training, multi-agent collaboration, and tool integration [27].

For direct multi-agent system development, several specialized frameworks have emerged, each with distinct features. AutoGen, developed by Microsoft, is a lightweight framework designed for multi-agent dialogue-based collaboration. It supports flexible definitions of interaction modes between agents, including human-computer collaboration, and is known for its high customizability, ease of debugging, and suitability for research and complex system simulation [3,6,19,23,26]. Its architecture enables agents like `ConversableAgent`, `AssistantAgent`, and `UserProxyAgent` to collaborate through chatting to solve tasks, integrating with LLMs, humans, and external tools [26]. However, AutoGen can be inconvenient to deploy and has certain limitations in its tool capabilities [6].

CrewAI focuses on building multi-role collaborative agents through a "task collaboration" model, allowing developers to implement "team-based agent" solutions by creating organizational structures for task assignment. Its strengths lie in its excellent multi-agent architecture abstraction [6]. MetaGPT stands out by embedding human workflow processes and standard operating procedures directly into agent operations, assigning specific roles to agents to reduce hallucinations, and uniquely covering the entire software development process by incorporating human domain knowledge into agent design and protocols [3,5,19]. CAMEL (Communicative Agents for “Mind” Exploration of Large scale language model society) facilitates autonomous agent collaboration through a novel "initial prompt" technique, guiding dialogue agents toward human-aligned goals and serving as a tool for generating and researching dialogue data [3,19].

Other notable frameworks and toolkits address specific aspects of multi-agent development. ReDel is a specialized toolkit for recursive multi-agent systems, a feature not commonly supported by existing tools. It provides custom tool use, various delegation schemes, and enhances debugging and visualization through event-based logging and an interactive web interface with replay capabilities [1]. For experimental prototyping, Auto-GPT serves as a standard example for LLM Agents, demonstrating autonomous task completion with planning, memory, and tool usage through a complex "plan-execute-self-check-retry" loop; however, it has been noted for stability issues and a lack of robust process management [6,27]. BabyAGI is another example focused on task management, automating task creation, prioritization, and execution through collaborative LLM-based agents [10].

Beyond these, several frameworks explore unique collaboration paradigms or research areas: AgentVerse facilitates multi-agent collaboration and emergent behaviors; AutoAgents adaptively generates and coordinates specialized agents; DyLAN offers a strategic method for agent team construction; and LUMOS provides a unified format and modular design for LLM agents [24]. The Cross-Team Collaboration (CTC) framework specifically orchestrates and manages multiple LLM-based agent teams, providing mechanisms for communication, content pruning, and solution aggregation to improve development quality [4]. For social simulation, SALM (Social Agent LM Framework) integrates language models into social network simulations to model long-term social phenomena while maintaining empirically validated behavioral fidelity [9]. The SPADE framework is utilized for building multi-agent systems, often integrated with LLM functionalities via APIs like OpenAI's to enable enhanced natural language interaction [25]. For benchmarking, SwarmBench provides an open and extensible toolkit to evaluate LLMs in swarm intelligence contexts, offering a configurable 2D grid environment and experimental datasets to facilitate reproducible research [8].

Architecturally, concepts like MRKL, HuggingGPT, and API-Bank highlight different approaches to agent design and tool utilization. MRKL (Modular Reasoning, Knowledge and Language) structures agents with expert modules and a large language model acting as a router [22]. HuggingGPT uses ChatGPT as a task planner to select and execute models from the HuggingFace platform [22]. API-Bank is designed to evaluate LLM tool-use abilities by simulating real-world scenarios requiring multi-level decision-making [22].

In summary, the landscape of frameworks and toolkits for LLM-based multi-agent systems is diverse and rapidly evolving. While general frameworks like LangChain provide foundational capabilities for LLM integration, specialized toolkits such as AutoGen and CrewAI focus on different collaboration paradigms, emphasizing customizability and role-based interactions respectively. ReDel carves out a niche for recursive systems, addressing a specific architectural challenge. Dify prioritizes ease of use and accessibility, contrasted by the steep learning curves of more powerful orchestration tools like LangGraph. The challenges of stability (as seen in Auto-GPT) and deployment (noted for AutoGen) remain considerations. The continuous emergence of frameworks like MetaGPT, with its focus on embedding human workflows, and benchmarking tools like SwarmBench, indicates a field actively refining its development methodologies and research practices [1,3,6,27].
## 4. Key Capabilities and Techniques

**Key Planning Frameworks in LLM-based Multi-Agent Systems**

| Planning Framework | Description                                                                         | Key Features                                                                   |
| :----------------- | :---------------------------------------------------------------------------------- | :----------------------------------------------------------------------------- |
| **AdaPlanner**     | Dynamically refines plans based on real-time feedback.                              | In-plan/out-of-plan refinement, skill discovery, adapts to environment.        |
| **ChatCoT**        | Tool-augmented CoT reasoning for chat-based interactions.                           | Alternates tool manipulation & reasoning, adaptable in dynamic conversations. |
| **KnowAgent**      | Integrates action knowledge base with self-learning.                                | Structured action knowledge, mitigates planning hallucinations.                |
| **RAP**            | Enhances planning with retrieval-augmented techniques and contextual memory.        | Leverages relevant past experiences, improves decision-making.                 |
| **Tree of Thoughts (ToT)** | Explores multiple thought sequences as intermediate steps.                       | Multi-path reasoning, comprehensive solution exploration.                     |
| **ReAct**          | Interleaves reasoning traces and task-specific actions.                            | Integrates task execution feedback, interacts with external resources.         |
| **LLM+P**          | Utilizes PDDL as intermediate interface with external classical planners.             | Long-term planning, converts between natural language and PDDL.               |


![LLM-based Multi-Agent Reasoning Techniques](https://modelbest-prod.oss-cn-beijing.aliyuncs.com/SurveyGo/picture/FXz0eQmTJ2ZhFjvYanXCx_/home/surveygo/data/requests/13542/survey/imgs/LLM-based%20Multi-Agent%20Reasoning%20Techniques.png)

LLM-based multi-agent systems signify a paradigm shift in artificial intelligence, fundamentally enhancing the core capabilities of agents beyond those of traditional designs [11,17,24,26]. This advancement is primarily attributable to the intrinsic language understanding, generation, and reasoning abilities of Large Language Models (LLMs), which enable agents to process complex information, adapt dynamically, and engage in more sophisticated interactions. The integration of LLMs empowers agents with heightened reasoning, robust decision-making, adaptive planning, and continuous learning, all of which are further amplified by advanced collaboration mechanisms and external knowledge integration.

Central to these enhanced capabilities is **Reasoning**, where LLMs facilitate human-like thought processes through structured approaches like Chain-of-Thought (CoT) and Tree of Thoughts (ToT), enabling the decomposition of intricate problems into manageable steps and exploring multiple reasoning paths [11,14,22,23]. Beyond individual reasoning, LLMs empower agents with self-correction techniques (e.g., CoT-Self-Consistency) and foster collective reasoning through interaction and debate, significantly boosting accuracy and problem-solving in complex scenarios [4,11,18,29,31]. LLM-based agents also leverage diverse logical reasoning forms, including deductive, inductive, and analogical reasoning, enabling them to draw informed conclusions and adapt solutions from past experiences [11,15].

**Decision-Making** in LLM-based agents is characterized by their capacity for sophisticated policy generation and execution. Techniques such as Language Agent Tree Search (LATS), ABA, and Bilevel-LLM enable agents to navigate complex, decentralized environments and optimize their behavior [4,24]. By integrating tree search algorithms, LLMs can achieve deeper strategic foresight and proactive planning, moving beyond reactive responses [24]. Furthermore, game theory principles influence agent interactions, allowing them to exhibit flexible cooperative or competitive behaviors based on accumulated experience and internal parameters [7,15].

**Planning** capabilities are fundamentally transformed by LLMs, which excel at hierarchical task decomposition and goal setting, breaking down complex tasks into simpler sub-tasks [2,11,17,21]. Various planning frameworks, including AdaPlanner, ReAct, and Tree of Thoughts (ToT), allow LLM-based agents to refine and adapt plans dynamically based on real-time feedback, mitigating issues like hallucination and enabling robust operation under uncertainty [8,18,22,23,24]. This adaptability is crucial for achieving global planning and individual task decomposition in multi-agent systems.

The ability for **Learning** is a cornerstone, enabling continuous adaptation and evolution of agent behaviors and strategies. LLM-based agents leverage reinforcement learning through feedback mechanisms from environments, humans, or other agents, allowing them to refine their actions and conform to social dynamics [19]. Imitation learning, though less explicitly detailed, is implied through the use of communication logs for continuous adaptation [19,24]. Critically, self-supervised learning allows agents to retain information in memory, engage in self-reflection (e.g., self-questioning), and dynamically modify their objectives and planning strategies [3,5,19,23]. The inherent pre-training and In-Context Learning (ICL) capabilities of the underlying LLMs further allow agents to generalize to unseen tasks and learn from analogy without explicit parameter updates [11]. This continuous accumulation and updating of insights and experiences are vital for agents to navigate complex and dynamic environments [16].

Beyond individual enhancements, LLMs facilitate **Advanced Collaboration Mechanisms**, which are essential for tackling problems exceeding single-agent capabilities. This includes self-collaboration, where a single LLM acts as a cognitive synergist by simulating multiple personas (e.g., Solo Performance Prompting) [14,24]. Agents also exhibit self-correction through feedback and reflection, engaging in debates to resolve conflicts, reach consensus, and negotiate agreements, mirroring human-like social dynamics and leading to emergent collective intelligence [7,15,22,23,26,31]. Architectural innovations like Cross-Team Collaboration (CTC) and Mixture-of-Agents (MoA) further optimize information exchange and enhance collaborative problem-solving [4,5,18].

Finally, **Knowledge Graph Integration** plays a critical role in grounding LLMs by providing structured, factual, and external knowledge. This mitigates issues like hallucination and enhances interpretability [24]. KGs represent knowledge as triples and embeddings, enabling agents to retrieve relevant information through structured queries or semantic search and to reason over these graphs to infer new knowledge through logical inference or path-based reasoning. This synergistic relationship leverages the symbolic reasoning of KGs to complement the LLM's linguistic capabilities, forming a robust foundation for intelligent multi-agent behavior [24].

Collectively, these capabilities underscore how LLMs transform traditional agents into more autonomous, adaptive, and intelligent entities, capable of tackling highly complex and dynamic tasks through enhanced individual functions and sophisticated collective intelligence [11]. The ongoing research in these areas continues to push the boundaries of what LLM-based multi-agent systems can achieve.
### 4.1 Reasoning
Reasoning abilities are fundamental to the efficacy of LLM-based multi-agent systems, enabling them to tackle complex tasks through systematic thought processes and collaborative problem-solving. A core mechanism for enhancing reasoning in these systems is Chain-of-Thought (CoT) reasoning, which encourages large language models (LLMs) to break down intricate problems into more manageable, sequential steps [11,14,23].

Different studies employ varied prompting strategies to implement CoT in multi-agent contexts. The foundational CoT approach prompts LLMs to "Think Step by Step," generating intermediate reasoning steps that lead to a final answer [14,22]. This is often facilitated by few-shot examples, where the prompt provides demonstrations of <input, chain of thought/thinking process, output> pairs to guide the LLM's reasoning logic [22]. Expanding on this, Tree of Thoughts (ToT) allows agents to explore multiple reasoning possibilities at each step, forming a tree-like structure. The search process within ToT can utilize either Breadth-First Search (BFS) or Depth-First Search (DFS), with each state evaluated by a classifier or through majority voting to select the most promising path [14].

Beyond basic CoT and ToT, multi-agent systems integrate advanced self-correction and collective reasoning strategies to improve accuracy. Techniques like self-consistency, self-polish, and self-refine enable agents to scrutinize and improve their own reasoning processes [11]. Specifically, CoT-Self-Consistency (CoT-SC) generates multiple outputs by setting the temperature greater than zero during sampling and then selects the optimal output, often through majority voting, thus enhancing the robustness of the reasoning outcome compared to single-sample CoT [22].

In multi-agent environments, collective reasoning significantly boosts performance. Systems can leverage agent interaction and viewpoint exchange to enhance shared understanding and problem-solving, as demonstrated in tasks such as MMLU (Massive Multitask Language Understanding) and StrategyQA challenges [29,31]. The Conquer-and-Merge Discussion (CMD) framework, for instance, simulates human-like debates where multiple LLM-powered agents engage in open discussions, contributing diverse perspectives to improve overall reasoning capabilities [18]. Another approach is concurrent reasoning within teams, where agents explore multiple potential solutions simultaneously, sometimes incorporating role reversal mechanisms to deepen their analysis [4]. For long-context tasks that exceed individual LLM token limits, the Chain-of-Agents (CoA) framework employs worker agents to sequentially process portions of the input, passing results to a manager agent for final aggregation. Other emerging reasoning mechanisms include the use of agents to generate task-specific instructions, the OKR-Agent method, Chain-of-Expers (CoE), and Thought Propagation (TP) [24]. The Think-on-Graph (ToG) method is also mentioned as a reasoning mechanism, implying an integration with graph structures for enhanced reasoning, though specific details on its construction and utilization approaches are not extensively detailed in the provided digests [24].

LLM-based agents also leverage various forms of logical reasoning, including deductive, inductive, and analogical reasoning, to make informed decisions based on available evidence [11]. Analogical reasoning, in particular, allows agents to solve new problems by drawing parallels and applying solutions based on past experiences and learned patterns. While the general application of analogical reasoning for problem-solving is acknowledged, the specific challenges and limitations of its implementation within LLM-based multi-agent systems, such as handling irrelevant similarities or extracting appropriate past experiences in diverse contexts, are not comprehensively detailed in the provided materials [11]. Furthermore, some studies delve into specialized reasoning contexts, such as moral reasoning, demonstrating the breadth of reasoning applications for LLM-based agents [15].
### 4.2 Decision-Making
The application of Large Language Models (LLMs) in multi-agent systems necessitates robust mechanisms for policy generation and execution, with various algorithms designed to optimize agent behavior and interactions. Several distinct approaches have emerged for enabling LLMs to generate and execute policies effectively. Key mechanisms include Language Agent Tree Search (LATS), the ABA method (Asking Before Acting), and Bilevel-LLM, which collectively represent diverse strategies for decision-making within LLM-based agents [24]. Furthermore, specific techniques like a greedy pruning mechanism can be employed to refine policy outputs by eliminating low-quality content, while a solution aggregation mechanism facilitates the collaborative integration of various content elements into a superior collective outcome [4].

Evaluating the performance of these policy planning algorithms reveals both capabilities and limitations. In complex decentralized scenarios, LLMs operating with limited local perception and communication encounter significant challenges in their decision-making abilities [8]. Studies examining zero-shot decision-making in various coordination tasks have highlighted performance variations and inherent limitations in the LLMs' capacity for strategy formation under such constraints [8].

To enhance decision-making capabilities, tree search algorithms are increasingly integrated with LLMs. Language Agent Tree Search (LATS) is a notable example that leverages tree search principles to improve the strategic depth and foresight of LLM-based agents [24]. By systematically exploring potential future states and actions, LATS enables agents to make more informed and optimal decisions, moving beyond reactive responses to engage in proactive planning.

The interplay of agents in LLM-based multi-agent systems often involves concepts drawn from game theory, particularly concerning how agents learn to cooperate or compete. Agents' decision-making processes can be dynamically influenced by internal parameters such as aggressiveness, greed, and strength, alongside their memory of past interactions [7]. This dynamic environment allows agents to exhibit flexible behaviors, switching between conflict and cooperation based on their accumulated experiences [7]. Beyond strategic interactions, the complexity extends to moral decision-making, where LLMs in groups have been studied for their ability to demonstrate utilitarian boosts in ethical dilemmas [15]. Such investigations contribute to understanding the sophisticated social dynamics that can emerge in LLM-based multi-agent systems.
### 4.3 Planning
Planning is a foundational capability for intelligent agents, particularly in complex multi-agent systems (MAS) where agents must coordinate to achieve common goals. Unlike single-agent scenarios, multi-agent planning necessitates handling intricate contexts, ensuring internal system agreement, and aligning individual agent objectives with overarching system goals [2]. The planning core within LLM-based agents relies on their reasoning ability, enabling the decomposition of complex tasks into manageable sub-tasks and the development of appropriate strategies for each [11].

Different planning strategies and frameworks are employed in multi-agent systems, each with distinct strengths and weaknesses concerning efficiency, scalability, and robustness. Multi-agent planning involves both "global planning," which entails dividing workflows and assigning subtasks across the system, and individual "task decomposition" for each agent [2]. For instance, frameworks often emphasize task decomposition through role specialization, where complex tasks are broken down into smaller, role-specific assignments [5]. The process often involves stages like hierarchical sub-tasking and reflective planning to refine strategies [11]. However, LLMs face considerable difficulties in robust planning under uncertainty, especially in decentralized environments, which is critical for effective swarm intelligence [8].

LLMs are extensively utilized for task decomposition and goal setting by leveraging their inherent reasoning capabilities to break down complex tasks into simpler sub-tasks [21]. An example is GITM, an LLM agent that decomposes an overarching goal, such as "Mining Diamond," into a series of sub-goals, constructing a sub-goal tree [17]. This hierarchical approach allows for a structured approach to complex problems. Planning approaches can broadly be categorized based on their feedback mechanisms: those without feedback and those that incorporate feedback [21]. No-feedback planning includes strategies like Chain of Thought (CoT), Zero-shot CoT, ReWOO, and HuggingGPT, while multi-path reasoning often involves tree-like structures such as CoT-SC and Tree of Thoughts (ToT) [21]. Feedback-based planning, on the other hand, utilizes environmental, human, or model-based feedback to modify plans during execution [21].

Several planning frameworks specifically designed for LLM-based multi-agent systems contribute significantly to effective planning:
*   **AdaPlanner**: This framework allows LLM agents to refine and adapt plans dynamically based on real-time environmental feedback. It incorporates both in-plan refinement, which aligns actions with predictions, and out-of-plan refinement, which adjusts plans when predictions do not match actual outcomes [17,18]. AdaPlanner also features skill discovery, enabling agents to reuse successful past plans as few-shot examples, thereby improving adaptability and efficiency [18].
*   **ChatCoT**: This framework employs a tool-augmented Chain-of-Thought (CoT) reasoning approach, optimized for chat-based interactions [18]. It allows LLMs to alternate between tool manipulation and reasoning actions within dynamic, multi-turn conversations, significantly enhancing adaptability in complex scenarios [18].
*   **KnowAgent**: This framework integrates an action knowledge base and utilizes a self-learning strategy. By providing LLMs with structured action knowledge, KnowAgent guides the planning process and helps mitigate issues such as planning hallucinations, leading to more reliable plans [18].
*   **RAP (Retrieval-Augmented Planning)**: This approach enhances LLMs' planning capabilities by integrating retrieval-augmented techniques with contextual memory [18]. It dynamically leverages relevant past experiences, tailored to the current context, to inform and improve planning decisions [18].
*   **Tree of Thoughts (ToT)**: This framework significantly enhances problem-solving by allowing LLMs to explore coherent units of text, or "thoughts," as intermediate steps in problem-solving [18,21]. It enables multi-path reasoning by considering different thought sequences, leading to a more comprehensive exploration of solutions.
*   **ReAct (Reason and Act)**: Representing a notable advancement in integrating reasoning and action, ReAct facilitates an interleaved generation of reasoning traces and task-specific actions [18,22,23]. ReAct planning method integrates feedback from task execution into the reasoning process, enabling agents to autonomously interact with external resources, update task plans, and handle anomalous situations [21].

Beyond these, other frameworks such as MultiReAct, ToolChain*, DORAEMONGPT, and PSL (Plan-Seq-Learn) are also contributing to the evolving landscape of LLM-based multi-agent planning [24]. Furthermore, approaches like LLM+P utilize Planning Domain Definition Language (PDDL) as an intermediate interface, relying on external classical planners for long-term planning. The LLM converts the problem into "problem PDDL," requests a classical planner to generate a PDDL plan, and then converts it back into natural language [14].
### 4.4 Learning
The ability to learn and adapt dynamically is a cornerstone for Large Language Model (LLM)-based agents operating within complex multi-agent environments. This learning capability enables agents to evolve their behaviors, strategies, and internal knowledge structures in response to diverse stimuli and interactions [19]. Key learning paradigms in this context include reinforcement learning, imitation learning, and various forms of self-supervised learning.

Reinforcement learning (RL) fundamentally relies on agents receiving feedback on the outcomes of their actions, which allows them to understand impact and refine their strategies [19]. This feedback can originate from the environment, direct agent-to-agent interactions, human users, or even be intrinsically generated [19]. Agents adapt their strategies based on this feedback, demonstrating an ability to conform to and learn from their social environment [7]. While the survey outline specifically calls for a comparison of different RL algorithms and an evaluation of their performance in multi-agent settings [26], the provided digests primarily emphasize the general mechanism of feedback-driven adaptation and self-evolution [3,19]. For instance, agents can modify their initial objectives and planning strategies, or train themselves based on received feedback or communication logs, which are core principles underpinning RL approaches in dynamic environments [19]. However, specific details on distinct RL algorithms or empirical performance comparisons are not extensively elaborated within the scope of the current digest material.

Imitation learning, where agents learn by observing and mimicking expert behavior or human users, is another pertinent paradigm. Although the digests do not explicitly detail dedicated imitation learning algorithms or their inherent challenges and limitations for LLM-based agents, related concepts are present. The notion of agents training themselves based on "communication logs" [19] could implicitly involve learning from expert-generated or high-quality interaction data. Specifically, Communication Learning (LTC) utilizes multi-agent communication logs to train LLMs, facilitating continuous adaptation and potentially serving as a form of learning from demonstrated behaviors [19,24]. Furthermore, advanced agents like ProAgent predict teammate decisions and adjust strategies based on communication logs, which hints at a form of behavioral alignment or imitation within a multi-agent context [19].

Self-supervised learning (SSL) techniques are extensively leveraged by LLM-based agents to learn from unlabeled data, thereby significantly enhancing their capabilities in multi-agent systems. A fundamental aspect of self-supervision is the agent's ability to retain information from past interactions and feedback in its memory, retrieving relevant memories to inform and improve current actions [3,19]. This memory mechanism supports self-reflection, as seen in teaching agents that utilize their educational content memory to process higher-level information through self-questioning or summarizing large models [23].

Beyond internal reflection, agents achieve self-evolution by dynamically modifying themselves, their objectives, and their planning strategies [3,19]. This includes training themselves based on feedback and communication logs [19]. In a multi-agent setting, collaborative learning is a prominent form of SSL, where agents mutually improve their knowledge through interaction and knowledge sharing [25]. For instance, agents can update their internal knowledge vectors based on information received from other agents, fostering a collective learning process [25]. Concrete examples of self-supervised adaptation include MetaGPT's executable feedback mechanism, which allows engineers to optimize code quality automatically. This involves agents writing and executing unit tests, then recursively making decisions and self-prompting based on the results to achieve automated debugging [5].

Furthermore, LLM-based agents inherently benefit from their underlying large language models' pre-training, which is often self-supervised. This allows them to generalize to unseen tasks without specific training, a capability stemming from increased model and corpus size, and techniques such as multi-task learning (e.g., FLAN, T0) [11]. In-Context Learning (ICL) further enhances an agent's ability to learn from analogy by connecting original inputs with complete examples, enabling effective learning without explicit parameter updates and showcasing a powerful form of knowledge utilization and adaptation [11]. These combined learning strategies, encompassing feedback-driven adaptation, self-reflection, collaborative knowledge refinement, and leveraging inherent LLM capabilities, are critical for LLM-based agents to operate autonomously and effectively in dynamic multi-agent environments.
### 4.5 Advanced Collaboration Mechanisms
Advanced collaboration mechanisms are pivotal for enabling LLM-based agents to tackle increasingly complex problems that surpass the capabilities of individual agents. These mechanisms encompass how agents collaborate internally, self-correct, resolve disputes, and negotiate agreements.

One significant aspect of advanced collaboration is **self-collaboration**, where a single LLM-based agent leverages internal mechanisms to enhance its problem-solving abilities. The concept of Solo Performance Prompting (SPP) is a prime example, transforming a single LLM into a cognitive synergist by engaging in multi-round self-collaboration with multiple personas [14]. This approach dynamically identifies and simulates different personas based on task input, thereby harnessing internal knowledge acquisition, reducing hallucinations, and maintaining robust reasoning capabilities [14]. The general idea of self-collaboration is recognized as a key advancement in LLM agent research [24].

Beyond self-collaboration, the ability of agents to **self-correct** and improve performance over time is crucial. This involves the systematic application of feedback and self-reflection. Debate and self-reflection are identified as vital mechanisms for enhancing agent performance [26]. Agents can improve their capabilities not only from environment and human feedback but also by incorporating feedback from other agents within a multi-agent system, particularly in complex scenarios like debates [22]. Self-correction, through processes like "discussion-practice-reflection," is highlighted in applications such as educational teaching interactions [23]. However, it is important to note that continuous reflection may lead to increased uncertainty or hallucination, underscoring the need for balanced application of these mechanisms [26]. The broader concept of self-correction is a significant area of research in LLM agent development [24].

To address conflicts and foster collective decision-making, agents engage in **debates** to resolve conflicts and reach consensus. These debates allow LLM-MA agents to communicate and collectively enhance their reasoning abilities in scientific debate scenarios [31]. The efficacy of such debates is often supported by feedback received from participating agents [22]. Achieving consensus is a core objective, with studies examining various consensus protocols within LLM-based agent groups to boost utilitarian outcomes [15].

Furthermore, agents must effectively **negotiate** with each other to achieve mutually beneficial agreements. This involves various strategies for reaching a common understanding or division of labor [26]. Observational studies have shown that cooperation can emerge through the "concession" of rights among agents, leading to the establishment of hierarchies and stable "commonwealths" in agent societies, akin to social contract theories [7].

Beyond these specific mechanisms, several architectural and systemic approaches facilitate advanced collaboration. Cross-Team Collaboration (CTC) allows multiple teams of LLM-based agents to work concurrently on the same task, fostering a dynamic exchange of insights and solutions [4]. Communication infrastructure like the publish-subscribe mechanism employed by MetaGPT enables seamless information exchange and collaboration among agents [5]. The Mixture-of-Agents (MoA) architecture exemplifies a layered design where agents collaborate in distinct proposer and aggregator roles, significantly improving LLM performance across various benchmarks [18]. In decentralized multi-agent systems, studies explore emergent group dynamics and coordination effectiveness, particularly when agents have limited local perception and communication. This research highlights how LLMs can collaborate and coordinate their actions, while also identifying limitations in achieving robust collaboration in such environments [8]. The integration of diverse collaboration strategies is essential for robust multi-agent system design [26].
### 4.6 Knowledge Graph Integration
Knowledge Graphs (KGs) play a crucial role in grounding Large Language Models (LLMs) by providing structured, factual, and external knowledge, thereby enhancing their reasoning capabilities and reducing issues such as hallucination and lack of interpretability. The integration of KGs within LLM-based multi-agent systems is a prominent area of recent research [24].

Different approaches are employed for representing knowledge within KGs. Fundamentally, KGs typically structure information as triples, comprising a subject, a predicate (or relation), and an object (e.g., (entity1, relationship, entity2)). Beyond these basic triples, KGs can incorporate richer semantic structures, including ontologies and schemas that define classes, properties, and relationships, enabling more sophisticated knowledge organization and validation. For instance, entities and relations can be represented as high-dimensional embeddings, which facilitate their integration with the vector space representations used by LLMs. This allows for semantic similarity computations and enables LLMs to "understand" and interact with the KG's symbolic structure more effectively [24].

Agents retrieve relevant information from knowledge graphs through various mechanisms. One common approach involves query generation, where LLMs translate natural language queries or internal thoughts into structured KG query languages (e.g., SPARQL, Cypher). This allows agents to precisely retrieve specific facts or relationships. Another method utilizes semantic search, where embedding-based techniques are employed to find KG entities or subgraphs semantically similar to an agent's current context or query. Graph traversal algorithms are also critical, enabling agents to navigate the KG, discovering multi-hop relationships and contextual information pertinent to their tasks. The retrieved information can then be linearized or summarized by the LLM for direct consumption or further processing [24].

Furthermore, agents investigate how to reason over knowledge graphs to infer new knowledge, moving beyond simple retrieval. This involves leveraging the KG's inherent structure and logical consistency. Logical inference, where rules (e.g., if A and B, then C) are applied to existing facts in the KG, allows agents to deduce new, implicit knowledge. Path-based reasoning explores specific sequences of relations between entities to uncover indirect connections or derive conclusions. Inductive reasoning techniques, such as knowledge graph embedding models, can perform tasks like link prediction (inferring missing links between entities) or entity prediction, thereby expanding the KG's scope. When integrated with LLMs, this reasoning can be enhanced, as LLMs can guide the KG reasoning process, interpret intermediate results, and synthesize conclusions. Conversely, the KG provides a factual backbone, preventing LLM hallucinations during complex inference tasks, fostering a synergistic relationship where symbolic reasoning from the KG complements the LLM's vast linguistic and pattern recognition capabilities [24]. The effective fusion of these capabilities is a central challenge in advancing robust LLM-based multi-agent systems.
## 5. Applications of LLM-based Multi-Agent Systems
Large Language Model (LLM)-based multi-agent systems are rapidly transforming various sectors by offering novel approaches to complex problem-solving, task automation, and interactive intelligence. These systems harness the advanced reasoning and generative capabilities of LLMs, enabling multiple agents to collaborate, specialize, and interact to achieve common objectives or model intricate behaviors. The diverse applications of these systems highlight their potential benefits, including enhanced efficiency, improved decision-making, and increased system autonomy, while also presenting significant challenges related to coordination, validation, and ethical considerations [16,19,21,25].



![Key Application Areas of LLM-based Multi-Agent Systems](https://modelbest-prod.oss-cn-beijing.aliyuncs.com/SurveyGo/picture/zBmC4mH1ODwEf6OEOJS33_/home/surveygo/data/requests/13542/survey/imgs/Key%20Application%20Areas%20of%20LLM-based%20Multi-Agent%20Systems.png)

The applicability of LLM-based multi-agent systems spans a wide spectrum, fundamentally impacting how complex tasks are approached. In **Software Development**, these systems streamline the entire lifecycle from requirements analysis to debugging, significantly boosting efficiency and code quality by automating processes and fostering collaborative problem-solving among specialized agents such as product managers, programmers, and testers [3,10,14,19].

In **Simulation and Modeling**, LLM-based multi-agent systems introduce unprecedented realism and depth, enabling the authentic depiction of diverse roles and viewpoints. This facilitates the exploration of complex phenomena across social sciences, economics, psychological experiments, and physical domains, including epidemiological modeling and robotic task collaboration [3,17,19]. They provide robust frameworks for simulating social networks, human behavior, and market dynamics, enhancing the fidelity and insights derived from agent-based simulations [7,9].

**Intelligent Tutoring Systems and Dialogue Systems** benefit from these advancements by offering personalized learning experiences and fostering more natural and comprehensive human-computer interactions. Multi-agent architectures can provide tailored scaffolding, adapt content delivery, and manage instructional conversations in educational settings [23]. Similarly, in dialogue systems, such as intelligent customer service, agents assume distinct roles to collaboratively process complex inquiries, maintain conversational coherence, and integrate knowledge for holistic solutions, enhancing overall service quality [10,25].

For **Complex Problem-Solving and Decision-Making**, LLM-based multi-agent systems leverage collective intelligence to accelerate scientific discovery, optimize processes, and support sophisticated decisions. They facilitate structured debates among agents to refine reasoning on demanding tasks, provide support for medical diagnosis, navigate moral dilemmas, and automate complex workflows like academic paper composition [3,15,19,25].

Beyond these established areas, **Other Emerging Applications** demonstrate the versatility of LLM-based multi-agent systems across diverse, often interdisciplinary fields. These include web navigation, robotics and industrial automation (e.g., intelligent transportation systems), finance, creative industries (e.g., advertising generation), knowledge management (e.g., research literature analysis), machine translation, and various tasks in the natural sciences [11,14,21,25]. Their utility also extends across cyber (e.g., automated GUI testing like DroidAgent), physical (e.g., power grids), and social domains, enabling advanced modeling and automation in highly dynamic and interconnected environments [22,29,31].

Despite these profound benefits, common challenges persist across applications. Effective **coordination and communication** among diverse agents remain critical, often necessitating structured protocols and hierarchical designs to manage complex dependencies [3,19]. **Validation and reliability** are paramount, particularly in high-stakes domains, requiring robust methodologies to ensure that simulated actions or generated outputs accurately reflect real-world scenarios or desired outcomes [8]. Furthermore, scaling these systems to handle numerous "peer agents" and ensuring **fairness and robustness** in decentralized decision-making environments present ongoing research challenges [8,23]. Addressing these challenges is crucial for fully realizing the transformative potential of LLM-based multi-agent systems in real-world applications.
### 5.1 Software Development
The application of LLM-based multi-agent systems has emerged as a promising paradigm for enhancing software development processes, offering significant advantages in efficiency, code quality, and development time. These systems are designed to mimic diverse roles within a typical software development lifecycle, such as product managers, programmers, and testers, fostering collaborative problem-solving for complex tasks [3,14,19].

One primary benefit is the **increased efficiency and reduced development time**. Multi-agent systems can automate various stages of software development, spanning requirements analysis, architecture design, coding, testing, and debugging [5,14]. Prominent examples like MetaGPT and ChatDev demonstrate this capability, with MetaGPT specifically designed to streamline the entire development process through role specialization and structured communication [5,14,20]. The ability of LLM-based agents to automatically generate code, combined with their capacity for autonomous debugging and optimization through collaboration, directly contributes to notable improvements in development efficiency and speed [10]. For instance, projects like DroidAgent leverage LLM-based agents for autonomous GUI testing of Android applications, further exemplifying the potential for automation and efficiency gains [31].

Beyond efficiency, these systems also contribute to **improved code quality**. The iterative nature of agent interactions, where agents can communicate with code interpreters, other agents, or even human collaborators, allows for continuous refinement and improvement of the generated code [3,19]. A comparative study demonstrated that multi-team collaboration facilitated by LLM-based multi-agent systems led to a significant improvement in software quality when compared to traditional single-team approaches [4]. This enhanced quality stems from the collective intelligence and diverse perspectives brought forth by specialized agents operating in concert.

Despite these significant advantages, the implementation of LLM-based multi-agent systems in software development presents **challenges, particularly in coordinating diverse agents and managing complex dependencies**. The effective functioning of these systems heavily relies on structured communication. Typically, the communication structure among agents is hierarchical, mirroring established software development workflows or Standard Operating Procedures (SOPs) [3,19]. To facilitate structured coordination and manage dependencies, SOPs are often explicitly encoded into prompts, guiding agent interactions and ensuring alignment with project goals [19]. Frameworks like MetaGPT emphasize role specialization and structured communication protocols to streamline the development process and mitigate coordination complexities [5]. However, coordinating numerous "peer agents" in group discussions, as seen in tasks like proposing solutions for different promotional forms, still requires robust mechanisms to synthesize diverse outputs and resolve potential conflicts [23]. The inherent complexity of software development tasks, involving numerous interconnected modules and functionalities, necessitates sophisticated dependency management capabilities within multi-agent architectures to ensure coherence and prevent errors. Future research must continue to refine coordination mechanisms and develop more adaptive strategies for handling dynamic and intricate inter-agent dependencies to fully unlock the potential of LLM-based multi-agent systems in real-world software engineering environments.
### 5.2 Simulation and Modeling
The application of Large Language Model (LLM)-based multi-agent systems in simulation and modeling offers significant advantages, primarily due to their capacity to increase realism and foster a deeper understanding of complex phenomena [3,17]. LLMs, through their inherent role-playing capabilities, enable the authentic depiction of diverse roles and viewpoints, enriching the fidelity of simulated environments [19].

These systems are extensively utilized across various domains, ranging from prototype-level simulations with predefined rules, such as virtual social systems and games, to modeling complex real-world activities like economic interactions and human browsing behavior [17]. Beyond these, LLM-based multi-agent systems are applied in simulating company management policies, psychological experiments, and even robotic task collaboration where agents with varying capabilities work together to solve physical tasks [3,14]. The scope also includes the creation of highly realistic and reproducible environments for digital market simulations [24], and the analysis of emergent group dynamics and coordination effectiveness in decentralized multi-agent systems through platforms like SwarmBench [8].

A prominent area of application is social simulation, where LLM-based agents provide a robust framework for exploring nuanced social dynamics and validating social science theories [19]. For instance, the SALM framework has been specifically designed for social network simulation, demonstrating its capability to model long-term social phenomena by validating against real-world SNAP ego networks and capturing intricate social interactions [9]. Further applications in social sciences include simulating online social communities, modeling daily human life, and conducting political and economic studies [21]. The concept of Humanoid Agents, which are imbued with basic needs, emotions, and relationship intimacy, further enhances the realism by simulating human-like behavior within these complex societies [26]. This capability extends to simulating the emergence of social contracts, such as those described by Hobbes, allowing for the computational exploration of social evolution [7]. Other key areas benefiting from LLM-MA simulations include game theory, where interactive environments test hypotheses; psychological modeling, by applying experiments to agents to understand human characteristics; economic and financial trading environments; recommendation systems simulating user-item interactions and preference propagation; and policy simulations to evaluate the impact of various policies [19].

Despite these significant advancements, the widespread adoption and reliability of LLM-based multi-agent simulations are contingent upon addressing critical challenges. Primarily, calibrating agent behavior to ensure that the simulated actions accurately reflect real-world scenarios remains a complex task. This involves defining appropriate prompts, reward functions, and learning mechanisms that guide agent decision-making. Furthermore, the validation of simulation results against empirical data or established theoretical models is paramount to establishing their credibility and ensuring their utility for predictive or explanatory purposes. These challenges necessitate robust methodologies for evaluation and continuous refinement of agent models and simulation environments.
### 5.3 Intelligent Tutoring Systems and Dialogue Systems
LLM-based multi-agent systems significantly enhance the effectiveness of intelligent tutoring systems (ITS) and foster more natural and engaging conversations within dialogue systems [24].

In the domain of Intelligent Tutoring Systems, multi-agent architectures powered by Large Language Models can profoundly personalize the learning experience. For online self-directed learning scenarios, these systems provide multi-type scaffolding and intelligent guided learning interactions. They support diverse modalities of teaching content, including recommended text, video, and audio resources, while offering real-time progress evaluation and feedback information [23]. This comprehensive approach enables agents to effectively personalize learning paths, adapt content delivery based on learner performance, and manage the instructional conversation flow to optimize engagement and comprehension. The continuous evaluation and feedback mechanisms further refine the agents' understanding of user preferences and learning styles, leading to highly adaptive and effective educational support.

For dialogue systems, LLM-based multi-agent systems are pivotal in enabling more natural, coherent, and comprehensive interactions. In an intelligent customer service system, for instance, different agents can assume distinct roles, such as primary customer service and specialized technical support [25]. This role-based collaboration allows multiple agents to collectively process intricate customer inquiries and complaints, thereby delivering more comprehensive and professional services [10]. Large Language Models empower these agents to accurately understand complex dialogue contexts, maintain conversational coherence across turns, and seamlessly integrate knowledge from various domains to provide holistic solutions [25]. Furthermore, the application of human-like spoken dialogue generation and theory-of-mind enhanced dialogue generation capabilities contribute to more intuitive and empathetic interactions, allowing agents to better model user preferences and intentions [24]. Frameworks such as AutoGen exemplify how these systems facilitate agents taking on different roles and collaborating through natural language conversations to achieve specific goals, effectively managing the conversation flow and ensuring goal-oriented, engaging interactions [26].
### 5.4 Complex Problem-Solving and Decision-Making
Large Language Model (LLM)-based multi-agent systems are increasingly pivotal in addressing complex problems across diverse domains, notably in accelerating scientific discovery, optimizing intricate processes, and supporting sophisticated decision-making. These systems predominantly leverage collective intelligence, where individual agents collaborate and synthesize information to achieve a common goal [16,24].

In the realm of scientific discovery and enhanced reasoning, LLM-based multi-agent systems facilitate structured debate scenarios. For instance, agents can engage in argumentative exchanges to enhance their collective reasoning abilities on demanding tasks such as MMLU (Massive Multitask Language Understanding) benchmarks, mathematical problems, and StrategyQA [3,19]. This process typically involves each agent initially formulating its analysis of a problem, followed by a joint debate process across multiple rounds, ultimately leading to a consensus answer. This iterative refinement through debate exemplifies how collective intelligence can elevate the quality and robustness of solutions, thereby accelerating the scientific inquiry process.

Beyond theoretical reasoning, these multi-agent systems offer tangible support for practical decision-making. A prominent application is in medical diagnosis support systems, where LLM-powered agents meticulously analyze patient symptoms, suggest potential conditions, propose diagnoses, and recommend treatment plans [25]. By assisting medical professionals in making accurate and comprehensive decisions, these systems enhance the efficiency and precision of healthcare services. Furthermore, LLM-based multi-agent systems are also being explored for their capacity to navigate complex moral dilemmas, demonstrating their utility in achieving utilitarian boosts in ethically sensitive decision-making scenarios [15].

In terms of optimizing complex workflows and achieving efficient task completion, LLM-based agents demonstrate significant potential. For example, in educational contexts, multi-agent systems can automate and enhance the collaborative task of composing academic papers. Different intelligent agents can assume specialized roles, such as question setters, test takers, and graders, based on specific requirements like discipline, knowledge points, and discrimination criteria [23]. These agents collaboratively complete their assigned parts before submitting the final output for review and quality control, thereby streamlining a traditionally labor-intensive process.

While LLM-based multi-agent systems offer substantial benefits, their deployment in complex, decentralized environments presents unique challenges, particularly concerning efficiency and fairness in negotiation and decision-making. Benchmarking tools like SwarmBench are employed to evaluate LLMs' capabilities in solving complex coordination problems that necessitate decentralized decision-making and planning under uncertainty [8]. The findings from such assessments often highlight the difficulties LLMs face in consistently achieving robust solutions in these highly decentralized and dynamic scenarios [8]. This underscores the ongoing research imperative to improve the robustness, reliability, and fairness mechanisms within LLM-based multi-agent systems to ensure their effective operation in increasingly complex and distributed problem-solving landscapes. The general application of LLM-based multi-agent systems to complex problems is widely recognized, although specific instances across all domains (such as engineering design) may require further detailed exploration in some survey contexts [30].
### 5.5 Other Emerging Applications
The proliferation of Large Language Model (LLM)-based multi-agent systems has catalyzed their exploration across a diverse array of emerging applications, extending beyond conventional domains into complex, interdisciplinary fields. These systems are poised to significantly contribute to intelligent upgrades in areas such as intelligent manufacturing, smart cities, and healthcare [10].

In the realm of **web navigation**, LLM-based multi-agents demonstrate considerable potential by interpreting intricate instructions within dynamic web environments. They are adept at adapting to procedural changes and generalizing successful operations, enabling autonomous task completion like form filling and online shopping [11]. This capability positions them as crucial tools for enhancing user experience and automation in digital interfaces.

**Robotics and industrial automation** represent another significant application area for LLM-based agents. In engineering, these agents are capable of assisting across various disciplines, including civil engineering, computer science, and industrial automation, with specific emphasis on robotics [21]. Their ability to process complex instructions and adapt to physical environments makes them valuable for controlling intelligent transportation signal systems and power grids, although further scenario exploration is required for full realization [14].

Within **healthcare**, LLM-based multi-agent systems offer transformative capabilities, particularly in epidemiological modeling. They can accurately simulate the spread of diseases, mirroring human responses to outbreaks and elucidating complex pandemic patterns, thereby aiding in the mitigation of epidemic curves [3,19]. This simulation capacity provides a powerful tool for public health policy formulation and crisis management.

In the **finance and economics** sectors, LLM-based multi-agents facilitate sophisticated simulations of economic and financial transaction environments. These simulations enable researchers to explore agent behaviors influenced by resources, information, and individual preferences, offering critical insights into market dynamics and economic forecasting [3].

Beyond these sectors, LLM multi-agents are finding utility in various **creative industries and knowledge management** applications. An advertising creative generation system exemplifies their capacity for collaborative ideation, where different agents contribute diverse perspectives, iterate on concepts, and integrate multiple creative styles [25]. Similarly, in natural-language-oriented reasoning tasks, such as story generation, the generalizability of these frameworks has been demonstrated [4]. Furthermore, LLM agents are instrumental in research literature analysis systems, enabling advanced semantic-based retrieval and the integration of dispersed information into structured knowledge [25].

Applications also extend to fundamental AI tasks like **machine translation and multimodal processing**, including the specialized case of Mongolian Chinese Machine Translation [24]. In the broader **natural sciences**, LLM-based agents support document and data management, experimental assistance, and natural science education, including querying internet information and developing educational tools [21].

The potential of LLM-based multi-agent systems also spans across **cyber, physical, and social domains**, often manifesting in hybrid applications. In the **cyber domain**, their capabilities include automated GUI testing, as exemplified by the DroidAgent project. In this application, agents establish specific goals based on application functions and complete them through interaction, significantly enhancing the effectiveness and scope of Android application interface testing [22,29]. This is crucial for software quality assurance and potentially cybersecurity by identifying vulnerabilities.

The **physical domain** benefits from multi-agent systems through applications like the aforementioned intelligent transportation and power systems, as well as the broader integration into robotics and industrial automation [14,21]. The detailed simulations of disease propagation, as discussed in healthcare, also represent a significant physical application [3,19].

In the **social domain**, LLM-based multi-agents are powerful tools for social simulation, gaming, psychology, and policy making [3]. They enable the modeling of complex social behaviors to explore potential social dynamics, test social science theories, and populate virtual spaces for immersive experiences. In gaming, they can create dynamic simulated environments, allowing agents to assume diverse roles and test game theory hypotheses. For psychological research, these agents can simulate humans with varied characteristics and thought processes, enabling the application of psychological experiments in virtual settings. Moreover, in policy making, they facilitate the simulation of virtual governments or the impact of various policies on different communities, providing a robust platform for evidence-based decision-making [3]. Furthermore, their ability to understand implicit instructions and apply common sense knowledge, utilizing spatial data and item location, enhances their utility in general life scenarios [11].

Collectively, these emerging applications underscore the versatility and transformative potential of LLM-based multi-agent systems. Their capacity to operate across and integrate cyber, physical, and social domains highlights their growing significance in addressing complex real-world challenges and fostering intelligent advancements across numerous sectors.
## 6. Challenges and Future Directions
The burgeoning field of LLM-based Multi-Agent Systems (MAS) presents a landscape rich with potential yet fraught with significant challenges that impede their widespread deployment and necessitate focused research and development. These challenges span various dimensions, from technical limitations to profound ethical considerations, collectively defining the current frontier for innovation in this domain [2,18,19,30].



![Key Challenges in LLM-based Multi-Agent Systems](https://modelbest-prod.oss-cn-beijing.aliyuncs.com/SurveyGo/picture/qNr7s3DE6vqKfWl2agORW_/home/surveygo/data/requests/13542/survey/imgs/Key%20Challenges%20in%20LLM-based%20Multi-Agent%20Systems.png)

A primary technical hurdle lies in **scalability**, encompassing both computational and communication costs. Current LLM-based MAS face limitations in handling large numbers of agents, managing complex contextual information, and executing long-term planning and task decomposition due to inherent constraints such as token limits and computational resource demands [2,7,19,22]. **Robustness** remains a critical concern, as these systems must reliably perform in dynamic environments, handle noisy data, and respond to unexpected events. Issues such as information inconsistency, ambiguity, ineffective repetition, and the potential for infinite loops within multi-agent interactions underscore the need for more stable and predictable system behaviors [5,6]. The **interpretability** of agent decisions, often obscured by the "black box" nature of underlying LLMs, poses another significant challenge, making it difficult to understand, debug, and trust complex multi-agent behaviors, especially when small prompt changes lead to non-linear behavioral shifts [7]. While not explicitly detailed, limitations in **real-time response** are implicitly tied to the aforementioned scalability and computational demands, particularly in time-critical applications. Furthermore, effective **agent coordination constraints** are vital, requiring sophisticated mechanisms for optimizing task allocation, promoting robust reasoning through iterative debate, and efficiently managing shared memory and information flow, especially in decentralized scenarios with local information constraints [2,8].

A pervasive challenge across all LLM applications, significantly amplified in multi-agent settings, is the phenomenon of **hallucination**. In an MAS context, even minor hallucinations can undergo infinite amplification through inter-agent interactions, potentially leading to a collective convergence on incorrect information or "incorrect consistency" [3,11,21]. This issue is further exacerbated by the limited context an LLM can effectively process during extended debates or negotiations, contributing to the propagation of inaccuracies [11].

Beyond technical and performance limitations, the deployment of LLM-based MAS introduces complex **ethical considerations and safety concerns**. The potential for hallucination amplification directly impacts system reliability and trustworthiness. More critically, these systems can exhibit a "utilitarian boost" in collective moral decision-making, potentially leading to recommendations that conflict with nuanced human values, legal frameworks, or societal norms [15]. Aligning LLM agents with human knowledge and values is an essential challenge to ensure responsible behavior, particularly in morally sensitive domains and for applications like teaching agents, which must avoid bias and discrimination [17,23]. The risk of malicious use of autonomous LLM-based agents also underscores the urgent need for robust human alignment strategies, stringent safety measures, and clear operational rules to ensure accountability and prevent unintended consequences [21].

Addressing these challenges necessitates a comprehensive agenda for **future research opportunities**. 

![Future Research Directions in LLM-based Multi-Agent Systems](https://modelbest-prod.oss-cn-beijing.aliyuncs.com/SurveyGo/picture/LRVWn8wbh_8dqvblnYTxa_/home/surveygo/data/requests/13542/survey/imgs/Future%20Research%20Directions%20in%20LLM-based%20Multi-Agent%20Systems.png)

Key areas include developing more robust, efficient, and scalable architectures capable of handling large numbers of agents and complex, decentralized interactions. This involves improving LLMs' planning and strategy formation under uncertainty, exploring structural strategies like strong validation, enhanced communication protocols, uncertainty quantification, and refined memory/state management, as well as increasing agent memory and population size to expand system capabilities [7,8,19,20]. The integration of multi-modal data (images, audio, video) is crucial for enabling agents to interpret and respond to real-world environments more comprehensively, moving beyond text-centric interactions [3,14,19]. Advancements in sophisticated reasoning and learning capabilities, alongside improved collaboration mechanisms, are essential for fostering collective intelligence, optimizing co-adjustment among agents, and developing more generalized Standard Operating Procedures (SOPs) that dynamically adapt to experience [4,5,19].

Ethically, future work must focus on developing multi-agent moral evaluation suites and debiasing interventions, including investigating the linguistic triggers and internal representations influencing group decision-making, such as the utilitarian boost [15]. Mitigating hallucinations in multi-agent settings through effective information flow management is also paramount to prevent inaccuracy propagation [19]. Finally, the development of comprehensive benchmarks is critical for accurately evaluating and comparing LLM-MA systems across diverse applications, from scientific team operations to economic analysis [3,19]. Future research will also explore LLM-MA systems from various theoretical perspectives—including cognitive science, symbolic AI, cybernetics, complex systems, and collective intelligence—to unlock innovative applications and a more comprehensive understanding of the field, ultimately advancing towards Artificial General Intelligence (AGI) and the "Agent as a Service" (AaaS) paradigm [3,19,21].
### 6.1 Ethical Considerations and Safety
The deployment of Large Language Model (LLM)-based Multi-Agent Systems (MAS) introduces a complex array of ethical considerations that demand meticulous analysis and robust mitigation strategies. A primary concern revolves around the inherent tendency of LLMs to exhibit hallucinations [21].

In a multi-agent context, this issue can be significantly exacerbated; frequent interactions between agents risk the infinite amplification of minor hallucinations, potentially leading to a collective convergence on incorrect information or “incorrect consistency,” where all agents erroneously believe the inaccurate information to be true [11]. This challenge is further compounded by the limited context an LLM can handle—especially during extended periods of debate or negotiation within a multi-agent system [11].

Furthermore, the ethical implications extend to decision-making in morally sensitive domains. Research indicates a concerning “utilitarian boost” in the collective moral decision-making of LLMs when operating in groups [15]. While utilitarianism offers a clear framework, its unchecked application by autonomous agents could lead to morally problematic recommendations that directly conflict with established legal or broader societal moral obligations [15]. This poses a significant challenge for aligning LLM-based agents with the nuanced and often conflicting human values and norms, particularly in situations involving complex moral dilemmas.

Beyond unintentional errors and biases in moral reasoning, the potential for malicious use of LLM-based autonomous agents also presents a critical safety concern [21]. To address these profound challenges, the imperative for robust human alignment strategies is paramount, ensuring that LLM-based MAS operate responsibly and prevent unintended consequences [21]. This necessitates the development and implementation of stringent safety measures and clear operational rules to prevent the propagation of errors, mitigate biases, ensure accountability, and ultimately guide agent behavior towards ethical outcomes.
### 6.2 Future Research Opportunities
The continued advancement of LLM-based multi-agent systems (MAS) necessitates focused research to address current limitations and unlock their full potential. In particular, there is a need to develop more robust, efficient, and scalable architectures capable of handling large numbers of agents and complex interactions. A critical area involves enhancing the ability of LLMs to perform robust planning and strategy formation in decentralized environments, managing local information constraints, and coordinating effectively—especially under swarm-like conditions [8]. Addressing challenges related to computational complexity and resource demands is crucial for scaling LLM-MA systems [19]. Future research should explore structural strategies such as strong validation, enhanced communication protocols, uncertainty quantification, and improved memory and state management to rectify fundamental design flaws in existing MAS [20]. Furthermore, increasing agent memory and population size is a direct avenue for expanding system capabilities [7].

Another promising direction is the integration of multi-modal data—including images, audio, and video—into LLM-based multi-agent systems. This requires agents to effectively handle diverse data types and interpret information beyond textual input, enabling a more comprehensive understanding and response to real-world environments [19].

Developing more sophisticated reasoning and learning capabilities, coupled with improved collaboration mechanisms, is essential for enabling agents to work together effectively. This encompasses advancing collective intelligence by optimizing co-adjustment among multiple agents and leveraging synergistic effects from coordinated interactions [19]. Research should focus on developing more generalized Standard Operating Procedures (SOPs) applicable across various domains, along with methods for agents to dynamically adapt and refine these SOPs based on experience [5]. Exploring different team configurations, communication protocols, and aggregation mechanisms can further enhance the performance of multi-agent systems, particularly in complex tasks such as software development [4]. Challenges also exist in enabling agents to understand implicit meanings in textual input and to navigate the complexities of scientific terminology and multi-dimensional structures, challenges that are compounded by a severe lack of suitable training data in scientific fields [11]. Enhancing agents’ ability to map prompts to human behavioral motivations is also a vital area for future exploration [7].

From an ethical perspective, future work should focus on developing multi-agent moral evaluation suites and debiasing interventions. This includes investigating linguistic triggers and internal representations that influence group decision-making, such as the utilitarian boost observed in LLM groups [15].

Continued research is vital to address current limitations—such as mitigating hallucinations in multi-agent settings through effective information flow management to prevent the propagation of inaccuracies [19]. Developing comprehensive benchmarks is also essential for accurately evaluating and comparing LLM-MA systems across diverse applications, including scientific team operations and economic analysis [19]. The trajectory of LLM-based multi-agent systems points toward broader applications and a deeper understanding, with anticipated advancements across more fields [10]. This includes prioritizing the design and development of teaching agents to integrate generative AI into educational products and services [23]. Furthermore, exploring LLM-MA systems from various theoretical perspectives—such as cognitive science, symbolic AI, cybernetics, complex systems, and collective intelligence—can yield innovative applications and a more comprehensive understanding of the field [3,19]. Ultimately, these advancements are seen as contributing to the potential of LLM-based agents to advance Artificial General Intelligence (AGI) and foster the concept of “Agent as a Service” (AaaS) [21].
## 7. Conclusion
This survey has systematically explored the rapidly evolving landscape of LLM-based multi-agent systems, highlighting their fundamental concepts, theoretical underpinnings, and practical implementations `[14]`. The collective intelligence demonstrated by these systems has attracted significant research interest, showcasing their promising capabilities across diverse domains `[3,19]`.

A variety of architectural designs and frameworks have emerged to facilitate multi-agent collaboration and enhance LLM capabilities. Frameworks such as MetaGPT, which embeds Standard Operating Procedures (SOPs) for role specialization and workflow management, have achieved state-of-the-art performance in collaborative settings `[5]`. Similarly, the Cross-Team Collaboration (CTC) framework has proven effective in improving content generation quality through seamless information exchange and multidimensional solutions `[4]`. Innovations like SALM, designed for social network simulation, integrate Language Models (LMs) with hierarchical prompting architectures and attention-based memory systems to model long-term social phenomena with behavioral fidelity `[9]`. These advancements underscore the critical role of robust system architecture in enhancing LLM performance, particularly in areas like network planning and document review `[13]`. While selecting the appropriate framework is foundational, the true value of these systems lies in their application to solving repetitive, high-frequency problems with practical and business-oriented outcomes `[6]`.

LLM-based multi-agent systems enable efficient processing of complex tasks through agent collaboration, showing significant innovation in AI `[10]`. Their applications span a wide spectrum, from general problem-solving and world simulation `[3,19]` to specialized domains. They serve as a new paradigm for simulation, offering human-level intelligence for Agent-Based Modeling and Simulation (ABMS) `[17]`. This includes their potential to act as "virtual laboratories" for simulating complex group dynamics and exploring the evolution of collective behavior, exemplified by studies on social contract theory `[7]`. Furthermore, teaching agents built on large models represent a significant future direction in education, offering a core technical path to improve human-computer collaboration and inspire high-intelligence educational systems `[23]`.

Despite their burgeoning potential, LLM-based multi-agent systems face inherent challenges that distinguish them from single-agent systems. These include optimizing task allocation, promoting robust reasoning through debate, managing complex contextual information, and effectively managing memory in alignment with system interactions `[2]`. Benchmarking LLMs under swarm-like conditions reveals significant performance variations due to local information constraints in decentralized multi-agent systems, emphasizing the need for robust evaluation toolkits like SwarmBench `[8]`. Ethical considerations also emerge, as LLMs in multi-agent dialogues may exhibit a "utilitarian boost," showing a greater willingness to violate norms for perceived greater good, underscoring the urgent need for expanding alignment and benchmark evaluations to include group-level dynamics and developing multi-agent moral evaluation suites `[15]`.

Nevertheless, the key benefits of LLM-based multi-agent systems are evident, including increased efficiency, improved decision-making, and enhanced problem-solving capabilities `[2]`. This technology holds profound potential to impact various sectors, contributing to societal benefits and progress `[10]`. The development of agent applications based on LLMs is a field rich with both challenges and opportunities `[27]`. Continued research and development are crucial to address the identified open challenges, such as those related to agent construction, application, and evaluation `[21]`. By fostering reproducible research through open toolkits and focusing on practical applications, the field can unlock the full potential of LLMs in future decentralized systems and achieve groundbreaking innovations `[2,8]`. The journey towards fully realizing the transformative power of LLM-based multi-agent systems is ongoing, promising significant advancements and broader societal impact in the years to come `[19]`.

## References

[1] ReDel: LLM-Powered Recursive Multi-Agent Systems Toolkit [https://arxiv.org/abs/2408.02248v2](https://arxiv.org/abs/2408.02248v2) 

[2] LLM多智体系统：挑战与未解决的问题 [https://zhuanlan.zhihu.com/p/714368510](https://zhuanlan.zhihu.com/p/714368510) 

[3] LLM多智能体：进展、挑战与应用综述 [https://baijiahao.baidu.com/s?id=1798175049419538709&wfr=spider&for=pc](https://baijiahao.baidu.com/s?id=1798175049419538709&wfr=spider&for=pc) 

[4] Cross-Team Collaboration for Enhanced Multi-Agent Software Development [https://arxiv.org/html/2406.08979v1](https://arxiv.org/html/2406.08979v1) 

[5] MetaGPT：ICLR 2024 LLM Agent 领域高分论文，打造全网 Star 数最高的多智能体框架 [https://mp.weixin.qq.com/s?__biz=MzAxODI0OTgwMQ==&mid=2651394104&idx=3&sn=d443f00abf53687969fd8d4cf9084163&chksm=8024911eb75318086be6258d6624959534bac480056efbbb4201f606df556ba0df2a79b4e32f&scene=27](https://mp.weixin.qq.com/s?__biz=MzAxODI0OTgwMQ==&mid=2651394104&idx=3&sn=d443f00abf53687969fd8d4cf9084163&chksm=8024911eb75318086be6258d6624959534bac480056efbbb4201f606df556ba0df2a79b4e32f&scene=27) 

[6] 智能体框架选哪个？LangChain、Dify、CrewAI、AutoGen 五大框架对比 [https://mp.weixin.qq.com/s?__biz=MzU1MzMwODg3MQ==&mid=2247512112&idx=2&sn=24166de459f0d36d6b744fed390da07d&chksm=fa380565ed9129c645262caee1177f96a72ecb0365a28538bf8bcbfdd83bb0ae75342b16b513&scene=27](https://mp.weixin.qq.com/s?__biz=MzU1MzMwODg3MQ==&mid=2247512112&idx=2&sn=24166de459f0d36d6b744fed390da07d&chksm=fa380565ed9129c645262caee1177f96a72ecb0365a28538bf8bcbfdd83bb0ae75342b16b513&scene=27) 

[7] LLM智能体模拟：霍布斯社会契约的AI复现 [https://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&mid=2247714930&idx=1&sn=d334697b7b535a75ba2a71eed621feab&chksm=e99e4969ab035f60b9387c33ba80d58a01aa96a327bcc3eb0880a9f3076b0523d8171cba8979&scene=27](https://mp.weixin.qq.com/s?__biz=MzIzMjQyNzQ5MA==&mid=2247714930&idx=1&sn=d334697b7b535a75ba2a71eed621feab&chksm=e99e4969ab035f60b9387c33ba80d58a01aa96a327bcc3eb0880a9f3076b0523d8171cba8979&scene=27) 

[8] SwarmBench: Benchmarking LLMs for Swarm Intelligence in Decentralized MAS [http://www.paperreading.club/page?id=304030](http://www.paperreading.club/page?id=304030) 

[9] SALM: 基于语言模型的多智能体社交网络模拟框架 [http://www.paperreading.club/page?id=305460](http://www.paperreading.club/page?id=305460) 

[10] 基于LLM的多智能体系统：协作智慧解锁复杂任务 [https://developer.baidu.com/article/details/3323842](https://developer.baidu.com/article/details/3323842) 

[11] LLM Agent 综述：技术趋势、架构与实践 [https://juejin.cn/post/7435035570286280738](https://juejin.cn/post/7435035570286280738) 

[12] LLM Multi Agent - 大模型多智能体应用 [https://llmmultiagent.com/](https://llmmultiagent.com/) 

[13] Verify-Agent: LLM Multi-Agent for Intelligent Verification of Planning Templates [https://ieeexplore.ieee.org/document/11049395/](https://ieeexplore.ieee.org/document/11049395/) 

[14] LLM-based Agents：大语言模型多智能代理综述及展望 [https://zhuanlan.zhihu.com/p/648376562](https://zhuanlan.zhihu.com/p/648376562) 

[15] LLMs in Groups Show Utilitarian Boost: A Moral Dilemma [https://arxiv.org/html/2507.00814v1](https://arxiv.org/html/2507.00814v1) 

[16] LLM赋能多智能体系统综述：工作流程、基础设施与挑战 [https://link.springer.com/article/10.1007/s44336-024-00009-2](https://link.springer.com/article/10.1007/s44336-024-00009-2) 

[17] Large Language Model Empowered Agent-Based Modeling and Simulation: A Survey and Perspectives [https://www.nature.com/articles/s41599-024-03611-3](https://www.nature.com/articles/s41599-024-03611-3) 

[18] LLM多智能体系统技术综述：架构、记忆、规划与框架 [https://arxiv.org/html/2504.01963v1](https://arxiv.org/html/2504.01963v1) 

[19] LLM多智能体研究：现状、挑战与未来方向 [https://blog.csdn.net/l01011_/article/details/138729393](https://blog.csdn.net/l01011_/article/details/138729393) 

[20] 多代理LLM系统失败模式揭秘与MASFT分类体系 [https://blog.csdn.net/weixin_44975687/article/details/146588654](https://blog.csdn.net/weixin_44975687/article/details/146588654) 

[21] 基于大语言模型的自主代理综述：构建、应用与评估 [https://zhuanlan.zhihu.com/p/687186599](https://zhuanlan.zhihu.com/p/687186599) 

[22] LLM-Based Agent：规划、推理、记忆、工具使用与多Agent系统 [https://blog.csdn.net/2401_84204207/article/details/144917657](https://blog.csdn.net/2401_84204207/article/details/144917657) 

[23] 基于大模型的教学智能体构建与应用 [https://mp.weixin.qq.com/s?__biz=MzIzNjU3MDY4NA==&mid=2247585617&idx=2&sn=b4dddde63724afbb3c45edb5fb5bc5d7&chksm=e9705fceccfd06038521eccf9cde92edfd8ce4e8590b78a2e506960d68d6fc002db6573534c7&scene=27](https://mp.weixin.qq.com/s?__biz=MzIzNjU3MDY4NA==&mid=2247585617&idx=2&sn=b4dddde63724afbb3c45edb5fb5bc5d7&chksm=e9705fceccfd06038521eccf9cde92edfd8ce4e8590b78a2e506960d68d6fc002db6573534c7&scene=27) 

[24] ICLR'24：大语言模型智能体最新研究进展汇总 [https://mp.weixin.qq.com/s?__biz=Mzg4ODg5MDc1NA==&mid=2247486435&idx=1&sn=99f4b647df642c1a292c25d6b8ca05cc&chksm=cff57f0ef882f6185f6564682f30c34d9c506fd6f001bbf8c062792bf0e7288069a3bf3ca9f5&scene=27](https://mp.weixin.qq.com/s?__biz=Mzg4ODg5MDc1NA==&mid=2247486435&idx=1&sn=99f4b647df642c1a292c25d6b8ca05cc&chksm=cff57f0ef882f6185f6564682f30c34d9c506fd6f001bbf8c062792bf0e7288069a3bf3ca9f5&scene=27) 

[25] LLM-based Multi-Agent系统架构设计与项目实践(一)：概述与应用 [https://blog.csdn.net/universsky2015/article/details/144164277](https://blog.csdn.net/universsky2015/article/details/144164277) 

[26] LLM时代的多智能体系统：协作与竞争 [https://blog.csdn.net/CV_Autobot/article/details/138385376](https://blog.csdn.net/CV_Autobot/article/details/138385376) 

[27] LLM驱动的Agent应用开发探索：百度智能云千帆平台实践 [https://cloud.baidu.com/article/3373837](https://cloud.baidu.com/article/3373837) 

[28] LLM赋能：多智能体系统研究与实践 [https://blog.csdn.net/universsky2015/article/details/139816523](https://blog.csdn.net/universsky2015/article/details/139816523) 

[29] NeurIPS 2024：LLM-Multi Agent 研究依旧火爆 [https://blog.csdn.net/2401_85390073/article/details/144546518](https://blog.csdn.net/2401_85390073/article/details/144546518) 

[30] LLM Agent: 基于大型语言模型的多Agent进展与挑战综述 [https://download.csdn.net/blog/column/12596440/136621315](https://download.csdn.net/blog/column/12596440/136621315) 

[31] LLM-Based Multi-Agent 系统实现与应用 [https://wenku.csdn.net/answer/1ypp8cxrs9](https://wenku.csdn.net/answer/1ypp8cxrs9) 

[32] LLM-based Multi-Agent System [https://download.csdn.net/blog/column/12220857/139816523](https://download.csdn.net/blog/column/12220857/139816523) 

[33] YiyiBooks文档翻译平台 [https://yiyibooks.cn/__trs__/arxiv/2406.05804v1/index.html](https://yiyibooks.cn/__trs__/arxiv/2406.05804v1/index.html) 

[34] 一译文档登录注册及同步翻译功能介绍 [https://www.yiyibooks.cn/__src__/arxiv/2404.02183v1/index.html](https://www.yiyibooks.cn/__src__/arxiv/2404.02183v1/index.html) 

[35] 背景颜色设置：图案、纯色与自定义 [https://m.doc88.com/p-48237822636853.html](https://m.doc88.com/p-48237822636853.html) 

